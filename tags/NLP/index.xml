<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>NLP on</title><link>https://pinktalk.online/tags/NLP/</link><description>Recent content in NLP on</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="https://pinktalk.online/tags/NLP/index.xml" rel="self" type="application/rss+xml"/><item><title>Large Language Model(LLM) - MOC</title><link>https://pinktalk.online/computer_sci/Deep_Learning_And_Machine_Learning/LLM/LLM_MOC/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pinktalk.online/computer_sci/Deep_Learning_And_Machine_Learning/LLM/LLM_MOC/</guid><description>Training Training Tech Outline ⭐⭐⭐Train LLM from scratch ⭐⭐⭐Detailed explanation of RLHF technology How to do use fine tune tech to create your chatbot Learn finetune by Stanford Alpaca Metrics How to evaluate a LLM performance?</description></item><item><title>Tokenization</title><link>https://pinktalk.online/computer_sci/Deep_Learning_And_Machine_Learning/NLP/basic/tokenization/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pinktalk.online/computer_sci/Deep_Learning_And_Machine_Learning/NLP/basic/tokenization/</guid><description/></item></channel></rss>