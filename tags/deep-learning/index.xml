<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>deep-learning on</title><link>https://pinktalk.online/tags/deep-learning/</link><description>Recent content in deep-learning on</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="https://pinktalk.online/tags/deep-learning/index.xml" rel="self" type="application/rss+xml"/><item><title>AdaBoost</title><link>https://pinktalk.online/Deep-Learning-And-Machine-Learning/Deep_Learning_Block_and_Machine_Learning_Block/AdaBoost/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pinktalk.online/Deep-Learning-And-Machine-Learning/Deep_Learning_Block_and_Machine_Learning_Block/AdaBoost/</guid><description>Video you need to watch first AdaBoost, Clearly Explained Key words and equation Stump(树桩) means classification just by one feature Amount of say $$ \text{Amout of say} = \frac{1}{2}\log{(\frac{1-\text{Total Error}}{\text{Total Error}})} $$</description></item><item><title>Deep Learning - MOC</title><link>https://pinktalk.online/Deep-Learning-And-Machine-Learning/Deep-_Learning_MOC/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pinktalk.online/Deep-Learning-And-Machine-Learning/Deep-_Learning_MOC/</guid><description> Deep Learning Block &amp;amp; Machine Learning - MOC
Model Interpretability</description></item><item><title>Deep Neural Decision Forests</title><link>https://pinktalk.online/Deep-Learning-And-Machine-Learning/Deep_Learning_Block_and_Machine_Learning_Block/Deep_Neural_Decision_Forests/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pinktalk.online/Deep-Learning-And-Machine-Learning/Deep_Learning_Block_and_Machine_Learning_Block/Deep_Neural_Decision_Forests/</guid><description>Background Decision Tree Random Forest What is Deep Neural Decision Forests Reference Deep Neural Decision Forests - YouTube Vedio by Venkatesh Bingi</description></item><item><title>Model Interpretability - MOC</title><link>https://pinktalk.online/Deep-Learning-And-Machine-Learning/Model_interpretability/Model_Interpretability_MOC/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pinktalk.online/Deep-Learning-And-Machine-Learning/Model_interpretability/Model_Interpretability_MOC/</guid><description> SHAP</description></item><item><title>SHAP - a reliable way to analyze model interpretability</title><link>https://pinktalk.online/Deep-Learning-And-Machine-Learning/Model_interpretability/SHAP/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pinktalk.online/Deep-Learning-And-Machine-Learning/Model_interpretability/SHAP/</guid><description>SHAP is the most popular model-agnostic technique that is used to explain predictions. SHAP stands for SHapley Additive exPlanations
Shapely values are obtained by incorporating concepts from Cooperative Game Theory and local explanations</description></item><item><title>Transformer</title><link>https://pinktalk.online/Deep-Learning-And-Machine-Learning/Deep_Learning_Block_and_Machine_Learning_Block/Transformer/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pinktalk.online/Deep-Learning-And-Machine-Learning/Deep_Learning_Block_and_Machine_Learning_Block/Transformer/</guid><description> [!info] 在学习Transformer前，你需要学习 ⭐Attention
Transformer 是Seq2Seq model，由Encoder和Decoder组成 Encoder 这里贴的是原文Encoder的架构</description></item><item><title>XGBoost</title><link>https://pinktalk.online/Deep-Learning-And-Machine-Learning/Deep_Learning_Block_and_Machine_Learning_Block/XGBoost/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pinktalk.online/Deep-Learning-And-Machine-Learning/Deep_Learning_Block_and_Machine_Learning_Block/XGBoost/</guid><description>XGBoost is an open-source software library that implements optimized distributed gradient boosting machine learning algorithms under the Gradient Boosting framework.</description></item><item><title>⭐Attenion</title><link>https://pinktalk.online/Deep-Learning-And-Machine-Learning/Deep_Learning_Block_and_Machine_Learning_Block/Attention/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pinktalk.online/Deep-Learning-And-Machine-Learning/Deep_Learning_Block_and_Machine_Learning_Block/Attention/</guid><description>Self-Attention 讲述self-attention我们以sequence labeling任务作为任务来讲解，sequence labeling的任务是输入N个vector并且输出N个label。
典型的例子有输入一个句子，分析每个词汇的词性是什么，比如句子“I saw a saw”，这个句子里saw和saw的词性分别是verb和nonu，如果我们用fully-connected（FC）层来做的话，那么面对同样的输入saw，我们无法得出不同的结果。
我们的做法可以是对输入加窗，考虑周边邻近的词汇信息，这与信号处理常用的方法类似，但是窗的长度是有限且固定的，而seq的长度是变化的，因此我们在面对这种任务的时候，我们可以借助self-attention层。
Detail 对于Self-attention层，生成的$b^i$向量是考虑到所有输入$\sum_i\alpha^i$向量
Vector Relevance Step 1. 使用Dot-product 去计算 vector relevance Step 2.</description></item></channel></rss>