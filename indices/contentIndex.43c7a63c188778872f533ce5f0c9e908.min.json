{"/":{"title":"Home","content":"\n🕵️‍♂️ This is Jude Wang's vault about his notebook, his knowledge, his second brain. \n\n🚧 There are notebooks about his research career:\n\n* [Deep Learning](Deep%20Learning%20And%20Machine%20Learning/Deep%20_Learning_MOC.md)\n\n* [[Synthetic Aperture Radar Imaging/SAR_MOC| Synthetic Aperture Radar(SAR) Imaging]]\n\nAlso, his research needs some basic science to support\n\n* [Hardware](Hardware/Hardware_MOC.md)\n\n* [Physics](Physics/Physics_MOC.md)\n\n* [Signal Processing](Signal%20Processing/Signal%20Processing_MOC.md)\n\n🛶 Also, he learn some knowledge about his hobbies:\n\n* [📷 Photography](Photography/Photography_MOC.md)\n\n* [📮文学](文学/文学_MOC.md)\n\n","lastmodified":"2023-04-17T12:12:40.7084107Z","tags":null},"/%E6%96%87%E5%AD%A6/%E5%8F%A5%E5%AD%90/%E5%8F%A5%E5%AD%90":{"title":"句子","content":"\n* [🌸Love about](文学/句子/Love%20about.md)\n* [🌄Poem](文学/句子/Poem.md)\n* [🧗🏻‍♂️Motivation](文学/句子/Motivation.md)\n* [🧶Feeling](文学/句子/Feeling.md)\n* [📽Movie](文学/句子/Movie.md)\n* [🎹Novel](文学/句子/Novel.md)\n* [🥐Comments](文学/句子/Comments.md)\n* [🎺Music](文学/句子/Music.md)\n","lastmodified":"2023-04-17T12:12:40.716410792Z","tags":null},"/%E6%96%87%E5%AD%A6/%E5%8F%A5%E5%AD%90/Comments":{"title":"🥐Comments","content":"\n  \u003cstyle\u003e\n    p {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n\n    a {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n  \u003c/style\u003e\n\n\u003e [!quote] \n\u003e  From comments\n\u003e  \n\u003e   被一些影评人的高度评价给诈骗到了;看来不同人对浪漫的定义非常不同，对于有些人来说“宇宙”“存在”等词以及语焉不详的现代诗歌排列组合在一起即可触发内心浪漫情结，就跟大学生会用夏天、自由、苏打、快乐with黄油相机滤镜加字加字照片来营造自觉出众的氛围感朋友圈一样。女儿的线也太刻奇，套了一个寻找外星人的噱头、还有伪纪录片的形式，镜头的设计还有手持的感觉在大荧幕上显得非常粗糙，之前很喜欢导演那个《法制未来时》的短片,结果电影有种加长版视频的感觉，还是感觉撑不起来啊... ...\n\n\n--- \n\n\n \u003e [!quote] \n\u003e From CC98, credits to someone\n\u003e \n\u003e \n\u003e感觉你女朋友是那种 初中喜欢混混 高中喜欢体育生 军训喜欢教官 大学喜欢rapper 打工爱上领导 理发爱上托尼 看病爱上医生 离婚爱上律师的人\n\n\n--- \n\n\n\n\u003e [!quote] \n\u003e From a video talking about 坂本龙一 by [HOPICO](https://www.bilibili.com/video/BV1pa4y1T7v2/?spm_id_from=333.1007.top_right_bar_window_history.content.click\u0026vd_source=c47136abc78922800b17d6ce79d6e19f) \n\u003e \n\u003e 1. 脱下合成器的修饰之后，这首作品变成了一个最赤裸的样子。我们听过印象深刻的钢琴曲，我们热爱他们，我们在形容它们的时候，多数是“热情”、“悲伤”、“欢乐”、“雄伟”。但这首歌不一样，之于我第一次听到它的时候，我再想为什么会有一首歌，那么精确地，在开头把“安静”这两个字讲了出来，明明无声的真空才是最安静，可这几个音符勾勒出来的安静，就是胜过了无声的真空。我想，那是因为我们在这几个音符背后，仿佛能够看到一个作曲家，找到他的钢琴，好像全世界只剩下他们的样子。\n\u003e    \n\u003e    要说幸运的是，我亲眼见过教授带着管弦乐团的全编制演奏这首作品。虽然我内心一直觉得，这是一首寂寞的作品，我心中它最好的样子，就是保持在三人编制以下，但是我清楚记得，那天在现场听到最后一个段落时，我眼泪止不住地往下流，我还记得我当时心里想的是：“md，这么多年了，终于听到了”\n\u003e    \n\u003e    就像教授在后来采访里说的，它可能不是首好的电影配乐，因为它不需要画面就已经自成一体了。可是重新听到它地时候，仍然意气风发。\n\u003e    \n\u003e    \u003cp style=\"text-align: right\"\u003e——HOPICO 评价 「\u003ca href=\"https://music.apple.com/cn/album/merry-christmas-mr-lawrence-coda/1404842855?i=1404843053\"\u003eMerry Christmas, Mr. Lawrence\u003c/a\u003e」\u003c/p\u003e\n\u003e    \n\u003e 2. 坂本龙一小的时候很喜欢Beatles，甚至一度以为只有了解Beatles的人才能和自己做朋友。而「末代皇帝」当中，许多作品的录制，都是在abbey road 2号录影棚完成的，这里是The Beatles 1962年到1969年录音的地方。教授也通过这样的方式，和自己的偶像有了*重合*。\n\u003e    \n\u003e    而在这里录制的作品，就包括整部原声带当中我最喜欢的「Where is Armo?」，在这首歌的写作里，他构建出了一种徐徐前行，奔赴宿命的坦荡。\n\u003e    \n\u003e   \u003cp style=\"text-align: right\"\u003e——HOPICO 评价 「\u003ca href=\"https://music.apple.com/cn/album/where-is-armo/714659119?i=714659278\"\u003eWhere is Armo?\u003c/a\u003e」\u003c/p\u003e\n\u003e\n\u003e 3. 在这之后，教授有陆续发行自己钢琴演奏版本的「A Flower is Not A Flower」。如果说文金龙版本的是线状绵延的凄凉，那在教授钢琴的版本里，我们听到的是点状的，在夜里，一边开，一边败的花的失落之美。\n\u003e   \n\u003e\t  在教授这个阶段的很多作品里，我们都能找到类似的气质。或者说，教授本身就很擅长用琴键去勾勒这种气质。如果允许我用很自私的感受去总结的话，我想对于我而言就是，在这样的作品里，*哪怕是简单排列的单音，我们也能听到一边生长，一边流失*。\n\u003e\n\u003e    \u003cp style=\"text-align: right\"\u003e——HOPICO 评价 「\u003ca href=\"\"\u003eA Flower is Not A Flower\u003c/a\u003e」\u003c/p\u003e\n\u003e\n\u003e 4. 伟大的艺术家是在不停迭代自己的生命周期\n\u003e   \n\u003e \u003cp style=\"text-align: right\"\u003e——「\u003ca href=\"https://www.imdb.com/title/tt6578572/\"\u003eRyuichi Sakamoto: Coda\u003c/a\u003e」\u003c/p\u003e\n\u003e\n\u003e 5. 教授大概说过这么一句话，就是，钢琴的声音按下去之后，会逐渐地开始衰减，哪怕非常微弱地持续，最后也会消失，所以他也渴望可以永恒发展下去的声音。\n\u003e    \n\u003e    而在「andata」这首作品里，我们可以听到在下面这段与管风琴音色所演奏出来的主旋律的稳定所呼应的是一种在持续出现的，让人不安或者不稳定的合成器的声响。这看似矛盾的两者出现在一起，正是一种异步。他在去除人为对音乐冠以的快乐、悲伤这些明显的情绪化的修饰。声音的产生和这种不规律是去人性的，是高于人为定义的，生命也是如此。\n\u003e    \n\u003e    \u003cp style=\"text-align: right\"\u003e——HOPICO 评价 「\u003ca href=\"https://music.apple.com/cn/album/andata/1507014129?i=1507014130\"\u003eandata\u003c/a\u003e」\u003c/p\u003e\n\u003e    \n\u003e   6.  专辑的概念「异步」通过不同的形式贯穿每一首作品，在下面这首音乐里，我们可以听到一个好像扮演心跳信号的音色，贯穿始终。一般的做法，可能会使这个音色的节律和作品的速度保持一致，然后同步落到作品的正拍上。但明显，在这部作品里，教授让这个心跳节律的音色和作品的拍子，处在一个完全异步的过程当中。*我自私的理解是*，**生命中的声音与音乐不和谐的共存，才是真实的空间。毕竟和谐在多数时候都是人为制造的巧合，而生命中巧合的几率又只是少数**。\n\u003e \n\u003e \u003cp style=\"text-align: right\"\u003e——HOPICO 评价 「\u003ca href=\"https://music.apple.com/cn/album/ubi/1507014129?i=1507014136\"\u003eubi\u003c/a\u003e」\u003c/p\u003e\n\u003e \n\n![](文学/句子/attachments/Pasted%20image%2020230409171853.png)\n","lastmodified":"2023-04-17T12:12:40.712410746Z","tags":null},"/%E6%96%87%E5%AD%A6/%E5%8F%A5%E5%AD%90/Feeling":{"title":"🧶Feeling","content":"\n  \u003cstyle\u003e\n    p {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n\n    a {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n  \u003c/style\u003e\n\n\u003e [!quote] \n\u003e A Sentence\n\u003e \n\u003e 一个太过于文艺的人注定不会快乐，因为心中有爱 有善良，骨子里住着孩子般的纯真，但也往往容易多愁善感，容易感知美好，也更容易体会悲伤。她喜欢文字，往往不善言辞，不是文字太少，而是感受太多。\n\u003e  \u003cp style=\"text-align:right\"\u003e——三毛\u003c/p\u003e\n\n\n--- \n\n\u003e [!quote] \n\u003e From bilibili vedio -  [陶喆给别人写的歌是什么水平?丨HOPICO](https://www.bilibili.com/video/BV1fo4y1z7jf/?spm_id_from=333.999.0.0\u0026vd_source=c47136abc78922800b17d6ce79d6e19f)\n\u003e \n\u003e 我们在面对回忆时，有一种态度就是，在疯狂之后都会回到安静里。举例证明，那大概就是在计程车后排，放空的眼神里，实际上在脑海中汹涌着，翻滚的回忆。\n\n\n--- \n\n\u003e [!quote] \n\u003e From JudeW, me\n\u003e \n\u003e 你的心软，世界的触感也更加真实\n ","lastmodified":"2023-04-17T12:12:40.716410792Z","tags":null},"/%E6%96%87%E5%AD%A6/%E5%8F%A5%E5%AD%90/Love-about":{"title":"🌸Love","content":"\n  \u003cstyle\u003e\n    p {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n\n    a {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n  \u003c/style\u003e\n\n  \u003e [!quote] \n\u003e [A poem](https://www.bilibili.com/video/BV1V24y1x7Nh/?buvid=YF4AFCFA7E0887094E329B9A6FADF98BF343\u0026is_story_h5=false\u0026mid=B1quk6Mlu6tnRY8zjwxWeg%3D%3D\u0026p=1\u0026plat_id=116\u0026share_from=ugc\u0026share_medium=iphone\u0026share_plat=ios\u0026share_session_id=4AD8E5F4-D617-499B-9C19-D5897A7EB825\u0026share_source=QQ\u0026share_tag=s_i\u0026timestamp=1679378304\u0026unique_k=tXa4xdJ\u0026up_id=315154029\u0026vd_source=c47136abc78922800b17d6ce79d6e19f) \u003cbr\u003e\n\u003e “至少有两次喜欢\u003cbr\u003e\n\u003e 一次发生在在一起之前，一次发生在之后，\u003cbr\u003e\n\u003e 第一次是喜欢上你。第二次是喜欢上我们，\u003cbr\u003e\n\u003e 我只敢把第二次翻译成爱，\u003cbr\u003e\n\u003e 第一次是因为你很好，第二次是因为我还没有坏到敢放满揉碎你的好。\u003cbr\u003e\n\u003e 我要小心的捧着第一次的喜欢，就像掏出一份手写的初稿，\u003cbr\u003e\n\u003e 你会接过我的目光，在岁月里重新誊写岁月，\u003cbr\u003e\n\u003e 要删改的地方还很多，包括但不限于，把差错翻译成幽默\u003cbr\u003e\n\u003e 改了还是存在啊，爱情本就是听起来很美的，阴差阳错”\n\n\n--- \n\n\u003e [!quote] \n\u003e A Sentence\n\u003e \n\u003e \"I am too full of life to be half-loved\"\n\u003e \n\n![400](文学/attachments/Pasted%20image%2020230321142115.png)\n\n---\n\n\u003e [!quote] \n\u003e [A poem](https://www.bilibili.com/video/BV1Vd4y187Tq/?buvid=YF4AFCFA7E0887094E329B9A6FADF98BF343\u0026is_story_h5=false\u0026mid=B1quk6Mlu6tnRY8zjwxWeg%3D%3D\u0026p=1\u0026plat_id=116\u0026share_from=ugc\u0026share_medium=iphone\u0026share_plat=ios\u0026share_session_id=F81E6185-E382-4E78-95FD-3155869F570B\u0026share_source=QQ\u0026share_tag=s_i\u0026timestamp=1679380048\u0026unique_k=Q9GSCLM\u0026up_id=2009238634\u0026vd_source=c47136abc78922800b17d6ce79d6e19f)\u003cbr\u003e\n\u003e  “他听的小众音乐，\u003cbr\u003e\n\u003e  第二天上了抖音热榜。\u003cbr\u003e\n\u003e  他爱吃的苍蝇小馆，\u003cbr\u003e\n\u003e  第二天全国连锁了一万家。\u003cbr\u003e\n\u003e  他爱的县城姑娘，\u003cbr\u003e\n\u003e  第二天出国留学再也没回来。\u003cbr\u003e\n\u003e  他觉得那些特别，\u003cbr\u003e\n\u003e  都已烟消云散，\u003cbr\u003e\n\u003e  可那些特别一直都在，\u003cbr\u003e\n\u003e  错就错在他认为特别\u003cbr\u003e\n\u003e  只属于他。”\u003cbr\u003e\n\u003e  \u003ca href=\"https://space.bilibili.com/2009238634\"\u003e\u003cp style=\"text-align:right\"\u003e——祺白石\u003c/p\u003e\u003c/a\u003e\n\n![400](文学/attachments/Pasted%20image%2020230321143300.png)","lastmodified":"2023-04-17T12:12:40.716410792Z","tags":null},"/%E6%96%87%E5%AD%A6/%E5%8F%A5%E5%AD%90/Motivation":{"title":"🧗🏻‍♂️Motivation","content":"\n  \u003cstyle\u003e\n    p {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n\n    a {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n  \u003c/style\u003e\n\n\u003e [!quote] \n\u003e A Sentence\n\u003e \n\u003e \"No easy basket\"\n\n“如果你想了解American篮球的根基，你要去看看美高”\n","lastmodified":"2023-04-17T12:12:40.716410792Z","tags":null},"/%E6%96%87%E5%AD%A6/%E5%8F%A5%E5%AD%90/Movie":{"title":"From Movie","content":"\n  \u003cstyle\u003e\n    p {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n\n    a {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n  \u003c/style\u003e\n\n\u003e [!quote] \n\u003e  铃芽之旅\n\u003e  \n\u003e  \"鎮住土地的是人心的重量。\"\n\n\n--- \n\n\n\u003e [!quote] \n\u003e  From comments\n\u003e  \n\u003e   被一些影评人的高度评价给诈骗到了;看来不同人对浪漫的定义非常不同，对于有些人来说“宇宙”“存在”等词以及语焉不详的现代诗歌排列组合在一起即可触发内心浪漫情结，就跟大学生会用夏天、自由、苏打、快乐with黄油相机滤镜加字加字照片来营造自觉出众的氛围感朋友圈一样。女儿的线也太刻奇，套了一个寻找外星人的噱头、还有伪纪录片的形式，镜头的设计还有手持的感觉在大荧幕上显得非常粗糙，之前很喜欢导演那个《法制未来时》的短片,结果电影有种加长版视频的感觉，还是感觉撑不起来啊... ...\n\n","lastmodified":"2023-04-17T12:12:40.716410792Z","tags":null},"/%E6%96%87%E5%AD%A6/%E5%8F%A5%E5%AD%90/Music":{"title":"🎺Music","content":"\n  \u003cstyle\u003e\n    p {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n\n    a {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n  \u003c/style\u003e\n\nMusic links usually link to apple music\n\n\u003e [!quote] \n\u003e From a video talking about 坂本龙一 by [HOPICO](https://www.bilibili.com/video/BV1pa4y1T7v2/?spm_id_from=333.1007.top_right_bar_window_history.content.click\u0026vd_source=c47136abc78922800b17d6ce79d6e19f) \n\u003e \n\u003e 1. 脱下合成器的修饰之后，这首作品变成了一个最赤裸的样子。我们听过印象深刻的钢琴曲，我们热爱他们，我们在形容它们的时候，多数是“热情”、“悲伤”、“欢乐”、“雄伟”。但这首歌不一样，之于我第一次听到它的时候，我再想为什么会有一首歌，那么精确地，在开头把“安静”这两个字讲了出来，明明无声的真空才是最安静，可这几个音符勾勒出来的安静，就是胜过了无声的真空。我想，那是因为我们在这几个音符背后，仿佛能够看到一个作曲家，找到他的钢琴，好像全世界只剩下他们的样子。\n\u003e    \n\u003e    要说幸运的是，我亲眼见过教授带着管弦乐团的全编制演奏这首作品。虽然我内心一直觉得，这是一首寂寞的作品，我心中它最好的样子，就是保持在三人编制以下，但是我清楚记得，那天在现场听到最后一个段落时，我眼泪止不住地往下流，我还记得我当时心里想的是：“md，这么多年了，终于听到了”\n\u003e    \n\u003e    就像教授在后来采访里说的，它可能不是首好的电影配乐，因为它不需要画面就已经自成一体了。可是重新听到它地时候，仍然意气风发。\n\u003e    \n\u003e    \u003cp style=\"text-align: right\"\u003e——HOPICO 评价 「\u003ca href=\"https://music.apple.com/cn/album/merry-christmas-mr-lawrence-coda/1404842855?i=1404843053\"\u003eMerry Christmas, Mr. Lawrence\u003c/a\u003e」\u003c/p\u003e\n\u003e    \n\u003e 2. 坂本龙一小的时候很喜欢Beatles，甚至一度以为只有了解Beatles的人才能和自己做朋友。而「末代皇帝」当中，许多作品的录制，都是在abbey road 2号录影棚完成的，这里是The Beatles 1962年到1969年录音的地方。教授也通过这样的方式，和自己的偶像有了*重合*。\n\u003e    \n\u003e    而在这里录制的作品，就包括整部原声带当中我最喜欢的「Where is Armo?」，在这首歌的写作里，他构建出了一种徐徐前行，奔赴宿命的坦荡。\n\u003e    \n\u003e   \u003cp style=\"text-align: right\"\u003e——HOPICO 评价 「\u003ca href=\"https://music.apple.com/cn/album/where-is-armo/714659119?i=714659278\"\u003eWhere is Armo?\u003c/a\u003e」\u003c/p\u003e\n\u003e\n\u003e 3. 在这之后，教授有陆续发行自己钢琴演奏版本的「A Flower is Not A Flower」。如果说文金龙版本的是线状绵延的凄凉，那在教授钢琴的版本里，我们听到的是点状的，在夜里，一边开，一边败的花的失落之美。\n\u003e   \n\u003e\t  在教授这个阶段的很多作品里，我们都能找到类似的气质。或者说，教授本身就很擅长用琴键去勾勒这种气质。如果允许我用很自私的感受去总结的话，我想对于我而言就是，在这样的作品里，*哪怕是简单排列的单音，我们也能听到一边生长，一边流失*。\n\u003e\n\u003e    \u003cp style=\"text-align: right\"\u003e——HOPICO 评价 「\u003ca href=\"\"\u003eA Flower is Not A Flower\u003c/a\u003e」\u003c/p\u003e\n\u003e\n\u003e 4. 伟大的艺术家是在不停迭代自己的生命周期\n\u003e   \n\u003e \u003cp style=\"text-align: right\"\u003e——「\u003ca href=\"https://www.imdb.com/title/tt6578572/\"\u003eRyuichi Sakamoto: Coda\u003c/a\u003e」\u003c/p\u003e\n\u003e\n\u003e 5. 教授大概说过这么一句话，就是，钢琴的声音按下去之后，会逐渐地开始衰减，哪怕非常微弱地持续，最后也会消失，所以他也渴望可以永恒发展下去的声音。\n\u003e    \n\u003e    而在「andata」这首作品里，我们可以听到在下面这段与管风琴音色所演奏出来的主旋律的稳定所呼应的是一种在持续出现的，让人不安或者不稳定的合成器的声响。这看似矛盾的两者出现在一起，正是一种异步。他在去除人为对音乐冠以的快乐、悲伤这些明显的情绪化的修饰。声音的产生和这种不规律是去人性的，是高于人为定义的，生命也是如此。\n\u003e    \n\u003e    \u003cp style=\"text-align: right\"\u003e——HOPICO 评价 「\u003ca href=\"https://music.apple.com/cn/album/andata/1507014129?i=1507014130\"\u003eandata\u003c/a\u003e」\u003c/p\u003e\n\u003e    \n\u003e   6.  专辑的概念「异步」通过不同的形式贯穿每一首作品，在下面这首音乐里，我们可以听到一个好像扮演心跳信号的音色，贯穿始终。一般的做法，可能会使这个音色的节律和作品的速度保持一致，然后同步落到作品的正拍上。但明显，在这部作品里，教授让这个心跳节律的音色和作品的拍子，处在一个完全异步的过程当中。*我自私的理解是*，**生命中的声音与音乐不和谐的共存，才是真实的空间。毕竟和谐在多数时候都是人为制造的巧合，而生命中巧合的几率又只是少数**。\n\u003e \n\u003e \u003cp style=\"text-align: right\"\u003e——HOPICO 评价 「\u003ca href=\"https://music.apple.com/cn/album/ubi/1507014129?i=1507014136\"\u003eubi\u003c/a\u003e」\u003c/p\u003e\n\u003e \n\n![](文学/句子/attachments/Pasted%20image%2020230409171853.png)\n\n\n\n\n\n\n\n\n","lastmodified":"2023-04-17T12:12:40.716410792Z","tags":null},"/%E6%96%87%E5%AD%A6/%E5%8F%A5%E5%AD%90/Novel":{"title":"From Novel","content":"\n  \u003cstyle\u003e\n    p {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n\n    a {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n  \u003c/style\u003e\n\n\n\u003e [!quote] \n\u003e From CC98, credits to someone\n\u003e \n\u003e 很奇怪，与一个人告别之后男生记起来的永远是一些微不足道的细节，男生不知道女生的名字，也不记得女生常穿的衣服是什么颜色，男生忘掉了每天在桥边上等女生的时间，女生的眼睛也慢慢在男生的记忆里蒙尘。 \n\u003e \n\u003e 不过男生记得等女生时桥下的流水潺潺，也记得校园里某个角落他们经常去看的四叶草，记得第一次注意到女生时公交站顶上那片不同的落叶，也记得步道旁女生指给他看的树皮。 \n\u003e \n\u003e 后来男生看了阿尔瓦雷斯的《行走的距离》，里面有句话是“别人稍一注意你，你就敞开心扉，你觉得这是坦率，其实这是孤独。”\n\u003e \n\u003e  男生不知道自己是不是孤独，也不知道自己是不是坦率。男生不关心。 \n\u003e  \n\u003e  男生很感谢那个女生。 \n\u003e  \n\u003e  男生很想写下“不过男生并不想念那个女生”。 \n\u003e  \n\u003e  不过男生很想念那个女生。\n","lastmodified":"2023-04-17T12:12:40.716410792Z","tags":null},"/%E6%96%87%E5%AD%A6/%E5%8F%A5%E5%AD%90/Poem":{"title":"🖋Poem","content":"\n  \u003cstyle\u003e\n    p {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n\n    a {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n  \u003c/style\u003e\n\n\u003e [!quote] \n\u003e [A poem](https://www.bilibili.com/video/BV1V24y1x7Nh/?buvid=YF4AFCFA7E0887094E329B9A6FADF98BF343\u0026is_story_h5=false\u0026mid=B1quk6Mlu6tnRY8zjwxWeg%3D%3D\u0026p=1\u0026plat_id=116\u0026share_from=ugc\u0026share_medium=iphone\u0026share_plat=ios\u0026share_session_id=4AD8E5F4-D617-499B-9C19-D5897A7EB825\u0026share_source=QQ\u0026share_tag=s_i\u0026timestamp=1679378304\u0026unique_k=tXa4xdJ\u0026up_id=315154029\u0026vd_source=c47136abc78922800b17d6ce79d6e19f) \u003cbr\u003e\n\u003e “至少有两次喜欢\u003cbr\u003e\n\u003e 一次发生在在一起之前，一次发生在之后，\u003cbr\u003e\n\u003e 第一次是喜欢上你。第二次是喜欢上我们，\u003cbr\u003e\n\u003e 我只敢把第二次翻译成爱，\u003cbr\u003e\n\u003e 第一次是因为你很好，第二次是因为我还没有坏到敢放满揉碎你的好。\u003cbr\u003e\n\u003e 我要小心的捧着第一次的喜欢，就像掏出一份手写的初稿，\u003cbr\u003e\n\u003e 你会接过我的目光，在岁月里重新誊写岁月，\u003cbr\u003e\n\u003e 要删改的地方还很多，包括但不限于，把差错翻译成幽默\u003cbr\u003e\n\u003e 改了还是存在啊，爱情本就是听起来很美的，阴差阳错”\n\n---\n\n\u003e [!quote] \n\u003e [A poem](https://www.bilibili.com/video/BV1Vd4y187Tq/?buvid=YF4AFCFA7E0887094E329B9A6FADF98BF343\u0026is_story_h5=false\u0026mid=B1quk6Mlu6tnRY8zjwxWeg%3D%3D\u0026p=1\u0026plat_id=116\u0026share_from=ugc\u0026share_medium=iphone\u0026share_plat=ios\u0026share_session_id=F81E6185-E382-4E78-95FD-3155869F570B\u0026share_source=QQ\u0026share_tag=s_i\u0026timestamp=1679380048\u0026unique_k=Q9GSCLM\u0026up_id=2009238634\u0026vd_source=c47136abc78922800b17d6ce79d6e19f)\u003cbr\u003e\n\u003e  “他听的小众音乐，\u003cbr\u003e\n\u003e  第二天上了抖音热榜。\u003cbr\u003e\n\u003e  他爱吃的苍蝇小馆，\u003cbr\u003e\n\u003e  第二天全国连锁了一万家。\u003cbr\u003e\n\u003e  他爱的县城姑娘，\u003cbr\u003e\n\u003e  第二天出国留学再也没回来。\u003cbr\u003e\n\u003e  他觉得那些特别，\u003cbr\u003e\n\u003e  都已烟消云散，\u003cbr\u003e\n\u003e  可那些特别一直都在，\u003cbr\u003e\n\u003e  错就错在他认为特别\u003cbr\u003e\n\u003e  只属于他。”\u003cbr\u003e\n\u003e  \u003ca href=\"https://space.bilibili.com/2009238634\"\u003e\u003cp style=\"text-align:right\"\u003e——祺白石\u003c/p\u003e\u003c/a\u003e\n\n![400](文学/attachments/Pasted%20image%2020230321143300.png)","lastmodified":"2023-04-17T12:12:40.716410792Z","tags":null},"/%E6%96%87%E5%AD%A6/%E6%96%87%E5%AD%A6_MOC":{"title":"文学","content":"\n  \u003cstyle\u003e\n    p {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n\n    a {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n  \u003c/style\u003e\n\nIn this MOC, it shows you the path to what I record for some interesting sentences, including Chinese and English, even Japanese.\n\n[🌌句子](文学/句子/句子.md)\n\n[📜原创诗](文学/Poem_by_me.md)\n","lastmodified":"2023-04-17T12:12:40.716410792Z","tags":null},"/%E6%96%87%E5%AD%A6/Poem_by_me":{"title":"My Poem","content":"\n  \u003cstyle\u003e\n    p {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n\n    a {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n  \u003c/style\u003e\n","lastmodified":"2023-04-17T12:12:40.7084107Z","tags":null},"/.trash/XGBoost-4f7e7664770b4a2c89107b59434de9ce/Untitled.png":{"title":"Untitled.png","content":"","lastmodified":"2023-04-17T12:12:39.628398188Z","tags":null},"/.trash/attachments/Pasted-image-20230320150424.png":{"title":"Pasted image 20230320150424.png","content":"","lastmodified":"2023-04-17T12:12:39.628398188Z","tags":null},"/Deep-Learning-And-Machine-Learning/Deep-_Learning_MOC":{"title":"Deep Learning - MOC","content":"\n* [Deep Learning Block \u0026 Machine Learning - MOC](Deep%20Learning%20And%20Machine%20Learning/Deep_Learning_Block_and_Machine_Learning_Block/Deep_Learning_Block_And_Machine_Learning_MOC.md)\n\n* [Model Interpretability](Deep%20Learning%20And%20Machine%20Learning/Model_interpretability/Model_Interpretability_MOC.md)\n\n","lastmodified":"2023-04-17T12:12:39.628398188Z","tags":null},"/Deep-Learning-And-Machine-Learning/Deep_Learning_Block_and_Machine_Learning_Block/AdaBoost":{"title":"AdaBoost","content":"\n# Video you need to watch first\n\n* [AdaBoost, Clearly Explained](https://www.youtube.com/watch?v=LsK-xG1cLYA)\n\n# Key words and equation\n\n- **Stump(树桩) means classification just by one feature**\n- Amount of say\n\n$$\n\\text{Amout of say} = \\frac{1}{2}\\log{(\\frac{1-\\text{Total Error}}{\\text{Total Error}})}\n$$\n\n- Wrong Classified Sample New Weight\n\n$$\n\\text{New Sample Weight} = \\text{Sample Weight}\\times e^{\\text{amount of say}}\n$$\n\n- Correct Clasified Sample New Weight\n\n$$\n\\text{New Sample Weight} = \\text{Sample Weight}\\times e^{-\\text{amount of say}}\n$$\n\n- After reassing sample weight, do bootstrap sample based on their new weight, it will select big weight sample lots of times to adjust next model\n- In last prediction, the **amount of say** decide which results we will pick.\n\n# Question\n\n- **[why decision stumps instead of trees?](https://stats.stackexchange.com/questions/520667/adaboost-why-decision-stumps-instead-of-trees)**","lastmodified":"2023-04-17T12:12:39.628398188Z","tags":null},"/Deep-Learning-And-Machine-Learning/Deep_Learning_Block_and_Machine_Learning_Block/Attention":{"title":"⭐Attenion","content":"# Self-Attention\n\n讲述self-attention我们以*sequence labeling*任务作为任务来讲解，sequence labeling的任务是输入N个vector并且输出N个label。\n\n典型的例子有输入一个句子，分析每个词汇的词性是什么，比如句子“I saw a saw”，这个句子里saw和saw的词性分别是verb和nonu，如果我们用fully-connected（FC）层来做的话，那么面对同样的输入saw，我们无法得出不同的结果。\n\n![Pasted image 20230315195403](Deep%20Learning%20And%20Machine%20Learning/Deep_Learning_Block_and_Machine_Learning_Block/attachments/1.png)\n\n我们的做法可以是对输入加窗，考虑周边邻近的词汇信息，这与信号处理常用的方法类似，但是窗的长度是有限且固定的，而seq的长度是变化的，因此我们在面对这种任务的时候，我们可以借助**self-attention**层。\n\n## Detail\n\n![Pasted image 20230315195603](Deep%20Learning%20And%20Machine%20Learning/Deep_Learning_Block_and_Machine_Learning_Block/attachments/Pasted%20image%2020230315195603.png)\n\n对于Self-attention层，生成的$b^i$向量是考虑到所有输入$\\sum_i\\alpha^i$向量\n\n### Vector Relevance\n\n![250](Deep%20Learning%20And%20Machine%20Learning/Deep_Learning_Block_and_Machine_Learning_Block/attachments/Pasted%20image%2020230315200009.png)\n\n\n* *Step 1.* 使用Dot-product 去计算 vector relevance\n\n![400](Deep%20Learning%20And%20Machine%20Learning/Deep_Learning_Block_and_Machine_Learning_Block/attachments/Pasted%20image%2020230315201906.png)\n\n* *Step 2.* Normalizing计算出来的vector relevance\n![400](Deep%20Learning%20And%20Machine%20Learning/Deep_Learning_Block_and_Machine_Learning_Block/attachments/Pasted%20image%2020230315202047.png)\n\n* *Step 3.*  根据vector relevance，也就是attention scores计算最后的输出。这是一个Reweighting Process，一个extract information based on attention scores\n\n![400](Deep%20Learning%20And%20Machine%20Learning/Deep_Learning_Block_and_Machine_Learning_Block/attachments/Pasted%20image%2020230315202314.png)\n\n\u003e [!hint] \n\u003e  从上面的过程中，可以看出，$b^i$互相之间的计算没有关系，具有很好的并行性\n\n### Matrix Detail\n\n$$\nq^i = W^q \\alpha^i\n$$\n\n\n$$\nQ = [q^1 \\quad q^2 \\quad \\cdots \\quad q^N],\\ \\  I = [\\alpha^1 \\quad \\alpha^2 \\quad \\cdots \\quad \\alpha^N]\n$$\n\n\n\nSo,\n\n$$\nQ = W^q I\n$$\n\nAs same,\n$$\nK = W^k I,\\quad V = W^v I\n$$\nCalculate attention score $\\alpha$,\n$$\n\\begin{bmatrix}\n\\alpha_{1,1} \\\\\n\\alpha_{1,2} \\\\\n\\cdots \\\\\n\\alpha_{1,N}\n\\end{bmatrix} =\n\\begin{bmatrix}\nk^1 \\\\\nk^2 \\\\\n\\cdots \\\\\nk_N\n\\end{bmatrix} q^1\n$$\n\nSo,\n$$\nA=\\begin{bmatrix}\n\\alpha_{1,1} \u0026 \\alpha_{2,1} \u0026 \\cdots \u0026 \\alpha_{N,1} \\\\\n\\alpha_{1,2} \u0026 \\alpha_{2,2} \u0026 \\cdots \u0026 \\alpha_{N,2} \\\\\n\\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots\\\\\n\\alpha_{1,N} \u0026 \\alpha_{2,N} \u0026 \\cdots \u0026 \\alpha_{N,N}\n\\end{bmatrix} =\n\\begin{bmatrix}\nk^1 \\\\\nk^2 \\\\\n\\cdots \\\\\nk_N\n\\end{bmatrix} [q^1 \\quad q^2 \\quad \\cdots \\quad q^N] = K^TQ\n$$\n\n$$\nA' = \\text{Softmax}(A)\n$$\n\nFinally, calculate output $b$\n\n$$\nO = [b^1 \\quad b^2 \\quad \\cdots \\quad b^N] = [v^1 \\quad v^2 \\quad \\cdots \\quad v^N] = VA'\n$$\n\n![600](Deep%20Learning%20And%20Machine%20Learning/Deep_Learning_Block_and_Machine_Learning_Block/attachments/Pasted%20image%2020230315205148.png)\n\n### Positional Encoding\n![250](Deep%20Learning%20And%20Machine%20Learning/Deep_Learning_Block_and_Machine_Learning_Block/attachments/Pasted%20image%2020230315205727.png)\n* Each position has a unique positional vector $e^i$\n\t* hand-crafted\n\t* learned from data\n\n## Fun Facts\n\n### Self-attention vs. CNN\n\n![Pasted image 20230315205918](Deep%20Learning%20And%20Machine%20Learning/Deep_Learning_Block_and_Machine_Learning_Block/attachments/Pasted%20image%2020230315205918.png)\n\n因为transformer有着更大的function set，所以需求更多的数据; ![Pasted image 20230315210032](Deep%20Learning%20And%20Machine%20Learning/Deep_Learning_Block_and_Machine_Learning_Block/attachments/Pasted%20image%2020230315210032.png)\n\n### Self-attention vs. RNN\n\n目前，RNN的角色正在被self-attention替代，RNN在long seq的情况下，前面的信息会被逐渐遗忘；同时**RNN没有并行性**\n同样，Self attention有着比RNN更大的function set，在某些情况下，self-attention可以变成RNN\n\n# Multi-head Self-attention\nMulti-head self attention就是由不同的self attention layer在一起，有不同的$W^q$,$W^k$来负责不同种类的relevance\n\n![600](Deep%20Learning%20And%20Machine%20Learning/Deep_Learning_Block_and_Machine_Learning_Block/attachments/Pasted%20image%2020230315210631.png)\n![300](Deep%20Learning%20And%20Machine%20Learning/Deep_Learning_Block_and_Machine_Learning_Block/attachments/Pasted%20image%2020230315210704.png) ","lastmodified":"2023-04-17T12:12:39.68039879Z","tags":null},"/Deep-Learning-And-Machine-Learning/Deep_Learning_Block_and_Machine_Learning_Block/Decision_Tree":{"title":"Decision Tree","content":"\nOnly vedio here:\n\n* [Decision and Classification Trees, Clearly Explained!!!](https://www.youtube.com/watch?v=_L39rN6gz7Y\u0026t=229s \"Decision and Classification Trees, Clearly Explained!!!\")\n* [Regression Trees, Clearly Explained!!!](https://www.youtube.com/watch?v=g9c66TUylZ4\u0026t=789s \"Regression Trees, Clearly Explained!!!\")\n\n","lastmodified":"2023-04-17T12:12:39.628398188Z","tags":null},"/Deep-Learning-And-Machine-Learning/Deep_Learning_Block_and_Machine_Learning_Block/Deep_Learning_Block_And_Machine_Learning_MOC":{"title":"Deep Learning Block \u0026 Machine Learning - MOC","content":"\n\n# Attention is all you need\n\n* [[Deep Learning And Machine Learning/Deep_Learning_Block_and_Machine_Learning_Block/⭐Attention|Attention Blocker]]\n* [[Deep Learning And Machine Learning/Deep_Learning_Block_and_Machine_Learning_Block/Transformer|Transformer]]\n\n\n# Tree-like architecture\n\n* [Decision Tree](Deep%20Learning%20And%20Machine%20Learning/Deep_Learning_Block_and_Machine_Learning_Block/Decision_Tree.md)\n* [Random Forest](Deep%20Learning%20And%20Machine%20Learning/Deep_Learning_Block_and_Machine_Learning_Block/Random_Forest.md)\n* [Deep Neural Decision Forests](Deep%20Learning%20And%20Machine%20Learning/Deep_Learning_Block_and_Machine_Learning_Block/Deep_Neural_Decision_Forests.md)\n* [XGBoost](Deep%20Learning%20And%20Machine%20Learning/Deep_Learning_Block_and_Machine_Learning_Block/XGBoost.md)\n\n\n# Ensemble Learning\n\n* [AdaBoost](Deep%20Learning%20And%20Machine%20Learning/Deep_Learning_Block_and_Machine_Learning_Block/AdaBoost.md)\n* [XGBoost](Deep%20Learning%20And%20Machine%20Learning/Deep_Learning_Block_and_Machine_Learning_Block/XGBoost.md)\n","lastmodified":"2023-04-17T12:12:39.628398188Z","tags":null},"/Deep-Learning-And-Machine-Learning/Deep_Learning_Block_and_Machine_Learning_Block/Deep_Neural_Decision_Forests":{"title":"Deep Neural Decision Forests","content":"\n# Background\n\n* [Decision Tree](Deep%20Learning%20And%20Machine%20Learning/Deep_Learning_Block_and_Machine_Learning_Block/Decision_Tree.md)\n* [Random Forest](Deep%20Learning%20And%20Machine%20Learning/Deep_Learning_Block_and_Machine_Learning_Block/Random_Forest.md)\n\n# What is Deep Neural Decision Forests\n\n![](Deep%20Learning%20And%20Machine%20Learning/Deep_Learning_Block_and_Machine_Learning_Block/attachments/Pasted%20image%2020230413112822.png)\n\nDeep Neural Decision Forests(dNDFs)是Neural Networks和Random Forest的结合，但是它更倾向于Neural Networks。它本质上是Nerual Networks incorporate Random Forest来提高NN的效率和准确度，训练方法和NN一致。\n\ndNDFs与NN的不同在output layer层发生变化，不单纯使用FC层输出，而是使用随机森林作为最后一层的分类器，相当于通过前面系统输出的data representation用随机森林作为分类器分类。**同时，通过将传统随机森林的local optimize改造成通过back propagation进行global optimize,随机森林的参数训练可以与前端的深度学习网络进行无缝衔接。**\n\n\u003e [!attention] \n\u003e  The method is different from random forest in the sense that it uses a principled, joint and global optimization of split and leaf node parameters and from conventional deep networks because a decision forest provides the final predictions\n\n# Math in Neural Decision Forests\n\nDecision Tree model要是stochastic的，为了让它differentiable，让后面可以通过back-propagation训练。在传统的decision tree模型中，从node到leaf的路径是由decision function确定的，而在这个模型中，我们将用two sets of probabilities去决定final output。\n\n1. Probability of an observation reaching to a leaf . These basically are associated with decision node/split node which decides whether an observation goes left or right\n2. Once an observation reaches a leaf node, probability that it takes a specific class\n\n \n\n# Reference\n\n* [Deep Neural Decision Forests - YouTube Vedio by  Venkatesh Bingi](https://www.youtube.com/watch?v=Uaimgqv75dY)\n* [Deep Neural Decision Forests - Medium by Gurparkash Singh Sohi](https://blog.goodaudience.com/deep-neural-decision-forests-b1dd39c4c6ce)\n* [Deep neural decision forest in keras - Medium by Kushal Mukherjee](https://kushalmukherjee.medium.com/deep-neural-decision-forest-in-keras-60134d270bfe)\n\n","lastmodified":"2023-04-17T12:12:39.628398188Z","tags":null},"/Deep-Learning-And-Machine-Learning/Deep_Learning_Block_and_Machine_Learning_Block/Random_Forest":{"title":"Random Forest","content":"\n# Background\n\n* [Decision Tree](Deep%20Learning%20And%20Machine%20Learning/Deep_Learning_Block_and_Machine_Learning_Block/Decision_Tree.md)\n\n# Detail\n\nonly vedio here:\n\n* [StatQuest: Random Forests Part 1 - Building, Using and Evaluating](https://www.youtube.com/watch?v=J4Wdy0Wc_xQ\u0026t=32s \"StatQuest: Random Forests Part 1 - Building, Using and Evaluating\")\n\n","lastmodified":"2023-04-17T12:12:39.628398188Z","tags":null},"/Deep-Learning-And-Machine-Learning/Deep_Learning_Block_and_Machine_Learning_Block/Transformer":{"title":"Transformer","content":"\n\u003e [!info] \n\u003e 在学习Transformer前，你需要学习 [⭐Attention](Deep%20Learning%20And%20Machine%20Learning/Deep_Learning_Block_and_Machine_Learning_Block/⭐Attention.md)\n\n\n\nTransformer 是Seq2Seq model，由Encoder和Decoder组成\n![300](Deep%20Learning%20And%20Machine%20Learning/Deep_Learning_Block_and_Machine_Learning_Block/attachments/Pasted%20image%2020230316160103.png)\n\n# Encoder\n这里贴的是原文Encoder的架构\n![Pasted image 20230316162635](Deep%20Learning%20And%20Machine%20Learning/Deep_Learning_Block_and_Machine_Learning_Block/attachments/Pasted%20image%2020230316162635.png)\n\n![Pasted image 20230316162642](Deep%20Learning%20And%20Machine%20Learning/Deep_Learning_Block_and_Machine_Learning_Block/attachments/Pasted%20image%2020230316162642.png)","lastmodified":"2023-04-17T12:12:39.628398188Z","tags":null},"/Deep-Learning-And-Machine-Learning/Deep_Learning_Block_and_Machine_Learning_Block/XGBoost":{"title":"XGBoost","content":"\n\nXGBoost is an open-source software library that implements optimized distributed gradient boosting machine learning algorithms under the **Gradient Boosting** framework.\n\n# What you need to know first\n\n* [🚧🚧AdaBoost](Deep%20Learning%20And%20Machine%20Learning/Deep_Learning_Block_and_Machine_Learning_Block/AdaBoost.md)\n\n# What is XGBoost\n\n**XGBoost**, which stands for Extreme Gradient Boosting, is a scalable, distributed **gradient-boosted** decision tree (GBDT) machine learning library. It provides parallel tree boosting and is the leading machine learning library for regression, classification, and ranking problems.\n\nIt’s vital to an understanding of XGBoost to first grasp the machine learning concepts and algorithms that XGBoost builds upon: **supervised machine learning**, **decision trees**, **ensemble learning**, and **gradient boosting**.\n\nHere, we need to know **ensemble learning** and **gradient boosting,** this two thing I don’t konw before.\n\n## What is Ensemble Learning(集成学习)\n\n**Ensemble learning** is a general meta approach to machine learning that **seeks better predictive performance by combining the predictions from multiple models**.\n\nThe three main classes of ensemble learning methods are **bagging**, **stacking**, and **boosting.**\n\n### Bagging\n\nBagging means **Bootstrap aggregation.** It’s an ****ensemble learning method that seeks a diverse group of ensemble members by **varying the training data**.\n\nThis typically involves using a single machine learning algorithm, almost always an unpruned decision tree, and **training each model on a different sample of the same training dataset.** The predictions made by the ensemble members are then **combined using simple statistics, such as voting or averaging.**\n\nKey to the method is the manner in which each sample of the dataset is prepared to train ensemble members. Each model gets its own unique sample of the dataset.\n\nBagging adopts the **bootstrap distribution** for generating **different base learners**. In other words, it applies **bootstrap sampling** to obtain the data subsets for training the base learners.\n\n![](Deep%20Learning%20And%20Machine%20Learning/Deep_Learning_Block_and_Machine_Learning_Block/attachments/Untitled.png)\n\n\u003caside\u003e\n💡 **Bootstrap Sampling\nSelect a sample(a row of data), then reture the sample to dataset and re-select another sample to aggregate a data sample dataset. It means a sample can be selected zero, one, or mulitple times for a given dataset.**\nBootstrap sampling ****is often used in statistics with **small dataset**. geive a better overall estimate of the desired quantity than simply estimating from the whole dataset directly.\n\n\u003c/aside\u003e\n\nKey word of bagging method:\n\n- **Bootstrap Sampling**\n- **Voting or averaging of predictions**\n- **Unpruned decision tree**\n\n\u003e Random forest is the typical example based on the bagging method.\n\u003e \n\n### Stacking\n\nStacking means **Stacked Generalization**. It is an ensemble method that seeks a diverse group of members by **varying the model types** fit on the training data and using a model to combine predictions.\n\n\u003e *Stacking is a general procedure where a learner is trained to combine the individual learners. Here, the individual learners are called the first-level learners, while the combiner is called the second-level learner, or meta-learner.*\n\u003e \n\nStacking has its own nomenclature where ensemble members are referred to as **level-0 models** and the model that is used to combine the predictions is referred to as a **level-1 model**.\n\nThe two-level hierarchy of models is the most common approach, although more layers of models can be used. For example, instead of a single level-1 model, we might have 3 or 5 level-1 models and a single level-2 model that combines the predictions of level-1 models in order to make a prediction.\n\n![](Deep%20Learning%20And%20Machine%20Learning/Deep_Learning_Block_and_Machine_Learning_Block/attachments/Untitled%201.png)\n\nKey words of stacknig method:\n\n- **Unchanged training dataset**\n- **Different machine learning algorithms for each ensemble member**\n- **Machine learning model to learn how to best combine predictions**\n\n### Boosting\n\n**Boosting** is an ensemble method that seeks to change the training data to focus attention on examples that previous fit models on the training dataset have gotten wrong.\n\n\u003e *In boosting, […] the training dataset for each subsequent classifier increasingly focuses on instances misclassified by previously generated classifiers.*\n\u003e \n\nThe key property of boosting ensembles is the idea of **correcting prediction errors**. The models are fit and added to the ensemble sequentially such that the second model attempts to correct the predictions of the first model, the third corrects the second model, and so on.\n\nThis typically involves the use of very simple decision trees that only make a single or a few decisions, referred to in boosting as weak learners. The predictions of the weak learners are combined using simple voting or averaging, although **the contributions are weighed proportional to their performance or capability**. The objective is to develop a so-called “***strong-learner***” from many purpose-built “***weak-learners***”.\n\nTypically, the training **dataset is left unchanged** and instead, the learning algorithm is modified to **pay more or less attention to specific samples based on whether they have been predicted correctly or incorrectly** by previously added ensemble members. \n\n![](Deep%20Learning%20And%20Machine%20Learning/Deep_Learning_Block_and_Machine_Learning_Block/attachments/Untitled%202.png)\n\nKey words to boosting method:\n\n- **Bias training data** toward those examples that are hard to predict\n- **Iteratively add ensemble members to correct predictions of prior models**\n- Combine predictions **using a weighted average** of models\n\n![](Deep%20Learning%20And%20Machine%20Learning/Deep_Learning_Block_and_Machine_Learning_Block/attachments/Untitled%203.png)\n\nType of boosting:\n\n- Adaptive boosting\n- Gradient boosting\n- Extreme gradient boosting\n\n# Introduction to three main type of boosting method\n\n## [Adaptive boosting](https://www.notion.so/AdaBoost-8e7009e35aee4334b31d46bfd7e3dbba)\n\nAdaptive Boosting (AdaBoost) was one of **the earliest boosting models** developed. It adapts and tries to **self-correct** in every iteration of the boosting process.\n\nAdaBoost initially gives the same weight to each dataset. Then, it automatically adjusts the weights of the data points after every decision tree. It **gives more weight to incorrectly classified items** to correct them for the next round. It repeats the process until the residual error, or the difference between actual and predicted values, falls below an acceptable threshold.\n\nYou can use AdaBoost with many predictors, and it is typically not as sensitive as other boosting algorithms. This approach does not work well when there is a correlation among features or high data dimensionality. Overall, **AdaBoost is a suitable type of boosting for classification problems**.\n\n**Must check Learning material below to know more detail of this algorithm. 🚧🚧🚧**\n\n## Gradient boosting\n\nGradient Boosting (GB) is similar to AdaBoost in that it, too, is a **sequential training technique**. The difference between AdaBoost and GB is that GB does not give incorrectly classified items more weight. Instead, GB software **optimizes the loss function by generating base learners sequentially** so that **the present base learner is always more effective than the previous one**. This method **attempts to generate accurate results initially instead of correcting errors throughout the process**, like AdaBoost. For this reason, GB software can lead to more accurate results. Gradient Boosting can help with both classification and regression-based problems.\n\n![](Deep%20Learning%20And%20Machine%20Learning/Deep_Learning_Block_and_Machine_Learning_Block/attachments/Untitled%204.png)\n\n## Extreme gradient boosting\n\nExtreme Gradient Boosting (XGBoost) improves gradient boosting for **computational speed and scale** in several ways. XGBoost uses multiple cores on the CPU so that learning can occur in parallel during training. It is a boosting algorithm that can handle extensive datasets, making it attractive for big data applications. The key features of XGBoost are parallelization, distributed computing, cache optimization, and out-of-core processing.\n\n# Reference\n\n## XGBoost\n\n* [What is XGBoost?](https://www.nvidia.com/en-us/glossary/data-science/xgboost/)\n\n* [XGBoost Part 1 (of 4): Regression](https://www.youtube.com/watch?v=OtD8wVaFm6E)\n\n## Ensemble Learning\n\n* [A Gentle Introduction to Ensemble Learning Algorithms - MachineLearningMastery.com](https://machinelearningmastery.com/tour-of-ensemble-learning-algorithms/)\n\n* [集成学习(ensemble learning)原理详解_Soyoger的博客-CSDN博客_ensemble l](https://blog.csdn.net/qq_36330643/article/details/77621232)\n\n* [What is Boosting? Guide to Boosting in Machine Learning - AWS](https://aws.amazon.com/what-is/boosting/)\n\n* [Regression Trees, Clearly Explained!!!](https://www.youtube.com/watch?v=g9c66TUylZ4\u0026list=PLblh5JKOoLUICTaGLRoHQDuF_7q2GfuJF\u0026index=45)\n\n* [AdaBoost, Clearly Explained](https://www.youtube.com/watch?v=LsK-xG1cLYA)\n\n* [Gradient Boost Part 1 (of 4): Regression Main Ideas](https://www.youtube.com/watch?v=3CC4N4z3GJc)\n","lastmodified":"2023-04-17T12:12:39.628398188Z","tags":null},"/Deep-Learning-And-Machine-Learning/Model_interpretability/Model_Interpretability_MOC":{"title":"Model Interpretability - MOC","content":"\n* [SHAP](Deep%20Learning%20And%20Machine%20Learning/Model_interpretability/SHAP.md)\n","lastmodified":"2023-04-17T12:12:39.68039879Z","tags":null},"/Deep-Learning-And-Machine-Learning/Model_interpretability/SHAP":{"title":"SHAP - a reliable way to analyze model interpretability","content":"\nSHAP is the most popular model-agnostic technique that is used to explain predictions. SHAP stands for **SH**apley **A**dditive ex**P**lanations\n\nShapely values are obtained by incorporating concepts from *Cooperative Game Theory*  and *local explanations*\n\n# Mathematical and Algorithm Foundation\n\n## Shapely Values\n\nShapely values were from game theory and invented by Lloyd Shapley. Shapely values were invented to be a way of providing a fair solution to the following question:\n\n\u003e [!question] \n\u003e  If we have a coalition **C** that collaborates to produce a value **V**: How much did each individual member contribute to the final value\n\nThe method here we assess each individual member’s contribution is to removing each member to get a new coalition and then compare their production, like this graphs:\n\n![](Deep%20Learning%20And%20Machine%20Learning/Model_interpretability/attachments/Pasted%20image%2020230329165429.png)\n\nAnd then, we get every member 1 included or not included coalitions like this:\n\n![](Deep%20Learning%20And%20Machine%20Learning/Model_interpretability/attachments/Pasted%20image%2020230329165523.png)\n\nUsing left value - right value, we can get difference like image left above; And then we calculate the mean of them:\n\n$$\n\\varphi_i=\\frac{1}{\\text{Members}}\\sum_{\\forall \\text{C s.t. i}\\notin \\text{C}} \\frac{\\text{Marginal Contribution of i to C}}{\\text{Coalitions of size |C|}}\n$$\n\n## Shapely Additive Explanations\n\nWe need to know what’s **additive** mean here. Lundberg and Lee define an additive feature attribution as follows:\n\n![](Deep%20Learning%20And%20Machine%20Learning/Model_interpretability/attachments/Pasted%20image%2020230329165623.png)\n\n![](Deep%20Learning%20And%20Machine%20Learning/Model_interpretability/attachments/Pasted%20image%2020230329165818.png)\n\n$x'$, the simplified local inputs usually means that we turn a feature vector into a discrete binary vector, where features are either included or excluded. Also, the $g(x')$ should take this form:\n\n$$\ng(x')=\\varphi_0+\\sum_{i=1}^N \\varphi_i {x'}_i\n$$\n\n* $\\varphi_0$ is the **null output** of this model, that is, the **average output** of this model\n-  $\\varphi_i$ is **feature affect**, is how much that feature changes the output of the model, introduced above. It’s called **attribution**\n\n![](Deep%20Learning%20And%20Machine%20Learning/Model_interpretability/attachments/Pasted%20image%2020230329165840.png)\n\nNow Lundberg and Lee go on to describe a set of three desirable properties of such an additive feature method, **local accuracy**, **missingness**, and **consistency**.\n\n### Local accuracy\n\n$$\ng(x')\\approx f(x) \\quad \\text{if} \\quad x'\\approx x\n$$\n\n### Missingness\n\n$$\n{x_i}' = 0 \\rightarrow \\varphi_i = 0\n$$\n\nif a feature excluded from the model. it’s attribution must be zero; that is, the only thing that can affect the output of the explanation model is the inclusion of features, not the exclusion.\n\n### Consistency\n\nIf feature contribution changes, the feature effect cannot change in the opposite direction\n\n# Why SHAP\n\nLee and Lundberg in their paper argue that only SHAP satisfies all three properties if **the feature attributions in only additive explanatory model are specifically chosen to be the shapley values of those features**\n\n# SHAP, step-by-step Process, same as shap.explainer\n\nFor example, we consider a ice cream shop in the airport, it has four features we can know to predict his business.\n\n$$\n\\begin{bmatrix}\n\\text{temperature} \u0026 \\text{day of weeks} \u0026 \\text{num of flights} \u0026 \\text{num of hours}\n\\end{bmatrix}\n\\\\\n\\rightarrow \\\\\n\\begin{bmatrix}\nT \u0026 D \u0026 F \u0026 H\n\\end{bmatrix}\n$$\n\nFor, example, we want to know the temperature 80 in sample [80 1 100 4] shapley value, here’s the step\n\n- Step 1. Get random permutation of features, and give a bracket to the feature we care and everything in its right. (manually)\n\n$$\n\\begin{bmatrix}\nF \u0026 D \u0026 \\underbrace{T \\quad H}\n\\end{bmatrix}\n$$\n\n- Step 2. Pick random sample from dataset\n \nFor example, [200 5 70 8], form: [F D T H]\n\n- Step 3. Form vectors $x_1 \\quad x_2$\n\n$$\nx_1=[100 \\quad 1 \\quad 80 \\quad \\color{#BF40BF} 8 \\color{#FFFFFF}] \n$$\n\n$x_1$ is partially from original sample and partially from the random chosen one, the feature in bracket will from random chosen one, exclude what we care\n\n$$\nx_2 = [100 \\quad 1 \\quad \\color{#BF40BF} 70 \\quad  8 \\color{#FFFFFF}]\n$$\n\n$x_2$  just change the feature we care into the same as random chosen one’s feature value\n\nThen, calculate the diff and record\n\n$$\nDIFF = c_1 - c_2\n$$\n\n- Step 4. Record the diff \u0026 return to step 1. and repeat many times\n\n$$\n\\text{SHAP}(T=80 | [80 \\quad 1 \\quad 100 \\quad 4]) = \\text{average(DIFF)}\n$$\n\n# Shapley kernel\n\n## Too many coalitions need to be sampled\n\nLike we introduce shapley values above, for each $\\varphi_i$ we need to sample a lot of coalitions to compute the difference. \n\nFor 4 features, we need 64 total coalitions to sample; For 32 features, we need 17.1 billion coalitions to sample.\n\nIt’s entirely untenable.\n\nSo, to get over this difficulty, we need devise a **shapley kernel**, and that’s how the Lee and Lundberg do\n\n![](Deep%20Learning%20And%20Machine%20Learning/Model_interpretability/attachments/Pasted%20image%2020230329181956.png)\n\n## Detail\n![](Deep%20Learning%20And%20Machine%20Learning/Model_interpretability/attachments/Pasted%20image%2020230329182011.png)\n\nThough most of ML models won’t just let you omit a feature, what we do is define a **background dataset** B, one that contains a set of representative data points that model was trained over. We then filled in out omitted feature of features with values from background dataset, while holding the features are included in the permutation fixed to their original values. We then take the average of the model output over all of these new synthetic data point as our model output for that feature permutation which we call $\\bar{y}$.\n\n$$\nE[y_{\\text{12i4}}\\ \\  \\forall \\ \\text{i}\\in B] = \\bar{y}_{\\text{124}}\n$$ \n![](Deep%20Learning%20And%20Machine%20Learning/Model_interpretability/attachments/Pasted%20image%2020230329205039.png)\n\nThem we have a number of samples computed in this way,like image in left.\n\nWe can formulate this as a weighted linear regression, with each feature assigned a coefficient.\n\nAnd we can prove that, in the special choice, the coefficient can be the shaplely values. **This weighting scheme is the basis of the Shapley Kernal.** In this situation, the weighted linear regression process as a whole is Kernal SHAP.\n\n### Different types of SHAP\n\n- **Kernal SHAP**\n- Low-order SHAP\n- Linear SHAP\n- Max SHAP\n- Deep SHAP\n- Tree SHAP\n\n![](Deep%20Learning%20And%20Machine%20Learning/Model_interpretability/attachments/Pasted%20image%2020230329205130.png)\n\n### You need to notice\nWe can see that, we calculate shapley values using linear regression lastly. So there must be the error here, but some python packages can not give us the error bound, so it’s confusion to konw if this error come from linear regression or the data, or the model.\n\n\n# Reference\n\n[Shapley Additive Explanations (SHAP)](https://www.youtube.com/watch?v=VB9uV-x0gtg)\n\n[SHAP: A reliable way to analyze your model interpretability](https://towardsdatascience.com/shap-a-reliable-way-to-analyze-your-model-interpretability-874294d30af6)\n\n[【Python可解释机器学习库SHAP】：Python的可解释机器学习库SHAP](https://zhuanlan.zhihu.com/p/483622352)\n\n[Shapley Values : Data Science Concepts](https://www.youtube.com/watch?v=NBg7YirBTN8)\n\n# Appendix\n\nOther methods to interprete model:\n\n[Papers with Code - SHAP Explained](https://paperswithcode.com/method/shap)","lastmodified":"2023-04-17T12:12:39.68039879Z","tags":null},"/Hardware/Hardware_MOC":{"title":"Hardware - MOC","content":"\n# Microcontroller unit (MCU)\n\n## Basic concepts\n\n* [Different programming interfaces](Hardware/MCU/Different%20programming%20interfaces.md)\n","lastmodified":"2023-04-17T12:12:39.688398883Z","tags":null},"/Hardware/MCU/Different-programming-interfaces":{"title":"Different programming interfaces","content":"# What is programming interfaces in MCU\n\nA **programming interface** is a device that allows a programmer to connect to a microcontroller (MCU) and program it. The programming interface is used to load the program into the MCU’s memory and debug it.\n\n# Different types of programming interfaces in MCU\nChipmakers have different names for programming interfaces that all basically do the same thing:\n-   ISP - programming interface for Atmel (now Microchip) AVRs. SPI-like (MISO, MOSI, SCK, reset). It can be used for flash programming and debugging.\n-   PDI - newer programming interface for Atmel AVRs (eg. Xmega). Uses two wires (data and clock). Can do the same as ISP.\n-   DebugWire - yet another interface from Atmel (this one uses only a single wire)\n-   ICSP - programming interface for Microchip PIC line of MCUs\n-   SWD - Serial Wire Debug - programming interface for MCUs with ARM Cortex-M cores (uses two wires - data and clock)\n-   JTAG - very generic term, SPI-like interface used for [boundary scan](https://en.wikipedia.org/wiki/Boundary_scan), can also be used for programming/debugging MCUs (almost every vendor has its own protocol, so Cortex-M JTAG is not the same as AVR JTAG or Blackfin JTAG)\n-   Spy-Bi-Wire - yet another two wire programming interface, this one is for TI's MSP430 MCUs\n\n## SWD 和 JTAG的区别\n\n目前在使用的st link可以使用SWD和JTAG这两种debugger去调试stm32，所以这两种方式的区别令人比较在意；\n* JTAG（Joint Test Action Group，联合测试行动小组）是一种国际标准测试协议，主要用于芯片内部测试。现在多数的高级器件都支持JTAG协议，如ARM、DSP、FPGA器件等。JTAG调试接口必须使用VCC、GND电源信号，以及TMS、TCK、TDI、TDO四根调试信号，可选TRST、RESET复位信号和RTCK（同步时钟）信号。\n\t* TMS(Test Mode Select)：模式选择，TMS用来设置JTAG接口处于某种特定的测试模式；\n\t* TCK(Test Clock)：时钟输入；\n\t* TDI(Test Data Input)：数据输入，数据通过TDI引脚输入JTAG接口；\n\t* TDO(Test Data Output)：数据输出，数据通过TDO引脚从JTAG接口输出；\n* 串行调试（Serial Wire Debug），是一种和JTAG不同的调试模式，使用的调试协议也不一样，所以最直接的体现在调试接口上，与JTAG的20个引脚相比，SWD只需要4个（或者5个）引脚，结构简单，但是使用范围没有JTAG广泛，主流调试器上也是后来才加的SWD调试模式。\n\t* SWDIO：串行数据输入输出，作为仿真信号的双向数据信号线，建议上拉；\n\t* SWCLK：串行时钟输入，作为仿真信号的时钟信号线，建议下拉；\n\t* SWO：串行数据输出引脚，CPU调试接口可通过SWO引脚输出一些调试信息。该引脚是可选的；\n\t* RESET：仿真器输出至目标CPU的系统复位信号，该引脚也为可选\n\n* SWD模式比JTAG在高速模式下面更加可靠。在大数据量的情况下面JTAG下载程序会失败，但是SWD发生的几率会小很多。*基本使用JTAG仿真模式的情况下是可以直接使用SWD模式的，只要你的仿真器支持。*\n* 在GPIO刚好缺一个的时候，可以使用SWD仿真，这种模式支持更少的引脚。\n\n\n* 同时JTAG调试版本不同的情况下：\n\t* JTAGV6 需要的硬件接口为: GND, RST, SWDIO, SWDCLK；\n\t* JTAGV7 需要的硬件接口为: GND, RST, SWDIO, SWDCLK，相对V6， 其速度有了明显的提高，速度是 JTAGV6 的 6 倍。 \n\t* JTAGV8 需要的硬件接口为: VCC, GND, RST, SWDIO, SWDCLK，速度可以到 10M。\n\n\n\n# Reference\n\n[JTAG, SWD, EDBG, ICSP, ISP terms - Electrical Engineering Stack Exchange](https://electronics.stackexchange.com/questions/412029/jtag-swd-edbg-icsp-isp-terms)\n\n[jtag和swd的区别_jtag和swd区别_耶稣赞我萌的博客-CSDN博客](https://blog.csdn.net/yym6789/article/details/88721409)\n\n[STM32的JTAG和SWD模式_学术马的博客-CSDN博客](https://blog.csdn.net/w1050321758/article/details/108663603)\n","lastmodified":"2023-04-17T12:12:39.688398883Z","tags":null},"/Photography/Cameras_Research/Polaroid/Polaroid":{"title":"Polaroid","content":"\n# Polaroid Background\n\n![](Photography/Cameras_Research/Polaroid/attachments/Pasted%20image%2020230330195031.png)\n\nPolaroid是一家成立于1937年的美国相机及照片制造公司，该公司曾经是即时相机市场的领导者。Polaroid公司在20世纪50年代推出了第一台即时相机，并在随后的几十年里不断推出各种型号的即时相机和胶片，成为了全球广泛使用的品牌。\n\nPolaroid最著名的特点之一是它的“即时影像”技术，这种技术可以使用户在拍摄后几秒钟内看到他们所拍摄的照片。Polaroid的即时相机成为了许多人记录重要时刻和创造独特艺术作品的选择。\n\n除了即时相机，Polaroid还生产和销售其他相机、相机附件、数码相框和照片打印机等产品。此外，Polaroid还与其他品牌合作，推出了许多联名款式的相机和其他产品。\n\n在Polaroid成立近90年的历史中，它的相机和胶片已经成为了文化和艺术的象征，并继续影响着人们对摄影和影像创作的认知。\n\n# Polaroid Camera Review\n\n* [Polaroid one600](Photography/Cameras_Research/Polaroid/Polaroid_one600.md)\n* [Polaroid Integral 600 Series](Photography/Cameras_Research/Polaroid/Polaroid_600.md)\n","lastmodified":"2023-04-17T12:12:39.688398883Z","tags":null},"/Photography/Cameras_Research/Polaroid/Polaroid_600":{"title":"Polaroid 600","content":"\n# Reference\n\n* [How do I use my Vintage Polaroid 600 camera? – Retrospekt](https://retrospekt.com/blogs/ask-the-expert/how-do-i-use-my-vintage-polaroid-600-instant-camera)\n* [Polaroid Integral 600 Series - Camera-wiki.org - The free camera encyclopedia](http://camera-wiki.org/wiki/Polaroid_Integral_600_Series)\n","lastmodified":"2023-04-17T12:12:39.688398883Z","tags":null},"/Photography/Cameras_Research/Polaroid/Polaroid_one600":{"title":"Polaroid_one600","content":"\n\n![](Photography/Cameras_Research/Polaroid/attachments/Pasted%20image%2020230330195707.png)\n\n# Specifications\n\n- **(Wide) 100mm lens with minimum focus distance of 3 feet.**\n- **Maximum Aperture F12.9 (Don't know if it can change)**\n- **1/200 s to 1/3 s**\n- **Fixed focus.**\n- Exposure modes - **Program automatic**\n- \"Aerodynamic\" styling (particularly when folded) with downward curve at back.\n- Flash moved to right hand side of user and can be manually switched on and off.\n- Hand grip on right.\n- LCD frame counter.\n- Self-timer.\n\n## Functionally similar models\n\n-   Polaroid One (silver/grey)\n-   Polaroid One600 Job Pro (black/silver/yellow) (Close-focus to 18 inches!)\n-   Polaroid One600 Nero (all black)\n-   Polaroid One600 \"Flowers\" (white with purple and yellow flower design)\n-   Polaroid One600 Panna (white/black)\n-   Polaroid One600 \"Poison Frog\" (silver/grey with yellow/black pattern)\n-   Polaroid One600 Polala 2006 (red/silver with gold Chinese dragon)\n-   Polaroid One600 Pro (all silver) (Like Job Pro, close-focus to 18 inches!)\n-   Polaroid One600 Royksopp (grey/silver with 'Royksopp - Only This Moment' branding)\n-   Polaroid One600 Superheadz Special Edition Red Hat (silver/black, with 'red hat' cartoon character)\n-   Polaroid One600 Rossa (bright red/black)\n-   Polaroid One Rossa (as above)\n-   Polaroid One Ultra (silver/black) (Close focus to 2 feet)\n-   Polaroid Pop Kit (silver/black with stickers for user's customization)\n\n# Reference\n\n* [Polaroid One 600 Camera Review - by Dan Finnen](https://danfinnen.com/review/polaroid-one-600-camera-review/)\n* [Polaroid One600 (Classic) - Camera-wiki.org - The free camera encyclopedia](http://camera-wiki.org/wiki/Polaroid_One600_(Classic))\n","lastmodified":"2023-04-17T12:12:39.688398883Z","tags":null},"/Photography/Photography_MOC":{"title":"Photography - MOC","content":"\n# 🌊Photo Portfolio\nYou can see my photography works in:\n\n* [🎨Slide show](https://pinkr1ver.com/PhotoGallery/)\n* [🌄Photo Collection in Notion](https://www.notion.so/pinkr1ver/3cfdd332b9a94b20bca041f2aa2bdcd2?v=24e696e6ab754386a710bc8e83976357)\n* [🍻Instagram](https://www.instagram.com/jude.wang.yc/?next=%2F)\n* [🧶小红书](https://www.xiaohongshu.com/user/profile/6272c025000000002102353b)\n\n# Notes\nAlso, here's my notes about learning photography\n\n## About Basic Concepts:\n\n* [Saturation](Photography/Saturation.md)\n\n## Appreciation of other works - about ***aesthetic***\n\n* [👧Portrait](Photography/Portrait.md)\n* [☝Style](Photography/Style/Style_MOC.md)\n\n## Camera Research\n\n* [✨Polaroid](Photography/Cameras_Research/Polaroid/Polaroid.md)\n\n## Skills I learned\n\n* [How to measure light using Polaroid?](Photography/Skills/Polaroid_light.md)\n\n## Photography story\n\n* [夜爬蛤蟆峰拍Polaroid慢门 - 2023.04.14](Photography/Story/Rainy_evening_hiking_Polaroid.md)\n\n# Reference\n\n## Platform\n\n* [Magnum Photos](https://www.magnumphotos.com/)\n* [CNU - Catch Next Ultimate](http://www.cnu.cc/)\n\n## Greatest Artist\n\n* [linksphotograph](https://www.linksphotograph.com/)\n* [HAMADA Hideaki / 濱田英明](https://www.hideakihamada.com)\n* [Jason Kummerfeldt](https://graincheck.darkroom.com/) and [his youtube](https://www.youtube.com/@grainydaysss)\n* [Nguan](https://nguan.tv/)\n* [Marta Bevacqua](https://www.martabevacquaphotography.com/)\n* [Sam Zhang](https://www.instagram.com/itscapturedbysam/)\n\n## Content Collector \u0026 Photographer\n\n* [🦺搬运UP主 - 豆腐素包](https://space.bilibili.com/196700312/video)\n* [小八怪 - 小红书](https://www.xiaohongshu.com/user/profile/5558b47f5894463d532a632c)","lastmodified":"2023-04-17T12:12:39.692398929Z","tags":null},"/Photography/Portrait":{"title":"👧Portrait","content":"\n* [🌸Flower \u0026 Girl](Photography/Portrait/Flower_and_Girl.md)\n* [🇰🇷Cute Portrait from Korean MV \u003cToday's Mood\u003e](Photography/Portrait/From%20Korean%20MV%20Todays_Mod.md)\n","lastmodified":"2023-04-17T12:12:39.692398929Z","tags":null},"/Photography/Portrait/Flower_and_Girl":{"title":"🌸Flower \u0026 Girl","content":"\nCredits to [Marta Bevacqua](https://www.martabevacquaphotography.com/), \nThanks🌸\n\n![](Photography/Portrait/attachments/14.jpg)\n\n![](Photography/Portrait/attachments/15.jpg)\n\n![](Photography/Portrait/attachments/16.jpg)\n\n![](Photography/Portrait/attachments/17.jpg)\n\n![](Photography/Portrait/attachments/18.jpg)\n\n![](Photography/Portrait/attachments/19.jpg)\n\n![](Photography/Portrait/attachments/20.jpg)\n\n![](Photography/Portrait/attachments/21.jpg)\n\n![](Photography/Portrait/attachments/22.jpg)\n\n![](Photography/Portrait/attachments/content%20(1).jpg)\n\n![](Photography/Portrait/attachments/content%20(2).jpg)\n\n![](Photography/Portrait/attachments/content%20(3).jpg)\n\n![](Photography/Portrait/attachments/content%20(4).jpg)\n\n![](Photography/Portrait/attachments/content%20(5).jpg)\n\n![](Photography/Portrait/attachments/content%20(6).jpg)\n\n![](Photography/Portrait/attachments/content%20(7).jpg)\n\n![](Photography/Portrait/attachments/content%20(8).jpg)\n\n![](Photography/Portrait/attachments/content%20(9).jpg)\n\n![](Photography/Portrait/attachments/content%20(11).jpg)\n\n![](Photography/Portrait/attachments/content%20(12).jpg)\n\n![](Photography/Portrait/attachments/content.jpg)\n\n","lastmodified":"2023-04-17T12:12:39.692398929Z","tags":null},"/Photography/Portrait/From-Korean-MV-Todays_Mod":{"title":"Cute Portrait from Korean MV \u003cToday's Mood\u003e","content":"\nCredits to [MV - CHEEZE(치즈) _ Today's Mood(오늘의 기분)](https://www.youtube.com/watch?v=zRq_DlEzygk),\nThanks\n\nAlso, I see this in [摄影灵感｜那有一点可爱 - by   \n小八怪](https://www.xiaohongshu.com/explore/63f0a27e0000000013002b05)\n\n![](Photography/Portrait/attachments/photo_4_2023-03-27_23-53-20.jpg)\n\n![](Photography/Portrait/attachments/photo_5_2023-03-27_23-53-20.jpg)\n\n![](Photography/Portrait/attachments/photo_6_2023-03-27_23-53-20.jpg)\n\n![](Photography/Portrait/attachments/photo_7_2023-03-27_23-53-20.jpg)\n\n![](Photography/Portrait/attachments/photo_8_2023-03-27_23-53-20.jpg)\n\n![](Photography/Portrait/attachments/photo_9_2023-03-27_23-53-20.jpg)\n\n![](Photography/Portrait/attachments/photo_1_2023-03-27_23-53-20%201.jpg)\n\n![](Photography/Portrait/attachments/photo_2_2023-03-27_23-53-20%201.jpg)\n\n![](Photography/Portrait/attachments/photo_3_2023-03-27_23-53-20%201.jpg)\n\n![](Photography/Portrait/attachments/photo_2023-03-27_23-55-45.jpg)","lastmodified":"2023-04-17T12:12:39.692398929Z","tags":null},"/Photography/Saturation":{"title":"Saturation - 饱和度","content":"\nto be written...","lastmodified":"2023-04-17T12:12:39.708399114Z","tags":null},"/Photography/Skills/Polaroid_light":{"title":"How to measure light using Polaroid?","content":"\nThe most thing you need to know is that, **the right exposure is in your head**.\n\n# Basic\n\n\n\n# Practice\n\n\n# Reference\n\n* [How to EXPOSE your POLAROID PICTURE - Youtuber Analog Things](https://www.youtube.com/watch?v=iqU5YRG8WiE)\n\n","lastmodified":"2023-04-17T12:12:39.708399114Z","tags":null},"/Photography/Story/Rainy_evening_hiking_Polaroid":{"title":"夜爬蛤蟆峰拍Polaroid慢门 - 2023.04.14","content":"\n# Hiking\n\n周五，周潭来杭，计划去蛤蟆峰顶拍拍立得慢门，记录西湖夜景。\n\n晚饭后，雨渐起，兴致不减，亦去。\n\n山底已经在小雨中颇有丁达尔现象的感觉。\n\n![](Photography/Story/attachments/9970714720C0835E6547C263418D551B.jpg)\n\n雨让石头逐渐变得打滑，蛤蟆峰山顶的石头快的攀登会变得非常危险，这一点难以描述，或许你可以问你杭州本地的朋友。周潭在攀登最后一段路程之前摔倒，还好背包缓冲了几乎所有的冲撞，也让他意识到雨天来到这里的危险性，是具有极限运动的底色在的。\n\n最后，在小心翼翼中，登顶了。\n\n# Photographer\n\n在蛤蟆峰顶拍慢门需要一定的三脚架架设技巧和测光技巧，在雨中就显得更加困难。\n\n![](Photography/Story/attachments/QQ视频20230416012046.mp4)\n\n![](Photography/Story/attachments/FCB8B96468D3B459532E010E865D0B99.jpg)\n\n\n经过测光和宝丽来app曝光调整，这次拍摄夜景的计划以$f/22$, 30s shutter speed, i-type film 640 ISO进行拍摄，先看成片效果：\n\n![](Photography/Story/attachments/IMG_5553.jpg)\n\n照片由iPhone 12 mini Polaroid app scanner扫描完成的film -\u003e digital，效果比较一般，但我们能看出，曝光的效果不尽人意。这里的原因认为由以下原因导致：\n* 天气恶劣，空气湿度大，造成光线色散加重\n* 没有考虑i-type相纸**倒易率**，曝光时间不足（重要原因🚧🚧🚧）\n* 没有查询Polaroid now+镜头最好的光学素质的参数，自认为是$f/22$，导致曝光时间过长导致的点光源色散严重。（目前还没有查询到Polaroid now+镜头的光学参数曲线🚧🚧🚧）\n\n同时，那晚还不懂now+ +键的使用导致相纸浪费一张，下面是now+中+键的用法：\n\n![](Photography/Story/attachments/Pasted%20image%2020230416014050.png)\n\n同时，那晚曝光时，有一次光圈不小心打到$f/33$，导致欠曝地更为厉害，其效果大概如下：\n\n![](Photography/Story/attachments/IMG_5550.jpg)\n\n同时要注意的是，Polaroid的曝光时间最多是30s，如果要更长时间的曝光，可以不弹相纸进行二次曝光，但是长曝光30s以上可能效果很差。\n\n## 人像\n\n搞了两张人像，同样的曝光参数$f/22$, 30s shutter speed, i-type film 640 ISO，开了宝丽来闪关灯最大等级：\n\n![](Photography/Story/attachments/IMG_5492.jpg)\n\n\n![](Photography/Story/attachments/IMG_5493.jpg)\n\n一张人像清晰些，以我个人观点来看，是因为伞造成的反射\n\n# 返程\n\n返程的","lastmodified":"2023-04-17T12:12:39.708399114Z","tags":null},"/Photography/Style/Polaroid_showcase":{"title":"How to show Polaroid photo in a great way","content":"\n\n\n![](Photography/Style/attachments/IMG_5330.jpg)\n\n\n\n![](Photography/Style/attachments/IMG_5329.jpg)\n\n\n\n![](Photography/Style/attachments/IMG_5327.jpg)\n\n\n\n![](Photography/Style/attachments/IMG_5334.jpg)\n\nCredits to  [比扫描仪更easy的宝丽来翻拍解决方案 -BonBon的Pan](https://www.xiaohongshu.com/user/profile/6272c025000000002102353b/6331af53000000001701acfd)","lastmodified":"2023-04-17T12:12:39.764399763Z","tags":null},"/Photography/Style/Style_MOC":{"title":"☝Style","content":"\n* [🌅Warmth - Nguan](Photography/Style/Warmth_by_Nguan.md)\n* [🖼How to show Polaroid photo in a great way](Photography/Style/Polaroid_showcase.md)\n\n","lastmodified":"2023-04-17T12:12:39.764399763Z","tags":null},"/Photography/Style/Warmth_by_Nguan":{"title":"🎈Warmth - Nguan","content":"\nCredits to [Nguan](https://www.instagram.com/_nguan_/)\n\n\n![](Photography/Style/attachments/167396766_118928406833773_7462235788758622009_n.jpg)\n\n![](Photography/Style/attachments/275801921_507726407459443_2779968335661218284_n.jpg)\n\n![](Photography/Style/attachments/275101252_116346090976633_4116581661408205933_n.jpg)\n\n\n![](Photography/Style/attachments/152391470_356387755409221_8144178651765781801_n.jpg)\n\n\n![](Photography/Style/attachments/153386473_426909131936316_8535520818773302544_n.jpg)\n\n\n![](Photography/Style/attachments/156216827_337435770999537_8250898900544979316_n.jpg)\n\n\n","lastmodified":"2023-04-17T12:12:39.764399763Z","tags":null},"/Physics/Electromagnetism/Basic/Electric_units":{"title":"Electric Units","content":"# Electrical impedance\n\n$$\nZ = \\sqrt{R^2 + {(X_L-X_C)}^2}\n$$\n\n\n* $Z$ = impedance\n* $R$ = resistance\n* $X_L$  = inductive reactance\n* $X_C$  = capacitive reactance\n\n![](Physics/Electromagnetism/Basic/attachments/Pasted%20image%2020230330163734.png)\n\n**阻抗**是电路中电阻、电感、电容对交流电的阻碍作用的统称。阻抗是一个复数，实部称为**电阻**，虚部称为**电抗**；其中电容在电路中对交流电所起的阻碍作用称为**容抗**，电感在电路中对交流电所起的阻碍作用称为**感抗**，容抗和感抗合称为**电抗**。\n\n阻抗将电阻的概念加以延伸至交流电路领域，不仅描述*电压与电流的相对振幅*，也描述其*相对相位*。当通过电路的电流是直流电时，电阻与阻抗相等，电阻可以视为相位为零的阻抗。\n\n## 形式\n\n1. $R+jX$\n2. $Z_m\\angle\\theta$\n3. $Z_m e^{j\\theta}$\n\n阻抗定义为电压与电流的频域比率。阻抗的大小$Z_{m}$ 是电压振幅与电流振幅的绝对值比率，阻抗的相位 $\\theta$是电压与电流的相位差。\n\n## 欧姆定律\n\n$$\nv = iZ = iZ_m e^{j\\theta}\n$$\n\n阻抗大小$Z_m$的作用恰巧就像电阻，设定电流$i$，就可以计算出阻抗$Z$两端的电压降$v$。相位因子$e^{j\\theta}$则是电流滞后于电压的相位差$\\theta$ \n\n\u003e [!tip] \n\u003e 在时域中，电流信号会比电压信号慢$\\theta T/2\\pi$秒\n\n## 理想的阻抗\n$$\nZ_R = R\n$$\n\n$$\nZ_C = \\frac{1}{j\\omega C}\n$$\n\n$$\nZ_L = j \\omega L\n$$\n\n* 对于电容，交流电压滞后90°于交流电流；\n* 对于电感，交流电压超前90°于交流电流\n\n### 容抗\n\n$$\nX_C = -j/\\omega C\n$$\n随着$\\omega$趋向于0，电源趋向于直流电源，容抗的绝对值趋向于无穷；*因此，在低频率运作时，电容器貌似断路。假设电源的频率越高，则容抗越低，对于电流通过的阻碍也越低。在高频率运作时，电容器貌似短路。*\n\n### 阻抗\n\n$$\nX_L = j\\omega L\n$$\n从这方程可以观察到，当交流电源的角频率趋向于零时，电源会趋向于直流电源，感抗会趋向于零，对于电流的通过阻碍越低。*所以，在低频率运作时，电感器貌似短路。假设电源角频率越高，则感抗越高，假设给定电压源振幅，则电流会趋向于零。所以，在高频率运作时，电感器貌似断路。*\n\n\n# Reference\n\n[电气单位（V，A，Ω，W，...） (rapidtables.org)](https://www.rapidtables.org/zh-CN/electric/Electric_units.html)\n","lastmodified":"2023-04-17T12:12:39.772399856Z","tags":null},"/Physics/Electromagnetism/Electromagnetism_MOC":{"title":"Electromagnetism MOC","content":"\n# Basic\n\n* [Electric units](Physics/Electromagnetism/Basic/Electric_units.md)\n\n## Advanced\n\n* [Maxwell's equation](Physics/Electromagnetism/Maxwells_equation.md)\n\n# Circuit\n\n* [Resonant circuit](Physics/Electromagnetism/Resonant_circuit.md)","lastmodified":"2023-04-17T12:12:39.772399856Z","tags":null},"/Physics/Electromagnetism/Maxwells_equation":{"title":"Maxwell's Equation","content":"\n# Equation\n\n\n$$\n\\nabla \\cdot E = \\frac{\\rho}{\\epsilon_0}\n$$\n\n$$\n\\nabla \\cdot B = 0\n$$\n\n$$\n\\nabla \\times E = -\\frac{\\partial B}{\\partial t}\n$$\n\n$$\n\\nabla \\times B = \\mu_0 (J + \\epsilon_0 \\frac{\\partial E}{\\partial t})\n$$\n\n# Vector field\n\nEssentially a vector field is what you get if you associate each point in space with a vector, some magnitude and direction. Maybe those vectors represent the velocities of particles of fluid at each point in space or maybe they represent the force of gravity at many different points in space or maybe a magnetic field strength.\n\n\u003e [!note] \n\u003e  If you were to draw the vectors to scale, the longer ones end up just cluttering the whole thing, so it's common to basically lie a little and artificially shorten ones that are too long. Maybe using **color to give some vague sense of length**.\n\n![](Physics/Electromagnetism/attachments/Pasted%20image%2020230411151612.png)\n\n## Divergence\n\n![](Physics/Electromagnetism/attachments/my-life.gif)\n\nDivergence $\\cdot$ Vector filed是来衡量在(x, y)点你产生fluid的能力\n\n所以上述图中，产生fluid的source点，他们的Divergence $\\cdot$ Vector filed是positive的\n\n那些fluid流入的sink端，他们的Divergence $\\cdot$ Vector filed就是negative的\n\n![](Physics/Electromagnetism/attachments/Pasted%20image%2020230411155711.png)\n\n同时，如果点可以slow flow in变fast slow out，这个点位的divergence $\\cdot$ vector filed也是positive的\n\n![](Physics/Electromagnetism/attachments/my-life%201.gif)\n\nVector field input point得到的是一个多维的输出，指向一个方向并带有scale；divergence $\\cdot$ vector field，它的输出depends on the behavior of the field in small neighborhood around that point。输出为一个数值，衡量这个point acts as a source or a sink\n\n![](Physics/Electromagnetism/attachments/Pasted%20image%2020230411161346.png)\n\n\u003e [!note] \n\u003e  For actual fluid flow: $\\text{div} F = 0$ everywhere\n\n## Curl\n\n![](Physics/Electromagnetism/attachments/output%202.gif)\n\nCurl是衡量fluid在point被rotate的程度，clockwise方向是positive curl，counterclockwise是negative curl。\n\n![](Physics/Electromagnetism/attachments/curl.gif)\n\n上图中这个点的curl也是非零的，因为fluid上快下慢，result in clockwise influence\n\n## Calculate divergence and curl\n\n$$\n\\text{div} F = \\nabla \\cdot F = \n\\begin{bmatrix}\n\\frac{\\partial}{\\partial x} \\\\\n\\frac{\\partial}{\\partial y}\n\\end{bmatrix} \\cdot\n\\begin{bmatrix}\nF_x \\\\\nF_y\n\\end{bmatrix} = \\frac{\\partial F_x}{\\partial x} + \\frac{\\partial F_y}{\\partial y}\n$$\n\n$$\n\\text{curl} F = \\nabla \\times F = \n\\begin{bmatrix}\n\\frac{\\partial}{\\partial x} \\\\\n\\frac{\\partial}{\\partial y}\n\\end{bmatrix} \\times\n\\begin{bmatrix}\nF_x \\\\\nF_y\n\\end{bmatrix}\n= \\frac{\\partial F_y}{\\partial x} - \\frac{\\partial F_x}{\\partial y}\n$$\n\n![](Physics/Electromagnetism/attachments/calculation_result.gif)\n\n### Detail Explanation\n\n![](Physics/Electromagnetism/attachments/Pasted%20image%2020230412144351.png)\n\n![](Physics/Electromagnetism/attachments/Pasted%20image%2020230412144501.png)\n\n在$(x_0, y_0)$微分一个很小的tiny step，会有一个新的vector，它与原有的vector会有一个difference。\n\n![](Physics/Electromagnetism/attachments/div.gif)\n\n$\\text{div} F(x_0, y_0)$其实就是corresponds to $360^\\circ$方向的average的Step $\\cdot$ Difference\n\n可以想象一个source端，它朝四面发射vector，它的Step $\\cdot$ Difference自然就是positive的\n\n![](Physics/Electromagnetism/attachments/Pasted%20image%2020230412145732.png)\n\n同理，不难想象的是，$\\text{curl} F(x_0, y_0)$是corresponds to Step $\\times$ Difference\n\n# Understand Maxwell's Equation\n\n学会vector filed中的divergence和curl，是理解Maxwell’s Equation的关键\n\n## Gauss's Law\n\n$$\n\\text{div} E = \\frac{\\rho}{\\epsilon_0}\n$$\n\n\n![](Physics/Electromagnetism/attachments/Pasted%20image%2020230411163735.png)\n\n* $\\rho$是charge density\n* $\\epsilon_0$是Epsilon Naught，free space的介电常数，它决定free space空间中电场的强度\n\n\u003e [!note] \n\u003e 形象的\n\u003e \n\u003e Gauss's law stating that **divergence of an electric field at a given point is a proportional to the charge density at that point**. \n\u003e \n\u003e **Positively charged regions as acting like sources** of some imagined fluid and n**egatively charged regions as being the sinks** of that fluid.\n\u003e \n\u003e Parts of space where there is on charge the fluid **would be flowing incompressively** just like water.\n\n\n## Gauss's law for magnetism\n\n$$\n\\text{div} B = 0\n$$\n\n![](Physics/Electromagnetism/attachments/Pasted%20image%2020230411165048.png)\n\n磁场的divergence在任意地方为0，说明磁场的fluid是incompressible的，没有source也没有sinks，就像water一样。也有这样的interpretation，说明magnetic monopoles是不存在的\n\n## Maxwell–Faraday equation (Faraday's law of induction)\n\n$$\n\\nabla \\times E = - \\frac{1}{c} \\frac{\\partial B}{\\partial t}\n$$\n\n## Ampère's circuital law (with Maxwell's addition)\n\n$$\n\\nabla \\times B = \\frac{1}{c} (4\\pi J + \\frac{\\partial E}{\\partial t})\n$$\n\n\n# Reference\n\n* [Fun fluid-flow illustrations - by 3B1B](https://anvaka.github.io/fieldplay/?cx=0\u0026cy=0\u0026w=8.5398\u0026h=8.5398\u0026dt=0.01\u0026fo=0.998\u0026dp=0.009\u0026cm=1\u0026vf=%2F%2F%20p.x%20and%20p.y%20are%20current%20coordinates%0A%2F%2F%20v.x%20and%20v.y%20is%20a%20velocity%20at%20point%20p%0Avec2%20get_velocity%28vec2%20p%29%20%7B%0A%20%20vec2%20v%20%3D%20vec2%280.%2C%200.%29%3B%0A%0A%20%20%2F%2F%20change%20this%20to%20get%20a%20new%20vector%20field%0A%20%20v.x%20%3D%20p.y%3B%0A%20%20v.y%20%3D%20%28max%28cos%28sin%28p.y%29%29%2Csin%28p.y%29%2Fp.y%29%2Bp.y%29%3B%0A%0A%20%20return%20v%3B%0A%7D\u0026code=%2F%2F%20p.x%20and%20p.y%20are%20current%20coordinates%0A%2F%2F%20v.x%20and%20v.y%20is%20a%20velocity%20at%20point%20p%0Avec2%20get_velocity%28vec2%20p%29%20%7B%0A%20%20vec2%20v%20%3D%20vec2%280.%2C%200.%29%3B%0A%0A%20%20%2F%2F%20change%20this%20to%20get%20a%20new%20vector%20field%0A%20%20v.x%20%3D%20%28max%28p.x%2Cp.y%29%2Bmax%28p.y%2Cp.x%29%29%3B%0A%20%20v.y%20%3D%20p.y%3B%0A%0A%20%20return%20v%3B%0A%7D)\n* [Divergence and curl: The language of Maxwell's equations, fluid flow, and more - YouTube vedio by 3b1b](https://www.youtube.com/watch?v=rB83DpBJQsE)\n* [Let There Be Light: Maxwell's Equation EXPLAINED for BEGINNERS - YouTube vedio by Parth G](https://www.youtube.com/watch?v=0jW74lrpeM0)","lastmodified":"2023-04-17T12:12:39.772399856Z","tags":null},"/Physics/Electromagnetism/Q_factor":{"title":"Q factor","content":"\n# Explanation\n\nIn physics and engineering, the quality factor or Q factor is a **dimensionless** parameter that describes how **underdamped** an oscillator or *resonator* is. It is defined as the ratio of the initial energy stored in the resonator to the *energy lost* in one radian of the cycle of oscillation. Q factor is alternatively defined as the ratio of a *resonator's center frequency to its bandwidth* when subject to an oscillating driving force. These two definitions give *numerically similar*, but not identical, results. \n\n\u003e [!tip] \n\u003e  高Q因子表示振子能量损失的速率较慢，振动可持续较长的时间; 单摆在空气中Q因子较高而在油中较低\n\n\n\n![](Physics/Electromagnetism/attachments/Pasted%20image%2020230404144801.png)\u003cfont size=1\u003eFig. A damped oscillation. A low Q factor – about 5 here – means the oscillation dies out rapidly.\u003c/font\u003e\n\n\nQ因子较高的振子在共振时，在共振频率附近的**振幅较大**，但会产生的共振的**频率范围比较小**，此频率范围可以称为频宽。\n\n例如一台无线电接收器内的调谐电路Q因子较高，要调整接收器对准一特定频率会比较困难，但其选择性较好，在过滤频谱上邻近电台的讯号上也有较佳的效果。\n\n系统的Q因子可能会随著应用场合及需求的不同而有大幅的差异。*强调阻尼特性的系统*（例如[防止门突然关闭的阻尼器](warehouse/dampers_keeping_a_door_from_slamming%20shut.md)）*其Q因子为1⁄2*，而时钟、雷射或是其他需要强烈共振或是要求频率稳定性的系统其Q因子也较高。音叉的Q因子大约为1000，原子钟、加速器中的超导射频或是光学共振腔的Q因子可以到$10^{11}$\n\n\u003e [!help] \n\u003e  There are many *alternative quantities* used by physicists and engineers to describe how damped an oscillator is. Important examples include: the [damping ratio](https://en.wikipedia.org/wiki/Damping_ratio \"Damping ratio\"), [relative bandwidth](https://en.wikipedia.org/wiki/Bandwidth_(signal_processing) \"Bandwidth (signal processing)\"), [linewidth](https://en.wikipedia.org/wiki/Oscillator_linewidth \"Oscillator linewidth\") and bandwidth measured in [octaves](https://en.wikipedia.org/wiki/Octave_(electronics) \"Octave (electronics)\").\n\n\n# Definition\n\n![](Physics/Electromagnetism/attachments/Pasted%20image%2020230404151254.png)\n\n\u003cfont size=1\u003eFig. 一阻尼谐振子的频宽, $\\Delta f$可以用频率和能量的图来表示。阻尼谐振子（或滤波器）的Q因子为$f_{0}/\\Delta f$。Q因子越大，其波峰高度会越高，而其宽度会越窄\u003c/font\u003e\n\nIn the context of resonators, there are two common definitions for Q, which aren't exactly equivalent. They become approximately equivalent *as Q becomes larger*, meaning the resonator becomes less damped.\n\n## Bandwidth definition\n\n$$Q\\stackrel{def}{=}\\frac{f_r}{\\Delta f}=\\frac{\\omega_r}{\\Delta \\omega}$$\n\n$f_r$为共振频率，$\\Delta f$为频宽，一般是 [full width at half maximum](https://en.wikipedia.org/wiki/Full_width_at_half_maximum \"Full width at half maximum\") (FWHM)\n\n## Stored energy definition\n\nQ因子可定义为在一系统的共振频率下，当信号振幅不随时间变化时，**系统储存能量和每个周期外界所提供能量的比例**（此时系统储存能量也不随时间变化）\n\n$$Q = 2\\pi \\times \\frac{\\text{Energy Stored}}{\\text{Energy dissipated per cycle}}=2\\pi f_r \\times \\frac{\\text{Energy Stored}}{\\text{Power Loss}}$$\n\n同时在像电感等储能元件的规格中，会用到和频率有关的Q因子，其定义如下\n\n$$Q(\\omega) = \\omega \\times \\frac{\\text{Maximum Energy Stored}}{\\text{Power Loss}}$$\n\n其中$\\omega$是计算储存能量和功率损失时的角频率\n\n\n# Reference\n\n* [Q factor in  wiki](https://en.wikipedia.org/wiki/Q_factor)\n* [品质因子](https://zh.wikipedia.org/zh-hans/%E5%93%81%E8%B3%AA%E5%9B%A0%E5%AD%90#:~:text=%E5%93%81%E8%B4%A8%E5%9B%A0%E5%AD%90%E6%88%96Q%E5%9B%A0%E5%AD%90,%E6%91%86Q%E5%9B%A0%E5%AD%90%E8%BE%83%E4%BD%8E%E3%80%82)","lastmodified":"2023-04-17T12:12:39.772399856Z","tags":null},"/Physics/Electromagnetism/Resonant_circuit":{"title":"Resonant circuit","content":"\n以RLC串联电路为例\n\n# 什么是谐振\n\n电路中电容器$L$、电感器$C$两组件之能量相等，当能量由电路中某一电抗组件释出时，且另一电抗组件必吸收相同之能量，即此两电抗组件间会产生一能量脉动。\n\n# 两种简单的谐振电路\n![](Synthetic%20Aperture%20Radar%20Imaging/attachments/Pasted%20image%2020230330160535.png)\n\n\n以串联谐振为例\n\n## *Resonant Frequency*\n\n电容，电阻的[电抗](Physics/Electromagnetism/Basic/Electric_units.md#Electrical%20impedance)相同时发生谐振\n\n$$\n|X_C| = |\\frac{1}{j2\\pi fC}| = |X_L| = |j2\\pi fL|\n$$\nRearranging,\n\n$$\nf^2 =  \\frac{1}{(2\\pi)^2 C L}\n$$\n\n$$\nf = \\frac{1}{2\\pi \\sqrt{LC}}\n$$\n\n## 串联谐振特性\n\n* 阻抗最小，且为纯电阻，$Z = R+jXL-jXC = R$ \n\n## **品质因子** ([*Q factor*](Physics/Electromagnetism/Q_factor.md))\n\n* 电感器或电容器在谐振时产生的电抗功率与电阻器消耗的平均功率之比，称为谐振时之品质因子。\n\n$$Q=\\frac{Q_L}{P}=\\frac{I^2X_L}{I^2R}=\\frac{Q_C}{P}=\\frac{I^2X_C}{I^2R}=\\frac{1}{R}\\sqrt{\\frac{L}{C}}=\\frac{\\sqrt{X_LX_C}}{R}$$\n\n#### 阻抗与频率的关系\n\n$Z = R + j(X_L-X_C)$\n* 当$f＝f_r$时，$Z＝R$为最小值，电路为电阻性；\n* 当$f＞f_r$时，$X_L＞X_C$为最小值，电路为电感性；\n* 当$f＜f_r$时，$X_L＜X_C$为最小值，电路为电容性。\n","lastmodified":"2023-04-17T12:12:39.772399856Z","tags":null},"/Physics/Physics_MOC":{"title":"Physics MOC","content":"\n* [Electromagnetism MOC](Physics/Electromagnetism/Electromagnetism_MOC.md)","lastmodified":"2023-04-17T12:12:40.680410375Z","tags":null},"/Report/2023.04.16-%E5%A4%A9%E7%BA%BF%E6%B5%8B%E8%AF%95":{"title":"2023.04.16 天线测试","content":"\n 对天线进行测距能力的测试\n\n# 背景\n\n![](Report/attachments/96251ac46494ab01294e570e352c426.png)\n\n# 测试结果\n\n## 无穷远距离测量\n\n前方30cm内无反射，超出本雷达测距能力极限，近似为无穷远距离内无反射，得到收集端电压\n\n![](Report/attachments/7983094eb03d1dcc285edf9c1768018.png)\n\n以前的天线收集的数据：\n\n![](Report/attachments/f5d557933b15f8ea7f6861f70663d13.png)\n\n问题在于两点：\n\n* 目前天线稳定性不足\n* 核心信号峰值下降为1.7v左右，而之前核心信号为2.2v\n\n## 实时测距实验\n\n*实时测距实验为在天线段实时测量信号并在前面按照时间放置金属挡板检测天线的测距能力。*\n\n实验大致的放置时间为：\n1. 0-25s，不放置金属挡板\n2. 25-50s，金属挡板贴紧天线\n3. 50-75s，不放置金属挡板\n4. 75-100s，在10cm处放置金属挡板\n5. 100-125s，不放置金属挡板\n6. 125-150s，在20cm处放置金属挡板\n7. 175-200s，不放置金属挡板\n8. 150-175s，在30cm处放置金属挡板\n\n新天线收集数据：\n\n![](Report/attachments/abaec3368e16f2c9be67b5edbba39be.png)\n\n旧天线收集信号：\n\n![](Report/attachments/ac4c5aa53392835d3db04a78e73476b.png)\n\n问题在于：\n\n* 新天线信号不稳定，与无穷远测试中的结果吻合。\n* 导致了不同距离的信号区分度丧失\n","lastmodified":"2023-04-17T12:12:40.680410375Z","tags":null},"/Signal-Processing/Basic-Concepts-in-Signal-Processing":{"title":"Basic Concepts in Signal Processing","content":"\n* [What is dB](Signal%20Processing/What%20is%20dB.md)","lastmodified":"2023-04-17T12:12:40.684410422Z","tags":null},"/Signal-Processing/Signal-Processing_MOC":{"title":"Signal Processing - MOC","content":"\n* [Basic Concepts in Signal Processing](Signal%20Processing/Basic%20Concepts%20in%20Signal%20Processing.md)\n","lastmodified":"2023-04-17T12:12:40.684410422Z","tags":null},"/Signal-Processing/What-is-dB":{"title":"What is dB","content":"dB is short for decibel, which is a unit that indicates ratio or gain. It is often used to measure *sound intensity*, *signal strength*, *attenuation* and other quantities. \n\nFor example, if a sound has a power of 10 W and another sound has a power of 1 W, then the difference in decibels is 10 dB = 10 log (10/1) = 10 log 10 = 10.\n\n**Signal Noise Ratio** is also measured by dB\n\n## Signal Noise Ratio\n$$\n{SNR}_{power}=\\frac{\\text{Average Signal Power}}{\\text{Average Noise Power}}\n$$\n\n$$\n{SNR}_{voltage}=\\frac{\\text{RMS Signal Voltage}}{\\text{RMS Noise Voltage}}\n$$\n\n$$\n{SNR}_{power}={{SNR}_{voltage}}^2\n$$\n\n$$\n{SNR}_{dB}=10\\log_{10}{{SNR}_{power}}=20\\log_{10}{{SNR}_{voltage}}\n$$\n","lastmodified":"2023-04-17T12:12:40.684410422Z","tags":null},"/Synthetic-Aperture-Radar-Imaging/Antenna":{"title":"Antenna","content":"\n# Theorem you need know\n\n* [🧷Resonant circuit](Physics/Electromagnetism/Resonant_circuit.md)\n\n# What is antenna\n\nA usually metallic device for radiating or receiving radio waves\n\n## A simple model representing antenna\n\n![](Synthetic%20Aperture%20Radar%20Imaging/attachments/Pasted%20image%2020230404163712.png)\n\n$R_L$ 损耗电阻 - 介质与结构导致的损耗\n$R_r$ 辐射电阻 - 与天线产生的辐射的能量关系密切\n$X_A$ 电抗 - 描述天线近场电磁能转换的现象 (一般情况下$X_A$ = 0)\n\n\u003e [!warning] \n\u003e 天线还有一个很重要的损耗来源，**mismatch loss**, 天线跟前端的阻抗不匹配，导致能量打不进天线，这点可以通过设计和材质来解决 \n\n# Types of antennas\n\n## Wire antennas\n\n![](Synthetic%20Aperture%20Radar%20Imaging/attachments/Pasted%20image%2020230404165239.png)\n\n## Aperture antennas\n\n![](Synthetic%20Aperture%20Radar%20Imaging/attachments/Pasted%20image%2020230410105310.png)\n\n## Microstrip antennas\n\n![](Synthetic%20Aperture%20Radar%20Imaging/attachments/Pasted%20image%2020230410105548.png)\n\n## Array antennas\n\n![](Synthetic%20Aperture%20Radar%20Imaging/attachments/Pasted%20image%2020230410111719.png)\n\n\u003e [!hint] \n\u003e 天线的目的简单来说，就是为了将能量尽可能辐射出去，同时按照你希望的方向和区间辐射。\n\n## Reflector antennas \u0026 Lens antennas\n\n![](Synthetic%20Aperture%20Radar%20Imaging/attachments/Pasted%20image%2020230410112252.png)\n\n\n# Radiation mechanism\n\n## Ideal antenna\n\nRadiate all the power delivered to it from the transmitter in a desired direction or directions.\n\n## How is radiation accomplished?\n\n* How are EM fields generated by the source?\n* How are EM fields contained and guided within the transmission line \u0026 antenna?\n* How are EM fields finally detached from the antenna to form a free-space wave?\n\n### How are EM fields generated by the source?\n \n![](Synthetic%20Aperture%20Radar%20Imaging/attachments/Pasted%20image%2020230410113039.png)\n\n* $q_v$电荷密度，$C/m^3$\n* $v_Z$电荷移动速度，$m/s$\n* $J_Z$电流密度，$A/m^2$\n$$\nA/m^2 = C/m^3 * m/s = \\frac{C}{m^2 * s}\n$$\n\n导线由PEC所做时，或者高频情况，电流变成面电流\n* $J_S$变成面电流密度，$A/m^2$\n* $q_S$也变成面电荷密度，$C/m^2$\n\n但wire非常thin，当然面最终被认为为线\n\n$$\nI_Z = q_l v_Z\n$$\n我们用thin wire case来讨论\n\n对这个式子做时间微分\n$$\n\\frac{dI_z}{dt} = q_l\\frac{v_Z}{dt}=q_l a_z\n$$\n$$\nl\\frac{dI_Z}{dt}=lq_la_Z=Qa_z\n$$\n\u003e [!hint] \n\u003e To create radiation, there must be **a time-varying current** or **an acceleration (or deceleration) of charge** \n\u003e \n\u003e -\u003e The wire must be curved, bent, discontinuous, terminated, or truncated\n\n###  How are EM fields contained and guided within the transmission line \u0026 antenna?\n\n![](Synthetic%20Aperture%20Radar%20Imaging/attachments/Pasted%20image%2020230411105457.png)\n\nradiation要考虑两个方面，一方面激发电场那边提供的电子的加速，另一方面时end部分的pause造成的电子的减速，这两边会有最主要的辐射；\n\n如果加速和减速之间的距离很短，形成一个pulse，会发出一个很宽频的信号；\n\n如果加减速达到间歇运动状态，会发出一个单频的辐射\n\n\u003e [!hint] \n\u003e 用水波去理解辐射\n\u003e \n\u003e 在池塘里要产生水波，你可以丟一颗石头\n\u003e \n\u003e Source可以产生pulse或者弦波，引起电磁振荡，induce电荷做加减速，产生时变电流，在导线里产生导波，也就是在传输线中引导的电磁波，电磁波最后会走到天线端，被辐射出去；\n\u003e \n\u003e pulse就像你丢了一颗石头下去，弦波就像你按照周期去丢\n \n\u003e [!hint] \n\u003e 根据[Maxwell's equations](Physics/Electromagnetism/Maxwells_equation.md)\n\u003e \n\u003e 当电磁波在导线中存在的时候，它是需要时变的电流或者说是加减速的电荷来support。在传输线里，需要source才能有场；\n\u003e \n\u003e 但是在解[Maxwell's equations](Physics/Electromagnetism/Maxwells_equation.md)的时候，是有一组homogeneous的解，这组解指的是，你不需要source的存在的场，这个场指的是free-space wave；\n\u003e \n\u003e 所以，天线本质上就是一个interface，将导线内需要source的场，变成不需要source的场，也就是free-space wave\n\n### How are EM fields finally detached from the antenna to form a free-space wave?\n\n# Radar key Parameters\n\n\n\n# Reference\n\n* [知乎 - 天线与电波传播基础知识](https://zhuanlan.zhihu.com/p/497482699)\n* [天线 in wiki](https://zh.wikipedia.org/wiki/%E5%A4%A9%E7%BA%BF)\n* [⭐⭐⭐陈士元 - 天线原理与基本参数](https://www.youtube.com/watch?v=JsVGW3z81wc\u0026list=PLQdXflQNtKfLaGnvPLW_XVal-RaHxFN5j\u0026index=1)\n* [天线8个核心参数解析 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/375911768)","lastmodified":"2023-04-17T12:12:40.684410422Z","tags":null},"/Synthetic-Aperture-Radar-Imaging/Radiometric_Calibration":{"title":"Radiometric Calibration - 辐射校准","content":"\n# Overview\nSAR 校准旨在提供其像素值可与场景中的雷达反向散射直接相关的影像。虽然未校准的 SAR 影像足以用于定性用途，但校准后的 SAR 影像对于定量使用 SAR 数据而言仍至关重要。\n\n生成级别 1 影像的典型 SAR 数据处理不包括辐射校正，且仍然存在明显的辐射偏差。因此有必要对 SAR 影像应用辐射校正，*使影像的像素值真正能够反映反射表面的雷达反向散射情况*。在比较由不同的传感器采集的 SAR 影像时，或比较由同一传感器在不同时间、不同模式下采集的（或由不同处理器处理的）SAR 影像时，都需要进行辐射校正。\n\n## Types\n* **Sigma nought** - 用于校准地面上单位面积内返回到天线的反向散射，并与地面范围相关。影像经过校准，因此可以直接与相同或不同传感器收集的不同雷达影像进行比较。科学家倾向于使用 sigma naught 来解释表面散射、表面反射以及表面属性。\n\t* *Scattering coefficient*, or the conventional measure of the strength of radar signals reflected by a distributed scatterer, usually expressed in dB. It is a *normalised dimensionless number*, comparing the strength observed to that expected from an area of one square meter. Sigma nought is defined with respect to the nominally horizontal plane, and in general has a significant variation with **incidence angle**, **wavelength**, and **polarisation**, as well as with **properties of the scattering surface itself**.\n* **Beta nought** - 可生成包含雷达亮度系数的数据集（雷达亮度系数是天线发射功率与接收功率之比）。它与倾斜范围有关，且无维度。\n* **Gamma** - 通常在校准天线时使用。因为每个范围像元与卫星的距离均相等，所以近距范围和远距范围的亮度均相等，这有助于确定输出数据集中的天线方向图。\n* **None** - 不做校正\n\n\n\n# Reference\n\n* [Sentinel-1 Radiometric Calibration—ArcMap | Documentation (arcgis.com)](https://desktop.arcgis.com/en/arcmap/latest/manage-data/raster-and-images/sentinel-1-radiometric-calibration.htm)\n\n* [Urban objects detection from C-band synthetic aperture radar (SAR) satellite images through simulating filter properties | Scientific Reports (nature.com)](https://www.nature.com/articles/s41598-021-85121-9)\n\n* [✨✨✨User Guides - Sentinel-1 SAR - Definitions - Sentinel Online - Sentinel Online (esa.int)](https://sentinel.esa.int/web/sentinel/user-guides/sentinel-1-sar/definitions)\n\n","lastmodified":"2023-04-17T12:12:40.684410422Z","tags":null},"/Synthetic-Aperture-Radar-Imaging/SAR_Explained":{"title":"Synthetic Aperture Radar (SAR) Explained","content":"\n# Radar Basic Concepts\n\n## Down Looking vs. Side Looking\n\n![Pasted image 20230320150424](Synthetic%20Aperture%20Radar%20Imaging/attachments/Pasted%20image%2020230320150424.png)\n\nDown Looking不能区分距离一样的a，b点，一般只用于monitoring of air and naval traffic\n\n## Simplified explanation of Radar working \u0026 What is SAR\nThe radar consists fundamentally of *a transmitter*, *a receiver*, *an antenna* and *an electronic system* to process and record the data.\n\nThe transmitter generates successive short bursts or pulses of microwave at regular intervals which are focused by the antenna into a beam. Radar beam illuminates the surface **obliquely** at a right angle to the motion of the platform. The antenna receives a portion of the transmitted energy reflected or it's known as backscattered from various objects within the illuminated beam by  measuring this time delay between the transmission of a pulse and the reception of the backscattered echo from different  targets. Their distance from the radar and therefore their location can be determined as the sensor platform *moves forward* recording and processing of the backscattered signals builds up a 2-dimensional image of the surface.\n\n\n\u003e [!important] \n\u003e Important\u003cbr\u003e\n\u003e The along track **resolution** is determined by the beam width which is *inversely proportional to the antenna length*, also known as the **aperture**, which means that longer antenna or a longer aperture will produce a narrow beam and a finer resolution. \u003cbr\u003e\n\u003e Long antenna $\\leftrightarrow$ Small beam $\\leftrightarrow$ Long aperture $\\leftrightarrow$ Better image resolution\n\n\n\n### Why SAR\n介于实际情况下的物理空间中，雷达天线的大小是限的，可以通过雷达的移动去模拟长天线情况下的雷达，也就是活得更大的aperture，这项被叫做SAR。目的是在于使用*comparatively small physical antennas*去获得*high resolution images*\n\n--- \n\n![660](Synthetic%20Aperture%20Radar%20Imaging/attachments/Pasted%20image%2020230320163240.png)\n\n* Radar can measure *amplitude* and *phase*\n* Radar can only measure part of echoes.\n* The strength of the reflected echo is the backscattering coefficient ([sigma nought](Synthetic%20Aperture%20Radar%20Imaging/Radiometric_Calibration.md)）and is expressed in [decibels(dB)](Signal%20Processing/What%20is%20dB.md)\n\n## Radar Resolution\n\n### Detail geometry\n\n![](Synthetic%20Aperture%20Radar%20Imaging/attachments/Pasted%20image%2020230330153450.png)\n\u003cfont size=1\u003e**Fig** *Geometry of a side-looking real aperture radar. (SLAR)*\u003c/font\u003e\n\nside-looking的雷达被分为two types —— real aperture radar(*SLAR or SLR*, SL for side-looking)和synthetic aperture radar(SAR)\n\n如上图所示，雷达发出的pulse被[antenna聚焦](Synthetic%20Aperture%20Radar%20Imaging/Antenna.md)在一个narrow的area里，然后scatter后在不同和的时间再被receiver接收\n\n### Resolution\n\n当我们谈SAR的分辨率时，我们要知道有四种operating modes对于SAR而言。\n\n* Stripmap SAR\n* Spotlight SAR\n* Circular SAR\n* Scan SAR\n\n其中Stripmap SAR, Spotlight SAR,  Circular SAR这三种最为常用\n\n![](Synthetic%20Aperture%20Radar%20Imaging/attachments/Pasted%20image%2020230414105501.png)\n\nStripmap SAR是将antenna固定在platform，以straight line方式移动并连续接发pulse，它的优势是可以cover large area。\n\n![](Synthetic%20Aperture%20Radar%20Imaging/attachments/Pasted%20image%2020230414105703.png)\n\nSpotlight SAR天线不断移动以照射同一区域，它的特点是high-resolution image，因为它从不同的角度收集同一区域的data\n\n![](Synthetic%20Aperture%20Radar%20Imaging/attachments/Pasted%20image%2020230414110025.png)\n\nCircular SAR通过circular trajectory窥探同一片area，它跟spotlight SAR很像，区别在于Spotlight mode里antenna是不动的，只有平台在移动，而在circular mode里，antenna也在移动，来收集$360^\\circ$信息，circular SAR的分辨率计算时，认为反射是$360^\\circ$各向同性反射，所以是理论分辨率。\n\n我在UWB radar探测烧伤的技术中将采用Spotlight SAR\n\n#### Range Resolution \u0026 Azimuth Resolution\n\n![](Synthetic%20Aperture%20Radar%20Imaging/attachments/Pasted%20image%2020230414111329.png)\n\n这是一张可以快速check概念的图\n\nTable. *Range and azimuth resolution*\n|               | Range Resolution                             | Azimuth Resolution                                     |\n| ------------- | -------------------------------------------- | ------------------------------------------------------ |\n| Stripmap SAR  | $\\Delta_r = \\frac{c\\pi}{2\\omega_0}$          | $\\Delta_a = \\frac{D_y}{2}$                             |\n| Spotlight SAR | $\\Delta_r = \\frac{c\\pi}{2\\omega_0}$          | $\\Delta_a=\\frac{r_n\\lambda_c}{4L \\cos \\theta_n(0)}$    |\n| Circular SAR  | $\\Delta_r = \\frac{\\pi}{\\rho_max - \\rho_min}$ | $\\Delta_a=\\frac{\\pi}{2k_c \\cos{\\theta_z}\\sin{\\phi_0}}$ |\n\n* $\\omega_0$ radar signal half-bandwidth in radians\n* $D_y$ the diameter of the radar in azimuth domain\n* $r_n$ the target radical distance from the center of aperture\n* $\\lambda_c = \\frac{2c\\pi}{\\omega_c}$ the wavelength at carrier fast-time frequency\n* $\\omega_c$ the central frequency\n* $L$ half-size of the aperture\n* $\\theta_n(0)$ the aspect angle of the $n$th target when radar is at (0, 0)\n* $\\rho_{max}$ and $\\rho_{min}$ the maximum and minimum polar radius in spatial frequency domain for the support of a target at the center of the spotlight area\n* $k_c$ the wavenumber at carrier frequency\n* $\\theta_z$ the average depression angle of the target area\n* $\\phi_0$ the polar angle in spatial frequency domain \n\n## Radar Image Format\n\n\n\n## Radar Key Parameters\n* Wave Length\n* Polarization\n* Incidence Angle\n\n### Wave Length\n\n![](Synthetic%20Aperture%20Radar%20Imaging/attachments/Pasted%20image%2020230330153007.png)\n\n雷达数据的空间分辨率与传感器波长与传感器天线长度之比直接相关。 对于给定的波长，天线越长，空间分辨率越高。 对于以大约 5 cm 波长运行的太空卫星（C 波段雷达），为了获得 10 m 的空间分辨率，您需要一个大约 4,250 m 长的雷达天线。 （超过 47 个足球场！）\n\n\n\n# Reference\n\n* [Theory of Synthetic Aperture Radar (uzh.ch)](https://www.geo.uzh.ch/~fpaul/sar_theory.html)\n* ***Sentinel-1** is a famous SAR, you can find almost every definitions* of SAR in this page:\n[User Guides - Sentinel-1 SAR - Definitions - Sentinel Online - Sentinel Online (esa.int)](https://sentinel.esa.int/web/sentinel/user-guides/sentinel-1-sar/definitions)\n* [SAR(Synthetic Aperture Radar)基础(一) - 知乎 (评论区说这个有错)](https://zhuanlan.zhihu.com/p/98053986)\n* [A Review of Synthetic-Aperture Radar Image Formation Algorithms and Implementations: A Computational Perspective]([Remote Sensing | Free Full-Text | A Review of Synthetic-Aperture Radar Image Formation Algorithms and Implementations: A Computational Perspective (mdpi.com)](https://www.mdpi.com/2072-4292/14/5/1258))\n","lastmodified":"2023-04-17T12:12:40.684410422Z","tags":null},"/Synthetic-Aperture-Radar-Imaging/SAR_Imaging_Algorithm":{"title":"SAR Imaging Algorithm review in 2022","content":"\n\n# Overview\n\n* Backprojection\n* Matched-filter\n* Polar format\n* Range-Doppler\n* Chirp scaling algorithms\n\n# What is SAR processing?\n\n## Born approximation\n\nSAR 处理算法将场景建模为一组离散的点目标，其分散的 EM 场不会相互影响。\n\n* 无多次反弹\n* 目标处的电场仅来自入射波，而不来自周围的散射体\n* 目标模型是线性的，因为点目标 P1 和点目标 P2 的散射响应被建模为点目标 P1 本身的响应 + 点目标 P2 本身的响应\n* 可以应用**叠加原理(principle of superposition)**\n\n--- \n\nSAR 处理是对图像中每个像素应用匹配滤波器，其中匹配滤波器系数是来自单个孤立点目标的响应\n\n* SAR processing is a correlation filter between a single isolated point target response and the raw data\n* SAR processing is an inner product between our model of a single isolated point target and the raw data\n\n\n# Range-Doppler Algorithm (RDA)\n\nRange-Doppler Algorithm是SAR成像的第一个算法，在1970年代被developed出来，用来生成stripmap的SAR。Range-Doppler Algorithm利用block-processing处理，在距离和方位角中使用频域运算。\n\n步骤如下：\n\n![](Synthetic%20Aperture%20Radar%20Imaging/attachments/Pasted%20image%2020230417110036.png)\n\n## Range Compression\n\n\n\n# Reference\n\n* [A Review of Synthetic-Aperture Radar Image Formation Algorithms and Implementations: A Computational Perspective]([Remote Sensing | Free Full-Text | A Review of Synthetic-Aperture Radar Image Formation Algorithms and Implementations: A Computational Perspective (mdpi.com)](https://www.mdpi.com/2072-4292/14/5/1258))\n* [Range Doppler Algorithm - University of Kansas](https://people.eecs.ku.edu/~callen58/826/826_SAR_Processing_Algorithms_Overview-F15.pptx)","lastmodified":"2023-04-17T12:12:40.684410422Z","tags":null},"/Synthetic-Aperture-Radar-Imaging/SAR_MOC":{"title":"Synthetic Aperture Radar (SAR) Imaging - MOC","content":"\n\n# Antenna\n\n* [Antenna](Synthetic%20Aperture%20Radar%20Imaging/Antenna.md)\n\n# SAR\n\n* [[Synthetic Aperture Radar Imaging/SAR_Explained|SAR Explained]]\n* [SAR Imaging Algorithm review in 2022](Synthetic%20Aperture%20Radar%20Imaging/SAR_Imaging_Algorithm.md)","lastmodified":"2023-04-17T12:12:40.684410422Z","tags":null},"/warehouse/dampers_keeping_a_door_from_slamming-shut":{"title":"Dampers keeping a door from slamming shut","content":"\n![](warehouse/attachments/Pasted%20image%2020230404150745.png)","lastmodified":"2023-04-17T12:12:40.7084107Z","tags":null}}