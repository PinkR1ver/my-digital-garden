{"/":{"title":"Home","content":"\n🕵️‍♂️ This is Jude Wang's vault about his notebook, his knowledge, his second brain. \n\n🚧 There are notebooks about his research career:\n\n* [Deep Learning](Deep%20Learning%20And%20Machine%20Learning/Deep%20_Learning_MOC.md)\n\n* [Signal Processing](Signal%20Processing/Signal%20Processing_MOC.md)\n\n* [[Synthetic Aperture Radar Imaging/SAR_MOC| Synthetic Aperture Radar(SAR) Imaging]]\n\n* [Hardware](Hardware/Hardware_MOC.md)\n\n🛶 Also, he learn some knowledge about his hobbies:\n\n* [📷 Photography](Photography/Photography_MOC.md)\n\n* [📮文学](文学/文学_MOC.md)\n\n","lastmodified":"2023-03-30T12:42:55.36655479Z","tags":null},"/%E6%96%87%E5%AD%A6/%E5%8F%A5%E5%AD%90/%E5%8F%A5%E5%AD%90":{"title":"句子","content":"\n  \u003cstyle\u003e\n    p {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n\n    a {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n  \u003c/style\u003e\n\n* [🌸Love about](文学/句子/Love%20about.md)\n* [🖋Poem](文学/句子/Poem.md)\n* [🧗🏻‍♂️Motivation](文学/句子/Motivation.md)\n* [🧶Feeling](文学/句子/Feeling.md)\n* [🎞 Movie](文学/句子/Movie.md)\n","lastmodified":"2023-03-30T12:42:55.374554923Z","tags":null},"/%E6%96%87%E5%AD%A6/%E5%8F%A5%E5%AD%90/Feeling":{"title":"🧶Feeling","content":"\n  \u003cstyle\u003e\n    p {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n\n    a {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n  \u003c/style\u003e\n\n\u003e [!quote] \n\u003e A Sentence\n\u003e \n\u003e 一个太过于文艺的人注定不会快乐，因为心中有爱 有善良，骨子里住着孩子般的纯真，但也往往容易多愁善感，容易感知美好，也更容易体会悲伤。她喜欢文字，往往不善言辞，不是文字太少，而是感受太多。\n\u003e  \u003cp style=\"text-align:right\"\u003e——三毛\u003c/p\u003e\n  ","lastmodified":"2023-03-30T12:42:55.374554923Z","tags":null},"/%E6%96%87%E5%AD%A6/%E5%8F%A5%E5%AD%90/Love-about":{"title":"🌸Love","content":"\n  \u003cstyle\u003e\n    p {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n\n    a {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n  \u003c/style\u003e\n\n  \u003e [!quote] \n\u003e [A poem](https://www.bilibili.com/video/BV1V24y1x7Nh/?buvid=YF4AFCFA7E0887094E329B9A6FADF98BF343\u0026is_story_h5=false\u0026mid=B1quk6Mlu6tnRY8zjwxWeg%3D%3D\u0026p=1\u0026plat_id=116\u0026share_from=ugc\u0026share_medium=iphone\u0026share_plat=ios\u0026share_session_id=4AD8E5F4-D617-499B-9C19-D5897A7EB825\u0026share_source=QQ\u0026share_tag=s_i\u0026timestamp=1679378304\u0026unique_k=tXa4xdJ\u0026up_id=315154029\u0026vd_source=c47136abc78922800b17d6ce79d6e19f) \u003cbr\u003e\n\u003e “至少有两次喜欢\u003cbr\u003e\n\u003e 一次发生在在一起之前，一次发生在之后，\u003cbr\u003e\n\u003e 第一次是喜欢上你。第二次是喜欢上我们，\u003cbr\u003e\n\u003e 我只敢把第二次翻译成爱，\u003cbr\u003e\n\u003e 第一次是因为你很好，第二次是因为我还没有坏到敢放满揉碎你的好。\u003cbr\u003e\n\u003e 我要小心的捧着第一次的喜欢，就像掏出一份手写的初稿，\u003cbr\u003e\n\u003e 你会接过我的目光，在岁月里重新誊写岁月，\u003cbr\u003e\n\u003e 要删改的地方还很多，包括但不限于，把差错翻译成幽默\u003cbr\u003e\n\u003e 改了还是存在啊，爱情本就是听起来很美的，阴差阳错”\n\n\n--- \n\n\u003e [!quote] \n\u003e A Sentence\n\u003e \n\u003e \"I am too full of life to be half-loved\"\n\u003e \n\n![400](文学/attachments/Pasted%20image%2020230321142115.png)\n\n---\n\n\u003e [!quote] \n\u003e [A poem](https://www.bilibili.com/video/BV1Vd4y187Tq/?buvid=YF4AFCFA7E0887094E329B9A6FADF98BF343\u0026is_story_h5=false\u0026mid=B1quk6Mlu6tnRY8zjwxWeg%3D%3D\u0026p=1\u0026plat_id=116\u0026share_from=ugc\u0026share_medium=iphone\u0026share_plat=ios\u0026share_session_id=F81E6185-E382-4E78-95FD-3155869F570B\u0026share_source=QQ\u0026share_tag=s_i\u0026timestamp=1679380048\u0026unique_k=Q9GSCLM\u0026up_id=2009238634\u0026vd_source=c47136abc78922800b17d6ce79d6e19f)\u003cbr\u003e\n\u003e  “他听的小众音乐，\u003cbr\u003e\n\u003e  第二天上了抖音热榜。\u003cbr\u003e\n\u003e  他爱吃的苍蝇小馆，\u003cbr\u003e\n\u003e  第二天全国连锁了一万家。\u003cbr\u003e\n\u003e  他爱的县城姑娘，\u003cbr\u003e\n\u003e  第二天出国留学再也没回来。\u003cbr\u003e\n\u003e  他觉得那些特别，\u003cbr\u003e\n\u003e  都已烟消云散，\u003cbr\u003e\n\u003e  可那些特别一直都在，\u003cbr\u003e\n\u003e  错就错在他认为特别\u003cbr\u003e\n\u003e  只属于他。”\u003cbr\u003e\n\u003e  \u003ca href=\"https://space.bilibili.com/2009238634\"\u003e\u003cp style=\"text-align:right\"\u003e——祺白石\u003c/p\u003e\u003c/a\u003e\n\n![400](文学/attachments/Pasted%20image%2020230321143300.png)","lastmodified":"2023-03-30T12:42:55.374554923Z","tags":null},"/%E6%96%87%E5%AD%A6/%E5%8F%A5%E5%AD%90/Motivation":{"title":"🧗🏻‍♂️Motivation","content":"\n  \u003cstyle\u003e\n    p {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n\n    a {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n  \u003c/style\u003e\n\n  \u003c/script\u003e\n\u003e [!quote] \n\u003e A Sentence\n\u003e \n\u003e \"No easy basket\"\n\n“如果你想了解American篮球的根基，你要去看看美高”\n","lastmodified":"2023-03-30T12:42:55.374554923Z","tags":null},"/%E6%96%87%E5%AD%A6/%E5%8F%A5%E5%AD%90/Movie":{"title":"From Movie","content":"\n\u003e [!quote] \n\u003e  铃芽之旅\n\u003e  \n\u003e  \"鎮住土地的是人心的重量。\"\n\n","lastmodified":"2023-03-30T12:42:55.374554923Z","tags":null},"/%E6%96%87%E5%AD%A6/%E5%8F%A5%E5%AD%90/Novel":{"title":"From Novel","content":"\n\u003e [!quote] \n\u003e From CC98, credits to someone\n\u003e \n\u003e 很奇怪，与一个人告别之后男生记起来的永远是一些微不足道的细节，男生不知道女生的名字，也不记得女生常穿的衣服是什么颜色，男生忘掉了每天在桥边上等女生的时间，女生的眼睛也慢慢在男生的记忆里蒙尘。 \n\u003e \n\u003e 不过男生记得等女生时桥下的流水潺潺，也记得校园里某个角落他们经常去看的四叶草，记得第一次注意到女生时公交站顶上那片不同的落叶，也记得步道旁女生指给他看的树皮。 \n\u003e \n\u003e 后来男生看了阿尔瓦雷斯的《行走的距离》，里面有句话是“别人稍一注意你，你就敞开心扉，你觉得这是坦率，其实这是孤独。”\n\u003e \n\u003e  男生不知道自己是不是孤独，也不知道自己是不是坦率。男生不关心。 \n\u003e  \n\u003e  男生很感谢那个女生。 \n\u003e  \n\u003e  男生很想写下“不过男生并不想念那个女生”。 \n\u003e  \n\u003e  不过男生很想念那个女生。\n","lastmodified":"2023-03-30T12:42:55.374554923Z","tags":null},"/%E6%96%87%E5%AD%A6/%E5%8F%A5%E5%AD%90/Poem":{"title":"🖋Poem","content":"\n  \u003cstyle\u003e\n    p {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n\n    a {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n  \u003c/style\u003e\n\n\u003e [!quote] \n\u003e [A poem](https://www.bilibili.com/video/BV1V24y1x7Nh/?buvid=YF4AFCFA7E0887094E329B9A6FADF98BF343\u0026is_story_h5=false\u0026mid=B1quk6Mlu6tnRY8zjwxWeg%3D%3D\u0026p=1\u0026plat_id=116\u0026share_from=ugc\u0026share_medium=iphone\u0026share_plat=ios\u0026share_session_id=4AD8E5F4-D617-499B-9C19-D5897A7EB825\u0026share_source=QQ\u0026share_tag=s_i\u0026timestamp=1679378304\u0026unique_k=tXa4xdJ\u0026up_id=315154029\u0026vd_source=c47136abc78922800b17d6ce79d6e19f) \u003cbr\u003e\n\u003e “至少有两次喜欢\u003cbr\u003e\n\u003e 一次发生在在一起之前，一次发生在之后，\u003cbr\u003e\n\u003e 第一次是喜欢上你。第二次是喜欢上我们，\u003cbr\u003e\n\u003e 我只敢把第二次翻译成爱，\u003cbr\u003e\n\u003e 第一次是因为你很好，第二次是因为我还没有坏到敢放满揉碎你的好。\u003cbr\u003e\n\u003e 我要小心的捧着第一次的喜欢，就像掏出一份手写的初稿，\u003cbr\u003e\n\u003e 你会接过我的目光，在岁月里重新誊写岁月，\u003cbr\u003e\n\u003e 要删改的地方还很多，包括但不限于，把差错翻译成幽默\u003cbr\u003e\n\u003e 改了还是存在啊，爱情本就是听起来很美的，阴差阳错”\n\n---\n\n\u003e [!quote] \n\u003e [A poem](https://www.bilibili.com/video/BV1Vd4y187Tq/?buvid=YF4AFCFA7E0887094E329B9A6FADF98BF343\u0026is_story_h5=false\u0026mid=B1quk6Mlu6tnRY8zjwxWeg%3D%3D\u0026p=1\u0026plat_id=116\u0026share_from=ugc\u0026share_medium=iphone\u0026share_plat=ios\u0026share_session_id=F81E6185-E382-4E78-95FD-3155869F570B\u0026share_source=QQ\u0026share_tag=s_i\u0026timestamp=1679380048\u0026unique_k=Q9GSCLM\u0026up_id=2009238634\u0026vd_source=c47136abc78922800b17d6ce79d6e19f)\u003cbr\u003e\n\u003e  “他听的小众音乐，\u003cbr\u003e\n\u003e  第二天上了抖音热榜。\u003cbr\u003e\n\u003e  他爱吃的苍蝇小馆，\u003cbr\u003e\n\u003e  第二天全国连锁了一万家。\u003cbr\u003e\n\u003e  他爱的县城姑娘，\u003cbr\u003e\n\u003e  第二天出国留学再也没回来。\u003cbr\u003e\n\u003e  他觉得那些特别，\u003cbr\u003e\n\u003e  都已烟消云散，\u003cbr\u003e\n\u003e  可那些特别一直都在，\u003cbr\u003e\n\u003e  错就错在他认为特别\u003cbr\u003e\n\u003e  只属于他。”\u003cbr\u003e\n\u003e  \u003ca href=\"https://space.bilibili.com/2009238634\"\u003e\u003cp style=\"text-align:right\"\u003e——祺白石\u003c/p\u003e\u003c/a\u003e\n\n![400](文学/attachments/Pasted%20image%2020230321143300.png)","lastmodified":"2023-03-30T12:42:55.374554923Z","tags":null},"/%E6%96%87%E5%AD%A6/%E6%96%87%E5%AD%A6_MOC":{"title":"文学","content":"\n  \u003cstyle\u003e\n    p {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n\n    a {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n  \u003c/style\u003e\n\nIn this MOC, it shows you the path to what I record for some interesting sentences, including Chinese and English, even Japanese.\n\n[🌌句子](文学/句子/句子.md)\n\n[📜原创诗](文学/Poem_by_me.md)\n","lastmodified":"2023-03-30T12:42:55.374554923Z","tags":null},"/%E6%96%87%E5%AD%A6/Poem_by_me":{"title":"My Poem","content":"\n  \u003cstyle\u003e\n    p {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n\n    a {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n  \u003c/style\u003e\n","lastmodified":"2023-03-30T12:42:55.36655479Z","tags":null},"/.trash/attachments/Pasted-image-20230320150424.png":{"title":"Pasted image 20230320150424.png","content":"","lastmodified":"2023-03-30T12:42:55.278553332Z","tags":null},"/Circuit/Basic/Electric_units":{"title":"Electric Units","content":"# Electrical impedance\n\n$$\nZ = \\sqrt{R^2 + {(X_L-X_C)}^2}\n$$\n\n\n* $Z$ = impedance\n* $R$ = resistance\n* $X_L$  = inductive reactance\n* $X_C$  = capacitive reactance\n\n![](Circuit/Basic/attachments/Pasted%20image%2020230330163734.png)\n\n**阻抗**是电路中电阻、电感、电容对交流电的阻碍作用的统称。阻抗是一个复数，实部称为**电阻**，虚部称为**电抗**；其中电容在电路中对交流电所起的阻碍作用称为**容抗**，电感在电路中对交流电所起的阻碍作用称为**感抗**，容抗和感抗合称为**电抗**。\n\n阻抗将电阻的概念加以延伸至交流电路领域，不仅描述*电压与电流的相对振幅*，也描述其*相对相位*。当通过电路的电流是直流电时，电阻与阻抗相等，电阻可以视为相位为零的阻抗。\n\n## 形式\n\n1. $R+jX$\n2. $Z_m\\angle\\theta$\n3. $Z_m e^{j\\theta}$\n\n阻抗定义为电压与电流的频域比率。阻抗的大小$Z_{m}$ 是电压振幅与电流振幅的绝对值比率，阻抗的相位 $\\theta$是电压与电流的相位差。\n\n## 欧姆定律\n\n$$\nv = iZ = iZ_m e^{j\\theta}\n$$\n\n阻抗大小$Z_m$的作用恰巧就像电阻，设定电流$i$，就可以计算出阻抗$Z$两端的电压降$v$。相位因子$e^{j\\theta}$则是电流滞后于电压的相位差$\\theta$ \n\n\u003e [!tip] \n\u003e 在时域中，电流信号会比电压信号慢$\\theta T/2\\pi$秒\n\n## 理想的阻抗\n$$\nZ_R = R\n$$\n\n$$\nZ_C = \\frac{1}{j\\omega C}\n$$\n\n$$\nZ_L = j \\omega L\n$$\n\n* 对于电容，交流电压滞后90°于交流电流；\n* 对于电感，交流电压超前90°于交流电流\n\n### 容抗\n\n$$\nX_C = -j/\\omega C\n$$\n随着$\\omega$趋向于0，电源趋向于直流电源，容抗的绝对值趋向于无穷；*因此，在低频率运作时，电容器貌似断路。假设电源的频率越高，则容抗越低，对于电流通过的阻碍也越低。在高频率运作时，电容器貌似短路。*\n\n### 阻抗\n\n$$\nX_L = j\\omega L\n$$\n从这方程可以观察到，当交流电源的角频率趋向于零时，电源会趋向于直流电源，感抗会趋向于零，对于电流的通过阻碍越低。*所以，在低频率运作时，电感器貌似短路。假设电源角频率越高，则感抗越高，假设给定电压源振幅，则电流会趋向于零。所以，在高频率运作时，电感器貌似断路。*\n\n\n# Reference\n\n[电气单位（V，A，Ω，W，...） (rapidtables.org)](https://www.rapidtables.org/zh-CN/electric/Electric_units.html)\n","lastmodified":"2023-03-30T12:42:55.278553332Z","tags":null},"/Deep-Learning-And-Machine-Learning/Deep-Learning-Block/Attention":{"title":"⭐Attenion","content":"# Self-Attention\n\n讲述self-attention我们以*sequence labeling*任务作为任务来讲解，sequence labeling的任务是输入N个vector并且输出N个label。\n\n典型的例子有输入一个句子，分析每个词汇的词性是什么，比如句子“I saw a saw”，这个句子里saw和saw的词性分别是verb和nonu，如果我们用fully-connected（FC）层来做的话，那么面对同样的输入saw，我们无法得出不同的结果。\n\n![Pasted image 20230315195403](Deep%20Learning%20And%20Machine%20Learning/Deep%20Learning%20Block/attachments/1.png)\n\n我们的做法可以是对输入加窗，考虑周边邻近的词汇信息，这与信号处理常用的方法类似，但是窗的长度是有限且固定的，而seq的长度是变化的，因此我们在面对这种任务的时候，我们可以借助**self-attention**层。\n\n## Detail\n\n![Pasted image 20230315195603](Deep%20Learning%20And%20Machine%20Learning/Deep%20Learning%20Block/attachments/Pasted%20image%2020230315195603.png)\n\n对于Self-attention层，生成的$b^i$向量是考虑到所有输入$\\sum_i\\alpha^i$向量\n\n### Vector Relevance\n\n![250](Deep%20Learning%20And%20Machine%20Learning/Deep%20Learning%20Block/attachments/Pasted%20image%2020230315200009.png)\n\n\n* *Step 1.* 使用Dot-product 去计算 vector relevance\n\n![400](Deep%20Learning%20And%20Machine%20Learning/Deep%20Learning%20Block/attachments/Pasted%20image%2020230315201906.png)\n\n* *Step 2.* Normalizing计算出来的vector relevance\n![400](Deep%20Learning%20And%20Machine%20Learning/Deep%20Learning%20Block/attachments/Pasted%20image%2020230315202047.png)\n\n* *Step 3.*  根据vector relevance，也就是attention scores计算最后的输出。这是一个Reweighting Process，一个extract information based on attention scores\n\n![400](Deep%20Learning%20And%20Machine%20Learning/Deep%20Learning%20Block/attachments/Pasted%20image%2020230315202314.png)\n\n\u003e [!hint] \n\u003e  从上面的过程中，可以看出，$b^i$互相之间的计算没有关系，具有很好的并行性\n\n### Matrix Detail\n\n$$\nq^i = W^q \\alpha^i\n$$\n\n\n$$\nQ = [q^1 \\quad q^2 \\quad \\cdots \\quad q^N],\\ \\  I = [\\alpha^1 \\quad \\alpha^2 \\quad \\cdots \\quad \\alpha^N]\n$$\n\n\n\nSo,\n\n$$\nQ = W^q I\n$$\n\nAs same,\n$$\nK = W^k I,\\quad V = W^v I\n$$\nCalculate attention score $\\alpha$,\n$$\n\\begin{bmatrix}\n\\alpha_{1,1} \\\\\n\\alpha_{1,2} \\\\\n\\cdots \\\\\n\\alpha_{1,N}\n\\end{bmatrix} =\n\\begin{bmatrix}\nk^1 \\\\\nk^2 \\\\\n\\cdots \\\\\nk_N\n\\end{bmatrix} q^1\n$$\n\nSo,\n$$\nA=\\begin{bmatrix}\n\\alpha_{1,1} \u0026 \\alpha_{2,1} \u0026 \\cdots \u0026 \\alpha_{N,1} \\\\\n\\alpha_{1,2} \u0026 \\alpha_{2,2} \u0026 \\cdots \u0026 \\alpha_{N,2} \\\\\n\\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots\\\\\n\\alpha_{1,N} \u0026 \\alpha_{2,N} \u0026 \\cdots \u0026 \\alpha_{N,N}\n\\end{bmatrix} =\n\\begin{bmatrix}\nk^1 \\\\\nk^2 \\\\\n\\cdots \\\\\nk_N\n\\end{bmatrix} [q^1 \\quad q^2 \\quad \\cdots \\quad q^N] = K^TQ\n$$\n\n$$\nA' = \\text{Softmax}(A)\n$$\n\nFinally, calculate output $b$\n\n$$\nO = [b^1 \\quad b^2 \\quad \\cdots \\quad b^N] = [v^1 \\quad v^2 \\quad \\cdots \\quad v^N] = VA'\n$$\n\n![600](Deep%20Learning%20And%20Machine%20Learning/Deep%20Learning%20Block/attachments/Pasted%20image%2020230315205148.png)\n\n### Positional Encoding\n![250](Deep%20Learning%20And%20Machine%20Learning/Deep%20Learning%20Block/attachments/Pasted%20image%2020230315205727.png)\n* Each position has a unique positional vector $e^i$\n\t* hand-crafted\n\t* learned from data\n\n## Fun Facts\n\n### Self-attention vs. CNN\n\n![Pasted image 20230315205918](Deep%20Learning%20And%20Machine%20Learning/Deep%20Learning%20Block/attachments/Pasted%20image%2020230315205918.png)\n\n因为transformer有着更大的function set，所以需求更多的数据; ![Pasted image 20230315210032](Deep%20Learning%20And%20Machine%20Learning/Deep%20Learning%20Block/attachments/Pasted%20image%2020230315210032.png)\n\n### Self-attention vs. RNN\n\n目前，RNN的角色正在被self-attention替代，RNN在long seq的情况下，前面的信息会被逐渐遗忘；同时**RNN没有并行性**\n同样，Self attention有着比RNN更大的function set，在某些情况下，self-attention可以变成RNN\n\n# Multi-head Self-attention\nMulti-head self attention就是由不同的self attention layer在一起，有不同的$W^q$,$W^k$来负责不同种类的relevance\n\n![600](Deep%20Learning%20And%20Machine%20Learning/Deep%20Learning%20Block/attachments/Pasted%20image%2020230315210631.png)\n![300](Deep%20Learning%20And%20Machine%20Learning/Deep%20Learning%20Block/attachments/Pasted%20image%2020230315210704.png) ","lastmodified":"2023-03-30T12:42:55.330554194Z","tags":null},"/Deep-Learning-And-Machine-Learning/Deep-Learning-Block/Deep-Learning-Block":{"title":"Deep Learning Block - MOC","content":"\n[[Deep Learning And Machine Learning/Deep Learning Block/⭐Attention|Attention Blocker]]\n\n[[Deep Learning And Machine Learning/Deep Learning Block/Transformer|Transformer]]\n\n","lastmodified":"2023-03-30T12:42:55.278553332Z","tags":null},"/Deep-Learning-And-Machine-Learning/Deep-Learning-Block/Transformer":{"title":"Transformer","content":"\n\u003e [!info] \n\u003e 在学习Transformer前，你需要学习 [⭐Attention](Deep%20Learning%20And%20Machine%20Learning/Deep%20Learning%20Block/⭐Attention.md)\n\n\n\nTransformer 是Seq2Seq model，由Encoder和Decoder组成\n![300](Deep%20Learning%20And%20Machine%20Learning/Deep%20Learning%20Block/attachments/Pasted%20image%2020230316160103.png)\n\n# Encoder\n这里贴的是原文Encoder的架构\n![Pasted image 20230316162635](Deep%20Learning%20And%20Machine%20Learning/Deep%20Learning%20Block/attachments/Pasted%20image%2020230316162635.png)\n\n![Pasted image 20230316162642](Deep%20Learning%20And%20Machine%20Learning/Deep%20Learning%20Block/attachments/Pasted%20image%2020230316162642.png)","lastmodified":"2023-03-30T12:42:55.278553332Z","tags":null},"/Deep-Learning-And-Machine-Learning/Deep-_Learning_MOC":{"title":"Deep Learning - MOC","content":"\n* [Deep Learning Block](Deep%20Learning%20And%20Machine%20Learning/Deep%20Learning%20Block/Deep%20Learning%20Block.md)\n\n* [Model Interpretability](Deep%20Learning%20And%20Machine%20Learning/Model_interpretability/Model_Interpretability_MOC.md)\n\n","lastmodified":"2023-03-30T12:42:55.330554194Z","tags":null},"/Deep-Learning-And-Machine-Learning/Model_interpretability/Model_Interpretability_MOC":{"title":"Model Interpretability - MOC","content":"\n* [SHAP](Deep%20Learning%20And%20Machine%20Learning/Model_interpretability/SHAP.md)\n","lastmodified":"2023-03-30T12:42:55.330554194Z","tags":null},"/Deep-Learning-And-Machine-Learning/Model_interpretability/SHAP":{"title":"SHAP - a reliable way to analyze model interpretability","content":"\nSHAP is the most popular model-agnostic technique that is used to explain predictions. SHAP stands for **SH**apley **A**dditive ex**P**lanations\n\nShapely values are obtained by incorporating concepts from *Cooperative Game Theory*  and *local explanations*\n\n# Mathematical and Algorithm Foundation\n\n## Shapely Values\n\nShapely values were from game theory and invented by Lloyd Shapley. Shapely values were invented to be a way of providing a fair solution to the following question:\n\n\u003e [!question] \n\u003e  If we have a coalition **C** that collaborates to produce a value **V**: How much did each individual member contribute to the final value\n\nThe method here we assess each individual member’s contribution is to removing each member to get a new coalition and then compare their production, like this graphs:\n\n![](Deep%20Learning%20And%20Machine%20Learning/Model_interpretability/attachments/Pasted%20image%2020230329165429.png)\n\nAnd then, we get every member 1 included or not included coalitions like this:\n\n![](Deep%20Learning%20And%20Machine%20Learning/Model_interpretability/attachments/Pasted%20image%2020230329165523.png)\n\nUsing left value - right value, we can get difference like image left above; And then we calculate the mean of them:\n\n$$\n\\varphi_i=\\frac{1}{\\text{Members}}\\sum_{\\forall \\text{C s.t. i}\\notin \\text{C}} \\frac{\\text{Marginal Contribution of i to C}}{\\text{Coalitions of size |C|}}\n$$\n\n## Shapely Additive Explanations\n\nWe need to know what’s **additive** mean here. Lundberg and Lee define an additive feature attribution as follows:\n\n![](Deep%20Learning%20And%20Machine%20Learning/Model_interpretability/attachments/Pasted%20image%2020230329165623.png)\n\n![](Deep%20Learning%20And%20Machine%20Learning/Model_interpretability/attachments/Pasted%20image%2020230329165818.png)\n\n$x'$, the simplified local inputs usually means that we turn a feature vector into a discrete binary vector, where features are either included or excluded. Also, the $g(x')$ should take this form:\n\n$$\ng(x')=\\varphi_0+\\sum_{i=1}^N \\varphi_i {x'}_i\n$$\n\n* $\\varphi_0$ is the **null output** of this model, that is, the **average output** of this model\n-  $\\varphi_i$ is **feature affect**, is how much that feature changes the output of the model, introduced above. It’s called **attribution**\n\n![](Deep%20Learning%20And%20Machine%20Learning/Model_interpretability/attachments/Pasted%20image%2020230329165840.png)\n\nNow Lundberg and Lee go on to describe a set of three desirable properties of such an additive feature method, **local accuracy**, **missingness**, and **consistency**.\n\n### Local accuracy\n\n$$\ng(x')\\approx f(x) \\quad \\text{if} \\quad x'\\approx x\n$$\n\n### Missingness\n\n$$\n{x_i}' = 0 \\rightarrow \\varphi_i = 0\n$$\n\nif a feature excluded from the model. it’s attribution must be zero; that is, the only thing that can affect the output of the explanation model is the inclusion of features, not the exclusion.\n\n### Consistency\n\nIf feature contribution changes, the feature effect cannot change in the opposite direction\n\n# Why SHAP\n\nLee and Lundberg in their paper argue that only SHAP satisfies all three properties if **the feature attributions in only additive explanatory model are specifically chosen to be the shapley values of those features**\n\n# SHAP, step-by-step Process, same as shap.explainer\n\nFor example, we consider a ice cream shop in the airport, it has four features we can know to predict his business.\n\n$$\n\\begin{bmatrix}\n\\text{temperature} \u0026 \\text{day of weeks} \u0026 \\text{num of flights} \u0026 \\text{num of hours}\n\\end{bmatrix}\n\\\\\n\\rightarrow \\\\\n\\begin{bmatrix}\nT \u0026 D \u0026 F \u0026 H\n\\end{bmatrix}\n$$\n\nFor, example, we want to know the temperature 80 in sample [80 1 100 4] shapley value, here’s the step\n\n- Step 1. Get random permutation of features, and give a bracket to the feature we care and everything in its right. (manually)\n\n$$\n\\begin{bmatrix}\nF \u0026 D \u0026 \\underbrace{T \\quad H}\n\\end{bmatrix}\n$$\n\n- Step 2. Pick random sample from dataset\n \nFor example, [200 5 70 8], form: [F D T H]\n\n- Step 3. Form vectors $x_1 \\quad x_2$\n\n$$\nx_1=[100 \\quad 1 \\quad 80 \\quad \\color{#BF40BF} 8 \\color{#FFFFFF}] \n$$\n\n$x_1$ is partially from original sample and partially from the random chosen one, the feature in bracket will from random chosen one, exclude what we care\n\n$$\nx_2 = [100 \\quad 1 \\quad \\color{#BF40BF} 70 \\quad  8 \\color{#FFFFFF}]\n$$\n\n$x_2$  just change the feature we care into the same as random chosen one’s feature value\n\nThen, calculate the diff and record\n\n$$\nDIFF = c_1 - c_2\n$$\n\n- Step 4. Record the diff \u0026 return to step 1. and repeat many times\n\n$$\n\\text{SHAP}(T=80 | [80 \\quad 1 \\quad 100 \\quad 4]) = \\text{average(DIFF)}\n$$\n\n# Shapley kernel\n\n## Too many coalitions need to be sampled\n\nLike we introduce shapley values above, for each $\\varphi_i$ we need to sample a lot of coalitions to compute the difference. \n\nFor 4 features, we need 64 total coalitions to sample; For 32 features, we need 17.1 billion coalitions to sample.\n\nIt’s entirely untenable.\n\nSo, to get over this difficulty, we need devise a **shapley kernel**, and that’s how the Lee and Lundberg do\n\n![](Deep%20Learning%20And%20Machine%20Learning/Model_interpretability/attachments/Pasted%20image%2020230329181956.png)\n\n## Detail\n![](Deep%20Learning%20And%20Machine%20Learning/Model_interpretability/attachments/Pasted%20image%2020230329182011.png)\n\nThough most of ML models won’t just let you omit a feature, what we do is define a **background dataset** B, one that contains a set of representative data points that model was trained over. We then filled in out omitted feature of features with values from background dataset, while holding the features are included in the permutation fixed to their original values. We then take the average of the model output over all of these new synthetic data point as our model output for that feature permutation which we call $\\bar{y}$.\n\n$$\nE[y_{\\text{12i4}}\\ \\  \\forall \\ \\text{i}\\in B] = \\bar{y}_{\\text{124}}\n$$ \n![](Deep%20Learning%20And%20Machine%20Learning/Model_interpretability/attachments/Pasted%20image%2020230329205039.png)\n\nThem we have a number of samples computed in this way,like image in left.\n\nWe can formulate this as a weighted linear regression, with each feature assigned a coefficient.\n\nAnd we can prove that, in the special choice, the coefficient can be the shaplely values. **This weighting scheme is the basis of the Shapley Kernal.** In this situation, the weighted linear regression process as a whole is Kernal SHAP.\n\n### Different types of SHAP\n\n- **Kernal SHAP**\n- Low-order SHAP\n- Linear SHAP\n- Max SHAP\n- Deep SHAP\n- Tree SHAP\n\n![](Deep%20Learning%20And%20Machine%20Learning/Model_interpretability/attachments/Pasted%20image%2020230329205130.png)\n\n### You need to notice\nWe can see that, we calculate shapley values using linear regression lastly. So there must be the error here, but some python packages can not give us the error bound, so it’s confusion to konw if this error come from linear regression or the data, or the model.\n\n\n# Reference\n\n[Shapley Additive Explanations (SHAP)](https://www.youtube.com/watch?v=VB9uV-x0gtg)\n\n[SHAP: A reliable way to analyze your model interpretability](https://towardsdatascience.com/shap-a-reliable-way-to-analyze-your-model-interpretability-874294d30af6)\n\n[【Python可解释机器学习库SHAP】：Python的可解释机器学习库SHAP](https://zhuanlan.zhihu.com/p/483622352)\n\n[Shapley Values : Data Science Concepts](https://www.youtube.com/watch?v=NBg7YirBTN8)\n\n# Appendix\n\nOther methods to interprete model:\n\n[Papers with Code - SHAP Explained](https://paperswithcode.com/method/shap)","lastmodified":"2023-03-30T12:42:55.330554194Z","tags":null},"/Hardware/Hardware_MOC":{"title":"Hardware - MOC","content":"\n# Microcontroller unit (MCU)\n\n## Basic concepts\n\n* [Different programming interfaces](Hardware/MCU/Different%20programming%20interfaces.md)\n","lastmodified":"2023-03-30T12:42:55.342554393Z","tags":null},"/Hardware/MCU/Different-programming-interfaces":{"title":"Different programming interfaces","content":"# What is programming interfaces in MCU\n\nA **programming interface** is a device that allows a programmer to connect to a microcontroller (MCU) and program it. The programming interface is used to load the program into the MCU’s memory and debug it.\n\n# Different types of programming interfaces in MCU\nChipmakers have different names for programming interfaces that all basically do the same thing:\n-   ISP - programming interface for Atmel (now Microchip) AVRs. SPI-like (MISO, MOSI, SCK, reset). It can be used for flash programming and debugging.\n-   PDI - newer programming interface for Atmel AVRs (eg. Xmega). Uses two wires (data and clock). Can do the same as ISP.\n-   DebugWire - yet another interface from Atmel (this one uses only a single wire)\n-   ICSP - programming interface for Microchip PIC line of MCUs\n-   SWD - Serial Wire Debug - programming interface for MCUs with ARM Cortex-M cores (uses two wires - data and clock)\n-   JTAG - very generic term, SPI-like interface used for [boundary scan](https://en.wikipedia.org/wiki/Boundary_scan), can also be used for programming/debugging MCUs (almost every vendor has its own protocol, so Cortex-M JTAG is not the same as AVR JTAG or Blackfin JTAG)\n-   Spy-Bi-Wire - yet another two wire programming interface, this one is for TI's MSP430 MCUs\n\n## SWD 和 JTAG的区别\n\n目前在使用的st link可以使用SWD和JTAG这两种debugger去调试stm32，所以这两种方式的区别令人比较在意；\n* JTAG（Joint Test Action Group，联合测试行动小组）是一种国际标准测试协议，主要用于芯片内部测试。现在多数的高级器件都支持JTAG协议，如ARM、DSP、FPGA器件等。JTAG调试接口必须使用VCC、GND电源信号，以及TMS、TCK、TDI、TDO四根调试信号，可选TRST、RESET复位信号和RTCK（同步时钟）信号。\n\t* TMS(Test Mode Select)：模式选择，TMS用来设置JTAG接口处于某种特定的测试模式；\n\t* TCK(Test Clock)：时钟输入；\n\t* TDI(Test Data Input)：数据输入，数据通过TDI引脚输入JTAG接口；\n\t* TDO(Test Data Output)：数据输出，数据通过TDO引脚从JTAG接口输出；\n* 串行调试（Serial Wire Debug），是一种和JTAG不同的调试模式，使用的调试协议也不一样，所以最直接的体现在调试接口上，与JTAG的20个引脚相比，SWD只需要4个（或者5个）引脚，结构简单，但是使用范围没有JTAG广泛，主流调试器上也是后来才加的SWD调试模式。\n\t* SWDIO：串行数据输入输出，作为仿真信号的双向数据信号线，建议上拉；\n\t* SWCLK：串行时钟输入，作为仿真信号的时钟信号线，建议下拉；\n\t* SWO：串行数据输出引脚，CPU调试接口可通过SWO引脚输出一些调试信息。该引脚是可选的；\n\t* RESET：仿真器输出至目标CPU的系统复位信号，该引脚也为可选\n\n* SWD模式比JTAG在高速模式下面更加可靠。在大数据量的情况下面JTAG下载程序会失败，但是SWD发生的几率会小很多。*基本使用JTAG仿真模式的情况下是可以直接使用SWD模式的，只要你的仿真器支持。*\n* 在GPIO刚好缺一个的时候，可以使用SWD仿真，这种模式支持更少的引脚。\n\n\n* 同时JTAG调试版本不同的情况下：\n\t* JTAGV6 需要的硬件接口为: GND, RST, SWDIO, SWDCLK；\n\t* JTAGV7 需要的硬件接口为: GND, RST, SWDIO, SWDCLK，相对V6， 其速度有了明显的提高，速度是 JTAGV6 的 6 倍。 \n\t* JTAGV8 需要的硬件接口为: VCC, GND, RST, SWDIO, SWDCLK，速度可以到 10M。\n\n\n\n# Reference\n\n[JTAG, SWD, EDBG, ICSP, ISP terms - Electrical Engineering Stack Exchange](https://electronics.stackexchange.com/questions/412029/jtag-swd-edbg-icsp-isp-terms)\n\n[jtag和swd的区别_jtag和swd区别_耶稣赞我萌的博客-CSDN博客](https://blog.csdn.net/yym6789/article/details/88721409)\n\n[STM32的JTAG和SWD模式_学术马的博客-CSDN博客](https://blog.csdn.net/w1050321758/article/details/108663603)\n","lastmodified":"2023-03-30T12:42:55.342554393Z","tags":null},"/Photography/Cameras_Research/Polaroid/Polaroid":{"title":"Polaroid","content":"\n# Polaroid Background\n\n![](Photography/Cameras_Research/Polaroid/attachments/Pasted%20image%2020230330195031.png)\n\nPolaroid是一家成立于1937年的美国相机及照片制造公司，该公司曾经是即时相机市场的领导者。Polaroid公司在20世纪50年代推出了第一台即时相机，并在随后的几十年里不断推出各种型号的即时相机和胶片，成为了全球广泛使用的品牌。\n\nPolaroid最著名的特点之一是它的“即时影像”技术，这种技术可以使用户在拍摄后几秒钟内看到他们所拍摄的照片。Polaroid的即时相机成为了许多人记录重要时刻和创造独特艺术作品的选择。\n\n除了即时相机，Polaroid还生产和销售其他相机、相机附件、数码相框和照片打印机等产品。此外，Polaroid还与其他品牌合作，推出了许多联名款式的相机和其他产品。\n\n在Polaroid成立近90年的历史中，它的相机和胶片已经成为了文化和艺术的象征，并继续影响着人们对摄影和影像创作的认知。\n\n# Polaroid Camera Review\n\n* [Polaroid one600](Photography/Cameras_Research/Polaroid/Polaroid_one600.md)\n* [Polaroid Integral 600 Series](Photography/Cameras_Research/Polaroid/Polaroid_600.md)\n","lastmodified":"2023-03-30T12:42:55.342554393Z","tags":null},"/Photography/Cameras_Research/Polaroid/Polaroid_600":{"title":"Polaroid 600","content":"\n# Reference\n\n* [How do I use my Vintage Polaroid 600 camera? – Retrospekt](https://retrospekt.com/blogs/ask-the-expert/how-do-i-use-my-vintage-polaroid-600-instant-camera)\n* [Polaroid Integral 600 Series - Camera-wiki.org - The free camera encyclopedia](http://camera-wiki.org/wiki/Polaroid_Integral_600_Series)\n","lastmodified":"2023-03-30T12:42:55.342554393Z","tags":null},"/Photography/Cameras_Research/Polaroid/Polaroid_one600":{"title":"Polaroid_one600","content":"\n\n![](Photography/Cameras_Research/Polaroid/attachments/Pasted%20image%2020230330195707.png)\n\n# Specifications\n\n- **(Wide) 100mm lens with minimum focus distance of 3 feet.**\n- **Maximum Aperture F12.9 (Don't know if it can change)**\n- **1/200 s to 1/3 s**\n- **Fixed focus.**\n- Exposure modes - **Program automatic**\n- \"Aerodynamic\" styling (particularly when folded) with downward curve at back.\n- Flash moved to right hand side of user and can be manually switched on and off.\n- Hand grip on right.\n- LCD frame counter.\n- Self-timer.\n\n## Functionally similar models\n\n-   Polaroid One (silver/grey)\n-   Polaroid One600 Job Pro (black/silver/yellow) (Close-focus to 18 inches!)\n-   Polaroid One600 Nero (all black)\n-   Polaroid One600 \"Flowers\" (white with purple and yellow flower design)\n-   Polaroid One600 Panna (white/black)\n-   Polaroid One600 \"Poison Frog\" (silver/grey with yellow/black pattern)\n-   Polaroid One600 Polala 2006 (red/silver with gold Chinese dragon)\n-   Polaroid One600 Pro (all silver) (Like Job Pro, close-focus to 18 inches!)\n-   Polaroid One600 Royksopp (grey/silver with 'Royksopp - Only This Moment' branding)\n-   Polaroid One600 Superheadz Special Edition Red Hat (silver/black, with 'red hat' cartoon character)\n-   Polaroid One600 Rossa (bright red/black)\n-   Polaroid One Rossa (as above)\n-   Polaroid One Ultra (silver/black) (Close focus to 2 feet)\n-   Polaroid Pop Kit (silver/black with stickers for user's customization)\n\n# Reference\n\n* [Polaroid One 600 Camera Review - by Dan Finnen](https://danfinnen.com/review/polaroid-one-600-camera-review/)\n* [Polaroid One600 (Classic) - Camera-wiki.org - The free camera encyclopedia](http://camera-wiki.org/wiki/Polaroid_One600_(Classic))\n","lastmodified":"2023-03-30T12:42:55.342554393Z","tags":null},"/Photography/Photography_MOC":{"title":"Photography - MOC","content":"\n# 🌊Photo Portfolio\nYou can see my photography works in:\n\n* [🎨Slide show](https://pinkr1ver.com/PhotoGallery/)\n* [🌄Photo Collection in Notion](https://www.notion.so/pinkr1ver/3cfdd332b9a94b20bca041f2aa2bdcd2?v=24e696e6ab754386a710bc8e83976357)\n* [🍻Instagram](https://www.instagram.com/jude.wang.yc/?next=%2F)\n* [🧶小红书](https://www.xiaohongshu.com/user/profile/6272c025000000002102353b)\n\n# Notes\nAlso, here's my notes about learning photography\n\n## About Basic Concepts:\n\n* [Saturation](Photography/Saturation.md)\n\n## Appreciation of other works - about ***aesthetic***\n\n* [🦺搬运UP主 - 豆腐素包](https://space.bilibili.com/196700312/video)\n* [👧Portrait](Photography/Portrait.md)\n\n## Camera Research\n\n* [✨Polaroid](Photography/Cameras_Research/Polaroid/Polaroid.md)\n\n# Reference\n\n## Platform\n\n* [Magnum Photos](https://www.magnumphotos.com/)\n* [CNU - Catch Next Ultimate](http://www.cnu.cc/)\n\n## Greatest Artist\n\n* [linksphotograph](https://www.linksphotograph.com/)\n* [HAMADA Hideaki / 濱田英明](https://www.hideakihamada.com)\n* [Jason Kummerfeldt](https://graincheck.darkroom.com/) and [his youtube](https://www.youtube.com/@grainydaysss)\n* [Marta Bevacqua](https://www.martabevacquaphotography.com/)\n* [Sam Zhang](https://www.instagram.com/itscapturedbysam/)","lastmodified":"2023-03-30T12:42:55.342554393Z","tags":null},"/Photography/Portrait":{"title":"👧Portrait","content":"\n* [🌸Flower \u0026 Girl](Photography/Portrait/Flower_and_Girl.md)\n* [🇰🇷Cute Portrait from Korean MV \u003cToday's Mood\u003e](Photography/Portrait/From%20Korean%20MV%20Todays_Mod.md)\n","lastmodified":"2023-03-30T12:42:55.342554393Z","tags":null},"/Photography/Portrait/Flower_and_Girl":{"title":"🌸Flower \u0026 Girl","content":"\nCredits to [Marta Bevacqua](https://www.martabevacquaphotography.com/), \nThanks🌸\n\n![](Photography/Portrait/attachments/14.jpg)\n\n![](Photography/Portrait/attachments/15.jpg)\n\n![](Photography/Portrait/attachments/16.jpg)\n\n![](Photography/Portrait/attachments/17.jpg)\n\n![](Photography/Portrait/attachments/18.jpg)\n\n![](Photography/Portrait/attachments/19.jpg)\n\n![](Photography/Portrait/attachments/20.jpg)\n\n![](Photography/Portrait/attachments/21.jpg)\n\n![](Photography/Portrait/attachments/22.jpg)\n\n![](Photography/Portrait/attachments/content%20(1).jpg)\n\n![](Photography/Portrait/attachments/content%20(2).jpg)\n\n![](Photography/Portrait/attachments/content%20(3).jpg)\n\n![](Photography/Portrait/attachments/content%20(4).jpg)\n\n![](Photography/Portrait/attachments/content%20(5).jpg)\n\n![](Photography/Portrait/attachments/content%20(6).jpg)\n\n![](Photography/Portrait/attachments/content%20(7).jpg)\n\n![](Photography/Portrait/attachments/content%20(8).jpg)\n\n![](Photography/Portrait/attachments/content%20(9).jpg)\n\n![](Photography/Portrait/attachments/content%20(11).jpg)\n\n![](Photography/Portrait/attachments/content%20(12).jpg)\n\n![](Photography/Portrait/attachments/content.jpg)\n\n","lastmodified":"2023-03-30T12:42:55.342554393Z","tags":null},"/Photography/Portrait/From-Korean-MV-Todays_Mod":{"title":"Cute Portrait from Korean MV \u003cToday's Mood\u003e","content":"\nCredits to [MV - CHEEZE(치즈) _ Today's Mood(오늘의 기분)](https://www.youtube.com/watch?v=zRq_DlEzygk),\nThanks\n\nAlso, I see this in [摄影灵感｜那有一点可爱 - by   \n小八怪](https://www.xiaohongshu.com/explore/63f0a27e0000000013002b05)\n\n![](Photography/Portrait/attachments/photo_4_2023-03-27_23-53-20.jpg)\n\n![](Photography/Portrait/attachments/photo_5_2023-03-27_23-53-20.jpg)\n\n![](Photography/Portrait/attachments/photo_6_2023-03-27_23-53-20.jpg)\n\n![](Photography/Portrait/attachments/photo_7_2023-03-27_23-53-20.jpg)\n\n![](Photography/Portrait/attachments/photo_8_2023-03-27_23-53-20.jpg)\n\n![](Photography/Portrait/attachments/photo_9_2023-03-27_23-53-20.jpg)\n\n![](Photography/Portrait/attachments/photo_1_2023-03-27_23-53-20%201.jpg)\n\n![](Photography/Portrait/attachments/photo_2_2023-03-27_23-53-20%201.jpg)\n\n![](Photography/Portrait/attachments/photo_3_2023-03-27_23-53-20%201.jpg)\n\n![](Photography/Portrait/attachments/photo_2023-03-27_23-55-45.jpg)","lastmodified":"2023-03-30T12:42:55.342554393Z","tags":null},"/Photography/Saturation":{"title":"Saturation - 饱和度","content":"\nto be written...","lastmodified":"2023-03-30T12:42:55.362554724Z","tags":null},"/Signal-Processing/Basic-Concepts-in-Signal-Processing":{"title":"Basic Concepts in Signal Processing","content":"\n* [What is dB](Signal%20Processing/What%20is%20dB.md)","lastmodified":"2023-03-30T12:42:55.362554724Z","tags":null},"/Signal-Processing/Signal-Processing_MOC":{"title":"Signal Processing - MOC","content":"\n* [Basic Concepts in Signal Processing](Signal%20Processing/Basic%20Concepts%20in%20Signal%20Processing.md)\n","lastmodified":"2023-03-30T12:42:55.362554724Z","tags":null},"/Signal-Processing/What-is-dB":{"title":"What is dB","content":"dB is short for decibel, which is a unit that indicates ratio or gain. It is often used to measure *sound intensity*, *signal strength*, *attenuation* and other quantities. \n\nFor example, if a sound has a power of 10 W and another sound has a power of 1 W, then the difference in decibels is 10 dB = 10 log (10/1) = 10 log 10 = 10.\n\n**Signal Noise Ratio** is also measured by dB\n\n## Signal Noise Ratio\n$$\n{SNR}_{power}=\\frac{\\text{Average Signal Power}}{\\text{Average Noise Power}}\n$$\n\n$$\n{SNR}_{voltage}=\\frac{\\text{RMS Signal Voltage}}{\\text{RMS Noise Voltage}}\n$$\n\n$$\n{SNR}_{power}={{SNR}_{voltage}}^2\n$$\n\n$$\n{SNR}_{dB}=10\\log_{10}{{SNR}_{power}}=20\\log_{10}{{SNR}_{voltage}}\n$$\n","lastmodified":"2023-03-30T12:42:55.362554724Z","tags":null},"/Synthetic-Aperture-Radar-Imaging/Antenna":{"title":"Antenna","content":"\n# Theorem\n\n## 谐振电路 (Resonant circuit) - RLC for example\n\n### 什么是谐振\n\n电路中电容器$L$、电感器$C$两组件之能量相等，当能量由电路中某一电抗组件释出时，且另一电抗组件必吸收相同之能量，即此两电抗组件间会产生一能量脉动。\n\n### 两种简单的谐振电路\n\n![](Synthetic%20Aperture%20Radar%20Imaging/attachments/Pasted%20image%2020230330160535.png)\n\n\n#### *Resonant Frequency*\n\n电容，电阻的[电抗](Circuit/Basic/Electric_units.md#Electrical%20impedance)相同时发生谐振\n\n$$\n|X_C| = |\\frac{1}{j2\\pi fC}| = |X_L| = |j2\\pi fL|\n$$\nRearranging,\n\n$$\nf^2 =  \\frac{1}{(2\\pi)^2 C L}\n$$\n\n$$\nf = \\frac{1}{2\\pi \\sqrt{LC}}\n$$\n\n","lastmodified":"2023-03-30T12:42:55.362554724Z","tags":null},"/Synthetic-Aperture-Radar-Imaging/Electromagnetic_Theory":{"title":"Electromagnetic Theory","content":"\n","lastmodified":"2023-03-30T12:42:55.362554724Z","tags":null},"/Synthetic-Aperture-Radar-Imaging/Radiometric-Calibration":{"title":"Radiometric Calibration - 辐射校准","content":"\n# Overview\nSAR 校准旨在提供其像素值可与场景中的雷达反向散射直接相关的影像。虽然未校准的 SAR 影像足以用于定性用途，但校准后的 SAR 影像对于定量使用 SAR 数据而言仍至关重要。\n\n生成级别 1 影像的典型 SAR 数据处理不包括辐射校正，且仍然存在明显的辐射偏差。因此有必要对 SAR 影像应用辐射校正，*使影像的像素值真正能够反映反射表面的雷达反向散射情况*。在比较由不同的传感器采集的 SAR 影像时，或比较由同一传感器在不同时间、不同模式下采集的（或由不同处理器处理的）SAR 影像时，都需要进行辐射校正。\n\n## Types\n* **Sigma nought** - 用于校准地面上单位面积内返回到天线的反向散射，并与地面范围相关。影像经过校准，因此可以直接与相同或不同传感器收集的不同雷达影像进行比较。科学家倾向于使用 sigma naught 来解释表面散射、表面反射以及表面属性。\n\t* *Scattering coefficient*, or the conventional measure of the strength of radar signals reflected by a distributed scatterer, usually expressed in dB. It is a *normalised dimensionless number*, comparing the strength observed to that expected from an area of one square meter. Sigma nought is defined with respect to the nominally horizontal plane, and in general has a significant variation with **incidence angle**, **wavelength**, and **polarisation**, as well as with **properties of the scattering surface itself**.\n* **Beta nought** - 可生成包含雷达亮度系数的数据集（雷达亮度系数是天线发射功率与接收功率之比）。它与倾斜范围有关，且无维度。\n* **Gamma** - 通常在校准天线时使用。因为每个范围像元与卫星的距离均相等，所以近距范围和远距范围的亮度均相等，这有助于确定输出数据集中的天线方向图。\n* **None** - 不做校正\n\n\n\n# Reference\n\n* [Sentinel-1 Radiometric Calibration—ArcMap | Documentation (arcgis.com)](https://desktop.arcgis.com/en/arcmap/latest/manage-data/raster-and-images/sentinel-1-radiometric-calibration.htm)\n\n* [Urban objects detection from C-band synthetic aperture radar (SAR) satellite images through simulating filter properties | Scientific Reports (nature.com)](https://www.nature.com/articles/s41598-021-85121-9)\n\n* [✨✨✨User Guides - Sentinel-1 SAR - Definitions - Sentinel Online - Sentinel Online (esa.int)](https://sentinel.esa.int/web/sentinel/user-guides/sentinel-1-sar/definitions)\n\n","lastmodified":"2023-03-30T12:42:55.362554724Z","tags":null},"/Synthetic-Aperture-Radar-Imaging/SAR-Explained":{"title":"Synthetic Aperture Radar (SAR) Explained","content":"\n# Radar Basic Concepts\n\n## Down Looking vs. Side Looking\n\n![Pasted image 20230320150424](Synthetic%20Aperture%20Radar%20Imaging/attachments/Pasted%20image%2020230320150424.png)\n\nDown Looking不能区分距离一样的a，b点，一般只用于monitoring of air and naval traffic\n\n## Simplified explanation of Radar working \u0026 What is SAR\nThe radar consists fundamentally of *a transmitter*, *a receiver*, *an antenna* and *an electronic system* to process and record the data.\n\nThe transmitter generates successive short bursts or pulses of microwave at regular intervals which are focused by the antenna into a beam. Radar beam illuminates the surface **obliquely** at a right angle to the motion of the platform. The antenna receives a portion of the transmitted energy reflected or it's known as backscattered from various objects within the illuminated beam by  measuring this time delay between the transmission of a pulse and the reception of the backscattered echo from different  targets. Their distance from the radar and therefore their location can be determined as the sensor platform *moves forward* recording and processing of the backscattered signals builds up a 2-dimensional image of the surface.\n\n\n\u003e [!important] \n\u003e Important\u003cbr\u003e\n\u003e The along track **resolution** is determined by the beam width which is *inversely proportional to the antenna length*, also known as the **aperture**, which means that longer antenna or a longer aperture will produce a narrow beam and a finer resolution. \u003cbr\u003e\n\u003e Long antenna $\\leftrightarrow$ Small beam $\\leftrightarrow$ Long aperture $\\leftrightarrow$ Better image resolution\n\n### Detail geometry\n\n![](Synthetic%20Aperture%20Radar%20Imaging/attachments/Pasted%20image%2020230330153450.png)\n**Fig** *Geometry of a side-looking real aperture radar. (SLAR)*\n\nside-looking的雷达被分为two types —— real aperture radar(*SLAR or SLR*, SL for side-looking)和synthetic aperture radar(SAR)\n\n如上图所示，雷达发出的pulse被[antenna聚焦](Synthetic%20Aperture%20Radar%20Imaging/Antenna.md)在一个narrow的area里，然后scatter后在不同和的时间再被receiver接收\n\n\n### Why SAR\n介于实际情况下的物理空间中，雷达天线的大小是限的，可以通过雷达的移动去模拟长天线情况下的雷达，也就是活得更大的aperture，这项被叫做SAR。目的是在于使用*comparatively small physical antennas*去获得*high resolution images*\n\n\n## Review of Radar Image Formation\n\n![660](Synthetic%20Aperture%20Radar%20Imaging/attachments/Pasted%20image%2020230320163240.png)\n\n* Radar can measure *amplitude* and *phase*\n* Radar can only measure part of echoes.\n* The strength of the reflected echo is the backscattering coefficient ([sigma nought](Synthetic%20Aperture%20Radar%20Imaging/Radiometric%20Calibration.md)）and is expressed in [decibels(dB)](Signal%20Processing/What%20is%20dB.md)\n\n## Radar Resolution\n\n\n\n## Radar Key Parameters\n* Wave Length\n* Polarization\n* Incidence Angle\n\n### Wave Length\n\n![](Synthetic%20Aperture%20Radar%20Imaging/attachments/Pasted%20image%2020230330153007.png)\n\n雷达数据的空间分辨率与传感器波长与传感器天线长度之比直接相关。 对于给定的波长，天线越长，空间分辨率越高。 对于以大约 5 cm 波长运行的太空卫星（C 波段雷达），为了获得 10 m 的空间分辨率，您需要一个大约 4,250 m 长的雷达天线。 （超过 47 个足球场！）\n\n\n# Reference\n\n* [Theory of Synthetic Aperture Radar (uzh.ch)](https://www.geo.uzh.ch/~fpaul/sar_theory.html)\n\n* ***Sentinel-1** is a famous SAR, you can find almost every *definitions* of SAR in this page:\n[User Guides - Sentinel-1 SAR - Definitions - Sentinel Online - Sentinel Online (esa.int)](https://sentinel.esa.int/web/sentinel/user-guides/sentinel-1-sar/definitions)\n\n* [SAR(Synthetic Aperture Radar)基础(一) - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/98053986)","lastmodified":"2023-03-30T12:42:55.362554724Z","tags":null},"/Synthetic-Aperture-Radar-Imaging/SAR_MOC":{"title":"Synthetic Aperture Radar (SAR) Imaging - MOC","content":"\n* [[Synthetic Aperture Radar Imaging/SAR Explained|SAR Explained]]\n","lastmodified":"2023-03-30T12:42:55.362554724Z","tags":null}}