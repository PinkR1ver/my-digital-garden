{"/":{"title":"Home","content":"\n🕵️‍♂️ This is Jude Wang's vault about his notebook, his knowledge, his second brain. \n\n🚧 There are notebooks about his research career:\n\n* [Deep Learning](Deep_Learning_And_Machine_Learning/Deep%20_Learning_MOC.md)\n\n* [[Synthetic Aperture Radar Imaging/SAR_MOC| Synthetic Aperture Radar(SAR) Imaging]]\n\nAlso, his research needs some basic science to support\n\n* [Hardware](Hardware/Hardware_MOC.md)\n\n* [Physics](Physics/Physics_MOC.md)\n\n* [Signal Processing](Signal%20Processing/Signal%20Processing_MOC.md)\n\n🛶 Also, he learn some knowledge about his hobbies:\n\n* [📷 Photography](Photography/Photography_MOC.md)\n\n* [📮文学](文学/文学_MOC.md)\n\n🏔 Finally, here's my resume:\n\n* [🍉Resume](resume.md)\n\n","lastmodified":"2023-06-10T07:55:32.777172689Z","tags":null},"/%E6%96%87%E5%AD%A6/%E5%8F%A5%E5%AD%90/%E5%8F%A5%E5%AD%90":{"title":"句子","content":"\n* [🌸Love about](文学/句子/Love%20about.md)\n* [🌄Poem](文学/句子/Poem.md)\n* [🧗🏻‍♂️Motivation](文学/句子/Motivation.md)\n* [🧶Feeling](文学/句子/Feeling.md)\n* [📽Movie](文学/句子/Movie.md)\n* [🎹Novel](文学/句子/Novel.md)\n* [🥐Comments](文学/句子/Comments.md)\n* [🎺Music](文学/句子/Music.md)\n* [🧙‍♂️Wisdom](文学/句子/Wisdom.md)\n","lastmodified":"2023-06-10T07:55:32.813173214Z","tags":null},"/%E6%96%87%E5%AD%A6/%E5%8F%A5%E5%AD%90/Comments":{"title":"🥐Comments","content":"\n  \u003cstyle\u003e\n    p {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n\n    a {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n  \u003c/style\u003e\n\n\u003e [!quote] \n\u003e  From comments\n\u003e  \n\u003e   被一些影评人的高度评价给诈骗到了;看来不同人对浪漫的定义非常不同，对于有些人来说“宇宙”“存在”等词以及语焉不详的现代诗歌排列组合在一起即可触发内心浪漫情结，就跟大学生会用夏天、自由、苏打、快乐with黄油相机滤镜加字加字照片来营造自觉出众的氛围感朋友圈一样。女儿的线也太刻奇，套了一个寻找外星人的噱头、还有伪纪录片的形式，镜头的设计还有手持的感觉在大荧幕上显得非常粗糙，之前很喜欢导演那个《法制未来时》的短片,结果电影有种加长版视频的感觉，还是感觉撑不起来啊... ...\n\n\n--- \n\n\n \u003e [!quote] \n\u003e From CC98, credits to someone\n\u003e \n\u003e \n\u003e感觉你女朋友是那种 初中喜欢混混 高中喜欢体育生 军训喜欢教官 大学喜欢rapper 打工爱上领导 理发爱上托尼 看病爱上医生 离婚爱上律师的人\n\n\n--- \n\n\n\n\u003e [!quote] \n\u003e From a video talking about 坂本龙一 by [HOPICO](https://www.bilibili.com/video/BV1pa4y1T7v2/?spm_id_from=333.1007.top_right_bar_window_history.content.click\u0026vd_source=c47136abc78922800b17d6ce79d6e19f) \n\u003e \n\u003e 1. 脱下合成器的修饰之后，这首作品变成了一个最赤裸的样子。我们听过印象深刻的钢琴曲，我们热爱他们，我们在形容它们的时候，多数是“热情”、“悲伤”、“欢乐”、“雄伟”。但这首歌不一样，之于我第一次听到它的时候，我再想为什么会有一首歌，那么精确地，在开头把“安静”这两个字讲了出来，明明无声的真空才是最安静，可这几个音符勾勒出来的安静，就是胜过了无声的真空。我想，那是因为我们在这几个音符背后，仿佛能够看到一个作曲家，找到他的钢琴，好像全世界只剩下他们的样子。\n\u003e    \n\u003e    要说幸运的是，我亲眼见过教授带着管弦乐团的全编制演奏这首作品。虽然我内心一直觉得，这是一首寂寞的作品，我心中它最好的样子，就是保持在三人编制以下，但是我清楚记得，那天在现场听到最后一个段落时，我眼泪止不住地往下流，我还记得我当时心里想的是：“md，这么多年了，终于听到了”\n\u003e    \n\u003e    就像教授在后来采访里说的，它可能不是首好的电影配乐，因为它不需要画面就已经自成一体了。可是重新听到它地时候，仍然意气风发。\n\u003e    \n\u003e    \u003cp style=\"text-align: right\"\u003e——HOPICO 评价 「\u003ca href=\"https://music.apple.com/cn/album/merry-christmas-mr-lawrence-coda/1404842855?i=1404843053\"\u003eMerry Christmas, Mr. Lawrence\u003c/a\u003e」\u003c/p\u003e\n\u003e    \n\u003e 2. 坂本龙一小的时候很喜欢Beatles，甚至一度以为只有了解Beatles的人才能和自己做朋友。而「末代皇帝」当中，许多作品的录制，都是在abbey road 2号录影棚完成的，这里是The Beatles 1962年到1969年录音的地方。教授也通过这样的方式，和自己的偶像有了*重合*。\n\u003e    \n\u003e    而在这里录制的作品，就包括整部原声带当中我最喜欢的「Where is Armo?」，在这首歌的写作里，他构建出了一种徐徐前行，奔赴宿命的坦荡。\n\u003e    \n\u003e   \u003cp style=\"text-align: right\"\u003e——HOPICO 评价 「\u003ca href=\"https://music.apple.com/cn/album/where-is-armo/714659119?i=714659278\"\u003eWhere is Armo?\u003c/a\u003e」\u003c/p\u003e\n\u003e\n\u003e 3. 在这之后，教授有陆续发行自己钢琴演奏版本的「A Flower is Not A Flower」。如果说文金龙版本的是线状绵延的凄凉，那在教授钢琴的版本里，我们听到的是点状的，在夜里，一边开，一边败的花的失落之美。\n\u003e   \n\u003e\t  在教授这个阶段的很多作品里，我们都能找到类似的气质。或者说，教授本身就很擅长用琴键去勾勒这种气质。如果允许我用很自私的感受去总结的话，我想对于我而言就是，在这样的作品里，*哪怕是简单排列的单音，我们也能听到一边生长，一边流失*。\n\u003e\n\u003e    \u003cp style=\"text-align: right\"\u003e——HOPICO 评价 「\u003ca href=\"\"\u003eA Flower is Not A Flower\u003c/a\u003e」\u003c/p\u003e\n\u003e\n\u003e 4. 伟大的艺术家是在不停迭代自己的生命周期\n\u003e   \n\u003e \u003cp style=\"text-align: right\"\u003e——「\u003ca href=\"https://www.imdb.com/title/tt6578572/\"\u003eRyuichi Sakamoto: Coda\u003c/a\u003e」\u003c/p\u003e\n\u003e\n\u003e 5. 教授大概说过这么一句话，就是，钢琴的声音按下去之后，会逐渐地开始衰减，哪怕非常微弱地持续，最后也会消失，所以他也渴望可以永恒发展下去的声音。\n\u003e    \n\u003e    而在「andata」这首作品里，我们可以听到在下面这段与管风琴音色所演奏出来的主旋律的稳定所呼应的是一种在持续出现的，让人不安或者不稳定的合成器的声响。这看似矛盾的两者出现在一起，正是一种异步。他在去除人为对音乐冠以的快乐、悲伤这些明显的情绪化的修饰。声音的产生和这种不规律是去人性的，是高于人为定义的，生命也是如此。\n\u003e    \n\u003e    \u003cp style=\"text-align: right\"\u003e——HOPICO 评价 「\u003ca href=\"https://music.apple.com/cn/album/andata/1507014129?i=1507014130\"\u003eandata\u003c/a\u003e」\u003c/p\u003e\n\u003e    \n\u003e   6.  专辑的概念「异步」通过不同的形式贯穿每一首作品，在下面这首音乐里，我们可以听到一个好像扮演心跳信号的音色，贯穿始终。一般的做法，可能会使这个音色的节律和作品的速度保持一致，然后同步落到作品的正拍上。但明显，在这部作品里，教授让这个心跳节律的音色和作品的拍子，处在一个完全异步的过程当中。*我自私的理解是*，**生命中的声音与音乐不和谐的共存，才是真实的空间。毕竟和谐在多数时候都是人为制造的巧合，而生命中巧合的几率又只是少数**。\n\u003e \n\u003e \u003cp style=\"text-align: right\"\u003e——HOPICO 评价 「\u003ca href=\"https://music.apple.com/cn/album/ubi/1507014129?i=1507014136\"\u003eubi\u003c/a\u003e」\u003c/p\u003e\n\u003e \n\n![](文学/句子/attachments/Pasted%20image%2020230409171853.png)\n\n\n--- \n\n\u003e [!quote] \n\u003e  [大卫·福斯特·华莱士](https://www.salon.com/1996/03/09/wallace_5/)，美国小说家\n\u003e  \n\u003e  每天，我会接触到250个广告和无数的娱乐选择，它们大部分都是由想卖给我东西的公司资助的。\n\u003e  \n\u003e  这就是世界对我产生影响的方式。我是一个作家，我的小说大量使用这些流行元素，这与100年前的小说家写花园散步和步行到河边取水的生活，并没有什么不同，人类的日常生活已经变了。\n\n","lastmodified":"2023-06-10T07:55:32.801173039Z","tags":null},"/%E6%96%87%E5%AD%A6/%E5%8F%A5%E5%AD%90/Feeling":{"title":"🧶Feeling","content":"\n  \u003cstyle\u003e\n    p {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n\n    a {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n  \u003c/style\u003e\n\n\u003e [!quote] \n\u003e A Sentence\n\u003e \n\u003e 一个太过于文艺的人注定不会快乐，因为心中有爱 有善良，骨子里住着孩子般的纯真，但也往往容易多愁善感，容易感知美好，也更容易体会悲伤。她喜欢文字，往往不善言辞，不是文字太少，而是感受太多。\n\u003e  \u003cp style=\"text-align:right\"\u003e——三毛\u003c/p\u003e\n\n\n--- \n\n\u003e [!quote] \n\u003e From bilibili vedio -  [陶喆给别人写的歌是什么水平?丨HOPICO](https://www.bilibili.com/video/BV1fo4y1z7jf/?spm_id_from=333.999.0.0\u0026vd_source=c47136abc78922800b17d6ce79d6e19f)\n\u003e \n\u003e 我们在面对回忆时，有一种态度就是，在疯狂之后都会回到安静里。举例证明，那大概就是在计程车后排，放空的眼神里，实际上在脑海中汹涌着，翻滚的回忆。\n\n\n--- \n\n\u003e [!quote] \n\u003e From JudeW, me\n\u003e \n\u003e 你的心软，世界的触感也更加真实\n\n\n--- \n\n\u003e [!quote] \n\u003e  A sentence\n\u003e  \n\u003e  “一个真正想死的人，不会再计较人们说什么，一个拿死说来说去的人，以我的经验来看并不是真的想死，而是......”   \n\u003e  \n\u003e  “而是什么？”  \n\u003e  \n\u003e  “而是还在......还在渴望爱。”\n\u003e  \n\u003e  \u003cp style=\"text-align: right\"\u003e——史铁生《务虚笔记》\u003c/p\u003e","lastmodified":"2023-06-10T07:55:32.801173039Z","tags":null},"/%E6%96%87%E5%AD%A6/%E5%8F%A5%E5%AD%90/Love-about":{"title":"🌸Love","content":"\n  \u003cstyle\u003e\n    p {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n\n    a {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n  \u003c/style\u003e\n\n  \u003e [!quote] \n\u003e [A poem](https://www.bilibili.com/video/BV1V24y1x7Nh/?buvid=YF4AFCFA7E0887094E329B9A6FADF98BF343\u0026is_story_h5=false\u0026mid=B1quk6Mlu6tnRY8zjwxWeg%3D%3D\u0026p=1\u0026plat_id=116\u0026share_from=ugc\u0026share_medium=iphone\u0026share_plat=ios\u0026share_session_id=4AD8E5F4-D617-499B-9C19-D5897A7EB825\u0026share_source=QQ\u0026share_tag=s_i\u0026timestamp=1679378304\u0026unique_k=tXa4xdJ\u0026up_id=315154029\u0026vd_source=c47136abc78922800b17d6ce79d6e19f) \u003cbr\u003e\n\u003e “至少有两次喜欢\u003cbr\u003e\n\u003e 一次发生在在一起之前，一次发生在之后，\u003cbr\u003e\n\u003e 第一次是喜欢上你。第二次是喜欢上我们，\u003cbr\u003e\n\u003e 我只敢把第二次翻译成爱，\u003cbr\u003e\n\u003e 第一次是因为你很好，第二次是因为我还没有坏到敢放满揉碎你的好。\u003cbr\u003e\n\u003e 我要小心的捧着第一次的喜欢，就像掏出一份手写的初稿，\u003cbr\u003e\n\u003e 你会接过我的目光，在岁月里重新誊写岁月，\u003cbr\u003e\n\u003e 要删改的地方还很多，包括但不限于，把差错翻译成幽默\u003cbr\u003e\n\u003e 改了还是存在啊，爱情本就是听起来很美的，阴差阳错”\n\n\n--- \n\n\u003e [!quote] \n\u003e A Sentence\n\u003e \n\u003e \"I am too full of life to be half-loved\"\n\u003e \n\n![400](文学/attachments/Pasted%20image%2020230321142115.png)\n\n---\n\n\u003e [!quote] \n\u003e [A poem](https://www.bilibili.com/video/BV1Vd4y187Tq/?buvid=YF4AFCFA7E0887094E329B9A6FADF98BF343\u0026is_story_h5=false\u0026mid=B1quk6Mlu6tnRY8zjwxWeg%3D%3D\u0026p=1\u0026plat_id=116\u0026share_from=ugc\u0026share_medium=iphone\u0026share_plat=ios\u0026share_session_id=F81E6185-E382-4E78-95FD-3155869F570B\u0026share_source=QQ\u0026share_tag=s_i\u0026timestamp=1679380048\u0026unique_k=Q9GSCLM\u0026up_id=2009238634\u0026vd_source=c47136abc78922800b17d6ce79d6e19f)\u003cbr\u003e\n\u003e  “他听的小众音乐，\u003cbr\u003e\n\u003e  第二天上了抖音热榜。\u003cbr\u003e\n\u003e  他爱吃的苍蝇小馆，\u003cbr\u003e\n\u003e  第二天全国连锁了一万家。\u003cbr\u003e\n\u003e  他爱的县城姑娘，\u003cbr\u003e\n\u003e  第二天出国留学再也没回来。\u003cbr\u003e\n\u003e  他觉得那些特别，\u003cbr\u003e\n\u003e  都已烟消云散，\u003cbr\u003e\n\u003e  可那些特别一直都在，\u003cbr\u003e\n\u003e  错就错在他认为特别\u003cbr\u003e\n\u003e  只属于他。”\u003cbr\u003e\n\u003e  \u003ca href=\"https://space.bilibili.com/2009238634\"\u003e\u003cp style=\"text-align:right\"\u003e——祺白石\u003c/p\u003e\u003c/a\u003e\n\n![400](文学/attachments/Pasted%20image%2020230321143300.png)\n\n--- \n\n\u003e [!quote] \n\u003e  From Network\n\u003e  \n\u003e  暗恋，像不停对焦的长镜头\n\n\n--- \n\n\u003e [!quote] \n\u003e  From [Xiaogongshu](https://www.xiaohongshu.com/explore/6466d391000000001300b055)\n\u003e  \n\u003e  标准是对不喜欢的人设定的，只有你才是例外和偏爱\n\n\n![](文学/句子/attachments/Pasted%20image%2020230519160552.png)\n\n","lastmodified":"2023-06-10T07:55:32.801173039Z","tags":null},"/%E6%96%87%E5%AD%A6/%E5%8F%A5%E5%AD%90/Motivation":{"title":"🧗🏻‍♂️Motivation","content":"\n  \u003cstyle\u003e\n    p {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n\n    a {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n  \u003c/style\u003e\n\n\u003e [!quote] \n\u003e A Sentence\n\u003e \n\u003e \"No easy basket\"\n\n“如果你想了解American篮球的根基，你要去看看美高”\n\n--- \n\n\u003e [!quote] \n\u003e  [人生是一个长板问题](https://github.com/ruanyf/weekly/blob/master/docs/issue-254.md)\n\u003e  \n\u003e  大家可能听说过“[水桶原理](https://baike.baidu.com/item/%E6%B0%B4%E6%A1%B6%E6%95%88%E5%BA%94/10942611)”：水桶的容量由最短的那块木板决定。\n\u003e  \n\u003e  它的意思是，某些系统的关键，不在于发展最强点，而在于避免最弱点。99%的地方都没有问题，只要1%的地方出现问题，整个系统就会失败。\n\u003e  \n\u003e  人体健康就是这样，有一个器官出现严重问题，哪怕其他器官完全正常，生活甚至生命就会受到影响。\n\u003e  \n\u003e  这类由短板决定的问题，统称为“**短板问题**”。日常生活有很多这样的例子，除了人体健康，还有食品安全，只要有一样成份不干净，你可能就会食物中毒。\n\u003e  \n\u003e  汽车、电视机、手机等消费品也是这样，只要有一个部件不合格，这个产品就有质量问题。\n\u003e  \n\u003e  但是，这不是今天的主题。我最近读到[一篇文章](https://www.experimental-history.com/p/science-is-a-strong-link-problem)，才意识到除了短板问题，还有长板问题\n\u003e  \n\u003e  **“长板问题”指的是，问题的关键不在于最弱点，而在于最强点。** 只要有一个点特别出色，这件事情就成功了，其他点的好坏无所谓。\n\u003e  \n\u003e  文艺作品就属于这种情况。你购买了一张专辑，其他的歌曲都不爱听，但是有一首歌你特别喜欢，这张专辑就值得了。电影和小说只要有一个角色或情节特别打动人，作品就成功了。\n\u003e  \n\u003e  风险投资也是这样，只要投了一个特别成功的项目，就能把所有损失补回来。\n\u003e  \n\u003e  最重要的是，**人生就是一个“长板问题”。** 一生中，失败和挫折其实不重要，多少次都不重要，只要有一次大的成功，人生就成功了。\n\u003e  \n\u003e  最大的那一次成功，决定了你一生的成就和高度。很多诺贝尔奖得主，一生就做出了一个重要的科学发现，就足够成为伟大科学家了。\n\u003e  \n\u003e  程序员写过多少代码不重要，只要创造过一个重大影响力的软件，职业生涯就成功了。\n\u003e  \n\u003e  **我们必须学会区分“短板问题”和“长板问题”，它们的解决方法完全不同。** 短板问题的解决，需要盯着薄弱环节，补齐最短的那块板；长板问题的解决，只需要推进最强的环节，不要在乎别的。\n\u003e  \n\u003e  人生不必在乎那些不重要的事情，没必要为了挫折和拒绝而沮丧，都会过去的。你要做的是向前看，拼命争取一次大的成功，让它足够大、更大，只要一次就够了。\n\n","lastmodified":"2023-06-10T07:55:32.801173039Z","tags":null},"/%E6%96%87%E5%AD%A6/%E5%8F%A5%E5%AD%90/Movie":{"title":"🎞Movie","content":"\n  \u003cstyle\u003e\n    p {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n\n    a {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n  \u003c/style\u003e\n\n\u003e [!quote] \n\u003e  铃芽之旅\n\u003e  \n\u003e  \"鎮住土地的是人心的重量。\"\n\n\n--- \n\n\n\u003e [!quote] \n\u003e  From comments\n\u003e  \n\u003e   被一些影评人的高度评价给诈骗到了;看来不同人对浪漫的定义非常不同，对于有些人来说“宇宙”“存在”等词以及语焉不详的现代诗歌排列组合在一起即可触发内心浪漫情结，就跟大学生会用夏天、自由、苏打、快乐with黄油相机滤镜加字加字照片来营造自觉出众的氛围感朋友圈一样。女儿的线也太刻奇，套了一个寻找外星人的噱头、还有伪纪录片的形式，镜头的设计还有手持的感觉在大荧幕上显得非常粗糙，之前很喜欢导演那个《法制未来时》的短片,结果电影有种加长版视频的感觉，还是感觉撑不起来啊... ...\n\n","lastmodified":"2023-06-10T07:55:32.801173039Z","tags":null},"/%E6%96%87%E5%AD%A6/%E5%8F%A5%E5%AD%90/Music":{"title":"🎺Music","content":"\n  \u003cstyle\u003e\n    p {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n\n    a {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n  \u003c/style\u003e\n\nMusic links usually link to apple music\n\n\u003e [!quote] \n\u003e From a video talking about 坂本龙一 by [HOPICO](https://www.bilibili.com/video/BV1pa4y1T7v2/?spm_id_from=333.1007.top_right_bar_window_history.content.click\u0026vd_source=c47136abc78922800b17d6ce79d6e19f) \n\u003e \n\u003e 1. 脱下合成器的修饰之后，这首作品变成了一个最赤裸的样子。我们听过印象深刻的钢琴曲，我们热爱他们，我们在形容它们的时候，多数是“热情”、“悲伤”、“欢乐”、“雄伟”。但这首歌不一样，之于我第一次听到它的时候，我再想为什么会有一首歌，那么精确地，在开头把“安静”这两个字讲了出来，明明无声的真空才是最安静，可这几个音符勾勒出来的安静，就是胜过了无声的真空。我想，那是因为我们在这几个音符背后，仿佛能够看到一个作曲家，找到他的钢琴，好像全世界只剩下他们的样子。\n\u003e    \n\u003e    要说幸运的是，我亲眼见过教授带着管弦乐团的全编制演奏这首作品。虽然我内心一直觉得，这是一首寂寞的作品，我心中它最好的样子，就是保持在三人编制以下，但是我清楚记得，那天在现场听到最后一个段落时，我眼泪止不住地往下流，我还记得我当时心里想的是：“md，这么多年了，终于听到了”\n\u003e    \n\u003e    就像教授在后来采访里说的，它可能不是首好的电影配乐，因为它不需要画面就已经自成一体了。可是重新听到它地时候，仍然意气风发。\n\u003e    \n\u003e    \u003cp style=\"text-align: right\"\u003e——HOPICO 评价 「\u003ca href=\"https://music.apple.com/cn/album/merry-christmas-mr-lawrence-coda/1404842855?i=1404843053\"\u003eMerry Christmas, Mr. Lawrence\u003c/a\u003e」\u003c/p\u003e\n\u003e    \n\u003e 2. 坂本龙一小的时候很喜欢Beatles，甚至一度以为只有了解Beatles的人才能和自己做朋友。而「末代皇帝」当中，许多作品的录制，都是在abbey road 2号录影棚完成的，这里是The Beatles 1962年到1969年录音的地方。教授也通过这样的方式，和自己的偶像有了*重合*。\n\u003e    \n\u003e    而在这里录制的作品，就包括整部原声带当中我最喜欢的「Where is Armo?」，在这首歌的写作里，他构建出了一种徐徐前行，奔赴宿命的坦荡。\n\u003e    \n\u003e   \u003cp style=\"text-align: right\"\u003e——HOPICO 评价 「\u003ca href=\"https://music.apple.com/cn/album/where-is-armo/714659119?i=714659278\"\u003eWhere is Armo?\u003c/a\u003e」\u003c/p\u003e\n\u003e\n\u003e 3. 在这之后，教授有陆续发行自己钢琴演奏版本的「A Flower is Not A Flower」。如果说文金龙版本的是线状绵延的凄凉，那在教授钢琴的版本里，我们听到的是点状的，在夜里，一边开，一边败的花的失落之美。\n\u003e   \n\u003e\t  在教授这个阶段的很多作品里，我们都能找到类似的气质。或者说，教授本身就很擅长用琴键去勾勒这种气质。如果允许我用很自私的感受去总结的话，我想对于我而言就是，在这样的作品里，*哪怕是简单排列的单音，我们也能听到一边生长，一边流失*。\n\u003e\n\u003e    \u003cp style=\"text-align: right\"\u003e——HOPICO 评价 「\u003ca href=\"\"\u003eA Flower is Not A Flower\u003c/a\u003e」\u003c/p\u003e\n\u003e\n\u003e 4. 伟大的艺术家是在不停迭代自己的生命周期\n\u003e   \n\u003e \u003cp style=\"text-align: right\"\u003e——「\u003ca href=\"https://www.imdb.com/title/tt6578572/\"\u003eRyuichi Sakamoto: Coda\u003c/a\u003e」\u003c/p\u003e\n\u003e\n\u003e 5. 教授大概说过这么一句话，就是，钢琴的声音按下去之后，会逐渐地开始衰减，哪怕非常微弱地持续，最后也会消失，所以他也渴望可以永恒发展下去的声音。\n\u003e    \n\u003e    而在「andata」这首作品里，我们可以听到在下面这段与管风琴音色所演奏出来的主旋律的稳定所呼应的是一种在持续出现的，让人不安或者不稳定的合成器的声响。这看似矛盾的两者出现在一起，正是一种异步。他在去除人为对音乐冠以的快乐、悲伤这些明显的情绪化的修饰。声音的产生和这种不规律是去人性的，是高于人为定义的，生命也是如此。\n\u003e    \n\u003e    \u003cp style=\"text-align: right\"\u003e——HOPICO 评价 「\u003ca href=\"https://music.apple.com/cn/album/andata/1507014129?i=1507014130\"\u003eandata\u003c/a\u003e」\u003c/p\u003e\n\u003e    \n\u003e   6.  专辑的概念「异步」通过不同的形式贯穿每一首作品，在下面这首音乐里，我们可以听到一个好像扮演心跳信号的音色，贯穿始终。一般的做法，可能会使这个音色的节律和作品的速度保持一致，然后同步落到作品的正拍上。但明显，在这部作品里，教授让这个心跳节律的音色和作品的拍子，处在一个完全异步的过程当中。*我自私的理解是*，**生命中的声音与音乐不和谐的共存，才是真实的空间。毕竟和谐在多数时候都是人为制造的巧合，而生命中巧合的几率又只是少数**。\n\u003e \n\u003e \u003cp style=\"text-align: right\"\u003e——HOPICO 评价 「\u003ca href=\"https://music.apple.com/cn/album/ubi/1507014129?i=1507014136\"\u003eubi\u003c/a\u003e」\u003c/p\u003e\n\u003e \n\n![](文学/句子/attachments/Pasted%20image%2020230409171853.png)\n\n\n--- \n\n\u003e [!quote] \n\u003e [身骑白马](https://music.apple.com/cn/album/%E8%BA%AB%E9%AA%91%E7%99%BD%E9%A9%AC/672648486?i=672648896), 徐佳莹 \n\u003e \n\u003e 而你却 靠近了\n\u003e \n\u003e 逼我们视线交错\n\n\n\n\n\n\n","lastmodified":"2023-06-10T07:55:32.801173039Z","tags":null},"/%E6%96%87%E5%AD%A6/%E5%8F%A5%E5%AD%90/Novel":{"title":"From Novel","content":"\n  \u003cstyle\u003e\n    p {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n\n    a {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n  \u003c/style\u003e\n\n\n\u003e [!quote] \n\u003e From CC98, credits to someone\n\u003e \n\u003e 很奇怪，与一个人告别之后男生记起来的永远是一些微不足道的细节，男生不知道女生的名字，也不记得女生常穿的衣服是什么颜色，男生忘掉了每天在桥边上等女生的时间，女生的眼睛也慢慢在男生的记忆里蒙尘。 \n\u003e \n\u003e 不过男生记得等女生时桥下的流水潺潺，也记得校园里某个角落他们经常去看的四叶草，记得第一次注意到女生时公交站顶上那片不同的落叶，也记得步道旁女生指给他看的树皮。 \n\u003e \n\u003e 后来男生看了阿尔瓦雷斯的《行走的距离》，里面有句话是“别人稍一注意你，你就敞开心扉，你觉得这是坦率，其实这是孤独。”\n\u003e \n\u003e  男生不知道自己是不是孤独，也不知道自己是不是坦率。男生不关心。 \n\u003e  \n\u003e  男生很感谢那个女生。 \n\u003e  \n\u003e  男生很想写下“不过男生并不想念那个女生”。 \n\u003e  \n\u003e  不过男生很想念那个女生。\n","lastmodified":"2023-06-10T07:55:32.801173039Z","tags":null},"/%E6%96%87%E5%AD%A6/%E5%8F%A5%E5%AD%90/Poem":{"title":"🖋Poem","content":"\n  \u003cstyle\u003e\n    p {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n\n    a {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n  \u003c/style\u003e\n\n\u003e [!quote] \n\u003e [A poem](https://www.bilibili.com/video/BV1V24y1x7Nh/?buvid=YF4AFCFA7E0887094E329B9A6FADF98BF343\u0026is_story_h5=false\u0026mid=B1quk6Mlu6tnRY8zjwxWeg%3D%3D\u0026p=1\u0026plat_id=116\u0026share_from=ugc\u0026share_medium=iphone\u0026share_plat=ios\u0026share_session_id=4AD8E5F4-D617-499B-9C19-D5897A7EB825\u0026share_source=QQ\u0026share_tag=s_i\u0026timestamp=1679378304\u0026unique_k=tXa4xdJ\u0026up_id=315154029\u0026vd_source=c47136abc78922800b17d6ce79d6e19f) \u003cbr\u003e\n\u003e “至少有两次喜欢\u003cbr\u003e\n\u003e 一次发生在在一起之前，一次发生在之后，\u003cbr\u003e\n\u003e 第一次是喜欢上你。第二次是喜欢上我们，\u003cbr\u003e\n\u003e 我只敢把第二次翻译成爱，\u003cbr\u003e\n\u003e 第一次是因为你很好，第二次是因为我还没有坏到敢放满揉碎你的好。\u003cbr\u003e\n\u003e 我要小心的捧着第一次的喜欢，就像掏出一份手写的初稿，\u003cbr\u003e\n\u003e 你会接过我的目光，在岁月里重新誊写岁月，\u003cbr\u003e\n\u003e 要删改的地方还很多，包括但不限于，把差错翻译成幽默\u003cbr\u003e\n\u003e 改了还是存在啊，爱情本就是听起来很美的，阴差阳错”\n\n---\n\n\u003e [!quote] \n\u003e [A poem](https://www.bilibili.com/video/BV1Vd4y187Tq/?buvid=YF4AFCFA7E0887094E329B9A6FADF98BF343\u0026is_story_h5=false\u0026mid=B1quk6Mlu6tnRY8zjwxWeg%3D%3D\u0026p=1\u0026plat_id=116\u0026share_from=ugc\u0026share_medium=iphone\u0026share_plat=ios\u0026share_session_id=F81E6185-E382-4E78-95FD-3155869F570B\u0026share_source=QQ\u0026share_tag=s_i\u0026timestamp=1679380048\u0026unique_k=Q9GSCLM\u0026up_id=2009238634\u0026vd_source=c47136abc78922800b17d6ce79d6e19f)\u003cbr\u003e\n\u003e  “他听的小众音乐，\u003cbr\u003e\n\u003e  第二天上了抖音热榜。\u003cbr\u003e\n\u003e  他爱吃的苍蝇小馆，\u003cbr\u003e\n\u003e  第二天全国连锁了一万家。\u003cbr\u003e\n\u003e  他爱的县城姑娘，\u003cbr\u003e\n\u003e  第二天出国留学再也没回来。\u003cbr\u003e\n\u003e  他觉得那些特别，\u003cbr\u003e\n\u003e  都已烟消云散，\u003cbr\u003e\n\u003e  可那些特别一直都在，\u003cbr\u003e\n\u003e  错就错在他认为特别\u003cbr\u003e\n\u003e  只属于他。”\u003cbr\u003e\n\u003e  \u003ca href=\"https://space.bilibili.com/2009238634\"\u003e\u003cp style=\"text-align:right\"\u003e——祺白石\u003c/p\u003e\u003c/a\u003e\n\n![400](文学/attachments/Pasted%20image%2020230321143300.png)\n\n--- \n\n\u003e [!quote] \n\u003e  From Network\n\u003e  \n\u003e  像不停对焦的长镜头\n\n","lastmodified":"2023-06-10T07:55:32.801173039Z","tags":null},"/%E6%96%87%E5%AD%A6/%E5%8F%A5%E5%AD%90/Wisdom":{"title":"🧙‍♂️Wisdom","content":"\n\u003e [!quote] \n\u003e  [人生是一个长板问题](https://github.com/ruanyf/weekly/blob/master/docs/issue-254.md)\n\u003e  \n\u003e  大家可能听说过“[水桶原理](https://baike.baidu.com/item/%E6%B0%B4%E6%A1%B6%E6%95%88%E5%BA%94/10942611)”：水桶的容量由最短的那块木板决定。\n\u003e  \n\u003e  它的意思是，某些系统的关键，不在于发展最强点，而在于避免最弱点。99%的地方都没有问题，只要1%的地方出现问题，整个系统就会失败。\n\u003e  \n\u003e  人体健康就是这样，有一个器官出现严重问题，哪怕其他器官完全正常，生活甚至生命就会受到影响。\n\u003e  \n\u003e  这类由短板决定的问题，统称为“**短板问题**”。日常生活有很多这样的例子，除了人体健康，还有食品安全，只要有一样成份不干净，你可能就会食物中毒。\n\u003e  \n\u003e  汽车、电视机、手机等消费品也是这样，只要有一个部件不合格，这个产品就有质量问题。\n\u003e  \n\u003e  但是，这不是今天的主题。我最近读到[一篇文章](https://www.experimental-history.com/p/science-is-a-strong-link-problem)，才意识到除了短板问题，还有长板问题\n\u003e  \n\u003e  **“长板问题”指的是，问题的关键不在于最弱点，而在于最强点。** 只要有一个点特别出色，这件事情就成功了，其他点的好坏无所谓。\n\u003e  \n\u003e  文艺作品就属于这种情况。你购买了一张专辑，其他的歌曲都不爱听，但是有一首歌你特别喜欢，这张专辑就值得了。电影和小说只要有一个角色或情节特别打动人，作品就成功了。\n\u003e  \n\u003e  风险投资也是这样，只要投了一个特别成功的项目，就能把所有损失补回来。\n\u003e  \n\u003e  最重要的是，**人生就是一个“长板问题”。** 一生中，失败和挫折其实不重要，多少次都不重要，只要有一次大的成功，人生就成功了。\n\u003e  \n\u003e  最大的那一次成功，决定了你一生的成就和高度。很多诺贝尔奖得主，一生就做出了一个重要的科学发现，就足够成为伟大科学家了。\n\u003e  \n\u003e  程序员写过多少代码不重要，只要创造过一个重大影响力的软件，职业生涯就成功了。\n\u003e  \n\u003e  **我们必须学会区分“短板问题”和“长板问题”，它们的解决方法完全不同。** 短板问题的解决，需要盯着薄弱环节，补齐最短的那块板；长板问题的解决，只需要推进最强的环节，不要在乎别的。\n\u003e  \n\u003e  人生不必在乎那些不重要的事情，没必要为了挫折和拒绝而沮丧，都会过去的。你要做的是向前看，拼命争取一次大的成功，让它足够大、更大，只要一次就够了。\n\n\n--- \n\n\n\u003e [!quote] \n\u003e  [《世界运作的几种方式》](https://collabfund.com/blog/one-big-web-a-few-ways-the-world-works/)\n\u003e  \n\u003e  金钱就像疫苗，它可以避免很多痛苦，但不一定会让你快乐。\n\n\n---\n\n\u003e [!quote] \n\u003e  [推特网友](https://twitter.com/landgren/status/1650054767987548160)\n\u003e  \n\u003e  AI 发展到最后，无非就是两种结果。一种是人类灵魂被证明只是一种基于概率算法的预测机制，另一种是 AI 发生了质变，产生了自主意识，拥有了与人类相似的灵魂。\n\n\n","lastmodified":"2023-06-10T07:55:32.801173039Z","tags":null},"/%E6%96%87%E5%AD%A6/%E6%96%87%E5%AD%A6_MOC":{"title":"文学","content":"\n  \u003cstyle\u003e\n    p {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n\n    a {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n  \u003c/style\u003e\n\nIn this MOC, it shows you the path to what I record for some interesting sentences, including Chinese and English, even Japanese.\n\n[🌌句子](文学/句子/句子.md)\n\n[📜原创诗](文学/Poem_by_me.md)\n","lastmodified":"2023-06-10T07:55:32.813173214Z","tags":null},"/%E6%96%87%E5%AD%A6/Poem_by_me":{"title":"My Poem","content":"\n  \u003cstyle\u003e\n    p {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n\n    a {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n  \u003c/style\u003e\n","lastmodified":"2023-06-10T07:55:32.793172922Z","tags":null},"/.trash/XGBoost-4f7e7664770b4a2c89107b59434de9ce/Untitled.png":{"title":"Untitled.png","content":"","lastmodified":"2023-06-10T07:55:31.329151367Z","tags":null},"/.trash/attachments/Pasted-image-20230320150424.png":{"title":"Pasted image 20230320150424.png","content":"","lastmodified":"2023-06-10T07:55:31.329151367Z","tags":null},"/Deep_Learning_And_Machine_Learning/Deep-_Learning_MOC":{"title":"Deep Learning - MOC","content":"\n* [Deep Learning Block \u0026 Machine Learning - MOC](Deep_Learning_And_Machine_Learning/Deep_Learning_Block_and_Machine_Learning_Block/Deep_Learning_Block_And_Machine_Learning_MOC.md)\n\n* [Model Interpretability](Deep_Learning_And_Machine_Learning/Model_interpretability/Model_Interpretability_MOC.md)\n\n* [Famous Model - MOC](Deep_Learning_And_Machine_Learning/Famous_Model/Famous_Model_MOC.md)\n\n* [Model Evaluation - MOC](Deep_Learning_And_Machine_Learning/Evaluation/model_evaluation_MOC.md)\n\n* [LLM - MOC](Deep_Learning_And_Machine_Learning/LLM/LLM_MOC.md)","lastmodified":"2023-06-10T07:55:31.329151367Z","tags":null},"/Deep_Learning_And_Machine_Learning/Deep_Learning_Block_and_Machine_Learning_Block/AdaBoost":{"title":"AdaBoost","content":"\n# Video you need to watch first\n\n* [AdaBoost, Clearly Explained](https://www.youtube.com/watch?v=LsK-xG1cLYA)\n\n# Key words and equation\n\n- **Stump(树桩) means classification just by one feature**\n- Amount of say\n\n$$\n\\text{Amout of say} = \\frac{1}{2}\\log{(\\frac{1-\\text{Total Error}}{\\text{Total Error}})}\n$$\n\n- Wrong Classified Sample New Weight\n\n$$\n\\text{New Sample Weight} = \\text{Sample Weight}\\times e^{\\text{amount of say}}\n$$\n\n- Correct Clasified Sample New Weight\n\n$$\n\\text{New Sample Weight} = \\text{Sample Weight}\\times e^{-\\text{amount of say}}\n$$\n\n- After reassing sample weight, do bootstrap sample based on their new weight, it will select big weight sample lots of times to adjust next model\n- In last prediction, the **amount of say** decide which results we will pick.\n\n# Question\n\n- **[why decision stumps instead of trees?](https://stats.stackexchange.com/questions/520667/adaboost-why-decision-stumps-instead-of-trees)**","lastmodified":"2023-06-10T07:55:31.329151367Z","tags":null},"/Deep_Learning_And_Machine_Learning/Deep_Learning_Block_and_Machine_Learning_Block/Attention":{"title":"⭐Attenion","content":"# Self-Attention\n\n讲述self-attention我们以*sequence labeling*任务作为任务来讲解，sequence labeling的任务是输入N个vector并且输出N个label。\n\n典型的例子有输入一个句子，分析每个词汇的词性是什么，比如句子“I saw a saw”，这个句子里saw和saw的词性分别是verb和nonu，如果我们用fully-connected（FC）层来做的话，那么面对同样的输入saw，我们无法得出不同的结果。\n\n![Pasted image 20230315195403](Deep_Learning_And_Machine_Learning/Deep_Learning_Block_and_Machine_Learning_Block/attachments/1.png)\n\n我们的做法可以是对输入加窗，考虑周边邻近的词汇信息，这与信号处理常用的方法类似，但是窗的长度是有限且固定的，而seq的长度是变化的，因此我们在面对这种任务的时候，我们可以借助**self-attention**层。\n\n## Detail\n\n![Pasted image 20230315195603](Deep_Learning_And_Machine_Learning/Deep_Learning_Block_and_Machine_Learning_Block/attachments/Pasted%20image%2020230315195603.png)\n\n对于Self-attention层，生成的$b^i$向量是考虑到所有输入$\\sum_i\\alpha^i$向量\n\n### Vector Relevance\n\n![250](Deep_Learning_And_Machine_Learning/Deep_Learning_Block_and_Machine_Learning_Block/attachments/Pasted%20image%2020230315200009.png)\n\n\n* *Step 1.* 使用Dot-product 去计算 vector relevance\n\n![400](Deep_Learning_And_Machine_Learning/Deep_Learning_Block_and_Machine_Learning_Block/attachments/Pasted%20image%2020230315201906.png)\n\n* *Step 2.* Normalizing计算出来的vector relevance\n![400](Deep_Learning_And_Machine_Learning/Deep_Learning_Block_and_Machine_Learning_Block/attachments/Pasted%20image%2020230315202047.png)\n\n* *Step 3.*  根据vector relevance，也就是attention scores计算最后的输出。这是一个Reweighting Process，一个extract information based on attention scores\n\n![400](Deep_Learning_And_Machine_Learning/Deep_Learning_Block_and_Machine_Learning_Block/attachments/Pasted%20image%2020230315202314.png)\n\n\u003e [!hint] \n\u003e  从上面的过程中，可以看出，$b^i$互相之间的计算没有关系，具有很好的并行性\n\n### Matrix Detail\n\n$$\nq^i = W^q \\alpha^i\n$$\n\n\n$$\nQ = [q^1 \\quad q^2 \\quad \\cdots \\quad q^N],\\ \\  I = [\\alpha^1 \\quad \\alpha^2 \\quad \\cdots \\quad \\alpha^N]\n$$\n\n\n\nSo,\n\n$$\nQ = W^q I\n$$\n\nAs same,\n$$\nK = W^k I,\\quad V = W^v I\n$$\nCalculate attention score $\\alpha$,\n$$\n\\begin{bmatrix}\n\\alpha_{1,1} \\\\\n\\alpha_{1,2} \\\\\n\\cdots \\\\\n\\alpha_{1,N}\n\\end{bmatrix} =\n\\begin{bmatrix}\nk^1 \\\\\nk^2 \\\\\n\\cdots \\\\\nk_N\n\\end{bmatrix} q^1\n$$\n\nSo,\n$$\nA=\\begin{bmatrix}\n\\alpha_{1,1} \u0026 \\alpha_{2,1} \u0026 \\cdots \u0026 \\alpha_{N,1} \\\\\n\\alpha_{1,2} \u0026 \\alpha_{2,2} \u0026 \\cdots \u0026 \\alpha_{N,2} \\\\\n\\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots\\\\\n\\alpha_{1,N} \u0026 \\alpha_{2,N} \u0026 \\cdots \u0026 \\alpha_{N,N}\n\\end{bmatrix} =\n\\begin{bmatrix}\nk^1 \\\\\nk^2 \\\\\n\\cdots \\\\\nk_N\n\\end{bmatrix} [q^1 \\quad q^2 \\quad \\cdots \\quad q^N] = K^TQ\n$$\n\n$$\nA' = \\text{Softmax}(A)\n$$\n\nFinally, calculate output $b$\n\n$$\nO = [b^1 \\quad b^2 \\quad \\cdots \\quad b^N] = [v^1 \\quad v^2 \\quad \\cdots \\quad v^N] = VA'\n$$\n\n![600](Deep_Learning_And_Machine_Learning/Deep_Learning_Block_and_Machine_Learning_Block/attachments/Pasted%20image%2020230315205148.png)\n\n### Positional Encoding\n![250](Deep_Learning_And_Machine_Learning/Deep_Learning_Block_and_Machine_Learning_Block/attachments/Pasted%20image%2020230315205727.png)\n* Each position has a unique positional vector $e^i$\n\t* hand-crafted\n\t* learned from data\n\n## Fun Facts\n\n### Self-attention vs. CNN\n\n![Pasted image 20230315205918](Deep_Learning_And_Machine_Learning/Deep_Learning_Block_and_Machine_Learning_Block/attachments/Pasted%20image%2020230315205918.png)\n\n因为transformer有着更大的function set，所以需求更多的数据; ![Pasted image 20230315210032](Deep_Learning_And_Machine_Learning/Deep_Learning_Block_and_Machine_Learning_Block/attachments/Pasted%20image%2020230315210032.png)\n\n### Self-attention vs. RNN\n\n目前，RNN的角色正在被self-attention替代，RNN在long seq的情况下，前面的信息会被逐渐遗忘；同时**RNN没有并行性**\n同样，Self attention有着比RNN更大的function set，在某些情况下，self-attention可以变成RNN\n\n# Multi-head Self-attention\nMulti-head self attention就是由不同的self attention layer在一起，有不同的$W^q$,$W^k$来负责不同种类的relevance\n\n![600](Deep_Learning_And_Machine_Learning/Deep_Learning_Block_and_Machine_Learning_Block/attachments/Pasted%20image%2020230315210631.png)\n![300](Deep_Learning_And_Machine_Learning/Deep_Learning_Block_and_Machine_Learning_Block/attachments/Pasted%20image%2020230315210704.png) ","lastmodified":"2023-06-10T07:55:31.397152382Z","tags":null},"/Deep_Learning_And_Machine_Learning/Deep_Learning_Block_and_Machine_Learning_Block/Decision_Tree":{"title":"Decision Tree","content":"\nOnly vedio here:\n\n* [Decision and Classification Trees, Clearly Explained!!!](https://www.youtube.com/watch?v=_L39rN6gz7Y\u0026t=229s \"Decision and Classification Trees, Clearly Explained!!!\")\n* [Regression Trees, Clearly Explained!!!](https://www.youtube.com/watch?v=g9c66TUylZ4\u0026t=789s \"Regression Trees, Clearly Explained!!!\")\n\n","lastmodified":"2023-06-10T07:55:31.329151367Z","tags":null},"/Deep_Learning_And_Machine_Learning/Deep_Learning_Block_and_Machine_Learning_Block/Deep_Learning_Block_And_Machine_Learning_MOC":{"title":"Deep Learning Block \u0026 Machine Learning - MOC","content":"\n\n# Attention is all you need\n\n* [[Deep_Learning_And_Machine_Learning/Deep_Learning_Block_and_Machine_Learning_Block/⭐Attention|Attention Blocker]]\n* [[Deep_Learning_And_Machine_Learning/Deep_Learning_Block_and_Machine_Learning_Block/Transformer|Transformer]]\n\n\n# Tree-like architecture\n\n* [Decision Tree](Deep_Learning_And_Machine_Learning/Deep_Learning_Block_and_Machine_Learning_Block/Decision_Tree.md)\n* [Random Forest](Deep_Learning_And_Machine_Learning/Deep_Learning_Block_and_Machine_Learning_Block/Random_Forest.md)\n* [Deep Neural Decision Forests](Deep_Learning_And_Machine_Learning/Deep_Learning_Block_and_Machine_Learning_Block/Deep_Neural_Decision_Forests.md)\n* [XGBoost](Deep_Learning_And_Machine_Learning/Deep_Learning_Block_and_Machine_Learning_Block/XGBoost.md)\n\n\n# Ensemble Learning\n\n* [AdaBoost](Deep_Learning_And_Machine_Learning/Deep_Learning_Block_and_Machine_Learning_Block/AdaBoost.md)\n* [XGBoost](Deep_Learning_And_Machine_Learning/Deep_Learning_Block_and_Machine_Learning_Block/XGBoost.md)\n\n\n# Time-series dealing block\n\n* [LSTM](Deep_Learning_And_Machine_Learning/Deep_Learning_Block_and_Machine_Learning_Block/LSTM.md)\n","lastmodified":"2023-06-10T07:55:31.329151367Z","tags":null},"/Deep_Learning_And_Machine_Learning/Deep_Learning_Block_and_Machine_Learning_Block/Deep_Neural_Decision_Forests":{"title":"Deep Neural Decision Forests","content":"\n# Background\n\n* [Decision Tree](Deep_Learning_And_Machine_Learning/Deep_Learning_Block_and_Machine_Learning_Block/Decision_Tree.md)\n* [Random Forest](Deep_Learning_And_Machine_Learning/Deep_Learning_Block_and_Machine_Learning_Block/Random_Forest.md)\n\n# What is Deep Neural Decision Forests\n\n![](Deep_Learning_And_Machine_Learning/Deep_Learning_Block_and_Machine_Learning_Block/attachments/Pasted%20image%2020230413112822.png)\n\nDeep Neural Decision Forests(dNDFs)是Neural Networks和Random Forest的结合，但是它更倾向于Neural Networks。它本质上是Nerual Networks incorporate Random Forest来提高NN的效率和准确度，训练方法和NN一致。\n\ndNDFs与NN的不同在output layer层发生变化，不单纯使用FC层输出，而是使用随机森林作为最后一层的分类器，相当于通过前面系统输出的data representation用随机森林作为分类器分类。**同时，通过将传统随机森林的local optimize改造成通过back propagation进行global optimize,随机森林的参数训练可以与前端的深度学习网络进行无缝衔接。**\n\n\u003e [!attention] \n\u003e  The method is different from random forest in the sense that it uses a principled, joint and global optimization of split and leaf node parameters and from conventional deep networks because a decision forest provides the final predictions\n\n# Math in Neural Decision Forests\n\nDecision Tree model要是stochastic的，为了让它differentiable，让后面可以通过back-propagation训练。在传统的decision tree模型中，从node到leaf的路径是由decision function确定的，而在这个模型中，我们将用two sets of probabilities去决定final output。\n\n1. Probability of an observation reaching to a leaf . These basically are associated with decision node/split node which decides whether an observation goes left or right\n2. Once an observation reaches a leaf node, probability that it takes a specific class\n\n \n\n# Reference\n\n* [Deep Neural Decision Forests - YouTube Vedio by  Venkatesh Bingi](https://www.youtube.com/watch?v=Uaimgqv75dY)\n* [Deep Neural Decision Forests - Medium by Gurparkash Singh Sohi](https://blog.goodaudience.com/deep-neural-decision-forests-b1dd39c4c6ce)\n* [Deep neural decision forest in keras - Medium by Kushal Mukherjee](https://kushalmukherjee.medium.com/deep-neural-decision-forest-in-keras-60134d270bfe)\n\n","lastmodified":"2023-06-10T07:55:31.329151367Z","tags":null},"/Deep_Learning_And_Machine_Learning/Deep_Learning_Block_and_Machine_Learning_Block/GRU":{"title":"Gated Recurrent Unit","content":"\n","lastmodified":"2023-06-10T07:55:31.329151367Z","tags":null},"/Deep_Learning_And_Machine_Learning/Deep_Learning_Block_and_Machine_Learning_Block/LSTM":{"title":"Long Short-Term Memory Networks","content":"\n\u003e [!quote] \n\u003e When I was learning LSTM, the new deep learning block *Transformers* dominate the NLP field. However, *Transformers* don't decisively outperform LSTMS in time-series-related tasks. The main reason is that LSTMs are more adept at handling **local temporal data**. \n\n\nLSTM的设计目标是解决传统RNN面临的长期依赖问题。传统RNN在处理长序列时，难以记住远距离的信息，因为随着时间的推移，梯度在传播过程中逐渐消失或爆炸。这使得传统RNN难以捕捉长期依赖关系，例如在自然语言处理中理解长句子的语义。\n\nLSTM通过使用一种称为门控机制的技术，有效地解决了这个问题。它包含一个称为记忆单元的重要组件，这个单元可以选择性地存储、读取和删除信息。LSTM的关键在于其三个门控单元：输入门、遗忘门和输出门。\n\n1.  输入门（Input Gate）：决定哪些信息将被更新到记忆单元中。它使用一个Sigmoid激活函数来控制输入的重要性。\n    \n2.  遗忘门（Forget Gate）：决定哪些信息将被从记忆单元中删除。通过使用另一个Sigmoid激活函数和一个逐元素的乘法操作，它决定了上一个记忆状态中的哪些信息保留下来。\n    \n3.  输出门（Output Gate）：决定将哪些信息从记忆单元输出到下一个时间步。这个输出经过一个Sigmoid激活函数和一个Tanh激活函数来进行处理。\n    \n\n这些门控单元允许LSTM选择性地记住或忘记特定的信息，从而使其能够有效地处理长序列。LSTM的网络结构使得信息可以在时间上流动，同时保留对过去信息的长期记忆。\n\n# Arch\n\n可以通过比较传统RNN模块和LSTM模块来加深记忆\n\n传统RNN网络：\n\n![](Deep_Learning_And_Machine_Learning/Deep_Learning_Block_and_Machine_Learning_Block/attachments/Pasted%20image%2020230522161052.png)\n\n\nLSTM模块：\n![](Deep_Learning_And_Machine_Learning/Deep_Learning_Block_and_Machine_Learning_Block/attachments/Pasted%20image%2020230522161520.png)\n\n![](Deep_Learning_And_Machine_Learning/Deep_Learning_Block_and_Machine_Learning_Block/attachments/Pasted%20image%2020230522161546.png)\n\n## Core idea\n\nLSTM的core idea是cell state, cell state可以被视为一个横贯整个LSTM网络的内部记忆。它类似于传统RNN中的隐藏状态，但相比之下，cell state的设计更加精细，使得LSTM能够更好地捕捉长期依赖关系。\n\n![](Deep_Learning_And_Machine_Learning/Deep_Learning_Block_and_Machine_Learning_Block/attachments/Pasted%20image%2020230522162225.png)\n\ncell state的更新是通过门控单元来控制的。在LSTM中，输入门、遗忘门和输出门共同决定了如何更新细胞状态。\n\n\n## Step-by-Step LSTM Walk Through\n\n### Step 1 - Throw away information\n\nLSTM第一步是throw away information，通过遗忘门(forget gate layer)。\n\n![](Deep_Learning_And_Machine_Learning/Deep_Learning_Block_and_Machine_Learning_Block/attachments/Pasted%20image%2020230522162536.png)\n\nforget gate layer 通过输入$x_t$和$h_{t-1}$，计算出$f_t$，$f_t$范围在（0，1），这个$f_t$会去乘以cell state $C_{t-1}$。1代表着“completely keep”，0代表着“completely get rid of this”\n\n一个好的例子，在nlp中，cell state可能包括当前主体的性别，以便可以使用正确的代词。 当我们看到一个新主题时，我们想忘记旧主题的性别。\n\n### Step 2  - Decide What information we're going to store\n\nLSTM第二步在于决定哪些信息要被store在cell state里，这里有两个部分，第一个部分是通过\"input gate layer\"（输入门），计算$i_t$。第二个部分通过一个tanh layer来计算新候选值的向量 $\\tilde{C}_t$。这两个部分将会用来update information in cell state\n\n![](Deep_Learning_And_Machine_Learning/Deep_Learning_Block_and_Machine_Learning_Block/attachments/Pasted%20image%2020230522163353.png)\n\n![](Deep_Learning_And_Machine_Learning/Deep_Learning_Block_and_Machine_Learning_Block/attachments/Pasted%20image%2020230522164237.png)\n\n### Step 3 - Decide output\n\n![](Deep_Learning_And_Machine_Learning/Deep_Learning_Block_and_Machine_Learning_Block/attachments/Pasted%20image%2020230522164609.png)\n\n最终的输出回事一个filtered version of cell state，计算如上图。\n\n# Variants on LSTM\n\nLSTM有很多变种，这里有列出来一些\n\n## Adding \"peephole connections\"  \n\n\n![](Deep_Learning_And_Machine_Learning/Deep_Learning_Block_and_Machine_Learning_Block/attachments/Pasted%20image%2020230522165117.png)\n\n在gate layer的输入中加入cell state，你可以选择在这三个门里的某些加入“peephole connection”（窥视孔连接），某些不加入。\n\n加入窥视孔连接的目的是增强LSTM对细胞状态的建模能力，并更好地捕捉序列中的长期依赖关系。\n\n## Use coupled forget and input gates\n\n![](Deep_Learning_And_Machine_Learning/Deep_Learning_Block_and_Machine_Learning_Block/attachments/Pasted%20image%2020230522170059.png)\n\n\n## GRU (Gated Recurrent Unit) ⭐⭐⭐\n\n* [GRU](Deep_Learning_And_Machine_Learning/Deep_Learning_Block_and_Machine_Learning_Block/GRU.md)\n\n![](Deep_Learning_And_Machine_Learning/Deep_Learning_Block_and_Machine_Learning_Block/attachments/Pasted%20image%2020230522170214.png)\n\nGRU是著名的LSTM变种，值得另起炉灶介绍\n\n\n# Demo code \u0026 Pytorch version LSTM graph explain\n\n![](Deep_Learning_And_Machine_Learning/Deep_Learning_Block_and_Machine_Learning_Block/attachments/Pasted%20image%2020230523164806.png)\n\n```python\nimport torch\nimport torch.nn as nn\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nclass LSTM(nn.Module):\n    def __init__(self, input_size, output_size, hidden_size, num_layers):\n        super(LSTM, self).__init__()\n        self.input_size = input_size\n        self.output_size = output_size\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        \n        self.lstm = nn.LSTM(input_size, hidden_size, num_layers)\n        \n        self.fc = nn.Linear(hidden_size, output_size)\n\n    def forward(self, input_seq):\n        # input_seq: (seq_len, batch, input_size)\n        # lstm_out: (seq_len, batch, hidden_size)\n\n        lstm_out, (hidden_state, cell_state) = self.lstm(input_seq)\n\n        lstm_out = self.fc(lstm_out)\n\n        return lstm_out, hidden_state, cell_state\n    \n\nif __name__ == '__main__':\n    seq = np.linspace(0, 3801, 3801)\n    h = torch.randn(1, 1, 64)\n    c = torch.randn(1, 1, 64)\n\n    lstm = LSTM(1, 1, 64, 1)\n\n    input = torch.Tensor(seq).view(len(seq), 1, -1)\n\n    lstm_out, hidden_state, cell_state = lstm(input)\n    lstm_out = torch.squeeze(lstm_out)\n\n    print(lstm_out.shape)\n    print(hidden_state.shape)\n    print(cell_state.shape)\n```\n\n# Reference\n\n* _Understanding LSTM Networks -- Colah’s Blog_. https://colah.github.io/posts/2015-08-Understanding-LSTMs/. Accessed 22 May 2023.\n* Hochreiter, Sepp, and Jürgen Schmidhuber. “Long Short-Term Memory.” _Neural Computation_, vol. 9, no. 8, Nov. 1997, pp. 1735–80. _DOI.org (Crossref)_, https://doi.org/10.1162/neco.1997.9.8.1735.\n* _Recurrent Nets That Time and Count_. https://ieeexplore.ieee.org/document/861302/. Accessed 22 May 2023.\n* ","lastmodified":"2023-06-10T07:55:31.329151367Z","tags":null},"/Deep_Learning_And_Machine_Learning/Deep_Learning_Block_and_Machine_Learning_Block/Random_Forest":{"title":"Random Forest","content":"\n# Background\n\n* [Decision Tree](Deep_Learning_And_Machine_Learning/Deep_Learning_Block_and_Machine_Learning_Block/Decision_Tree.md)\n\n# Detail\n\nonly vedio here:\n\n* [StatQuest: Random Forests Part 1 - Building, Using and Evaluating](https://www.youtube.com/watch?v=J4Wdy0Wc_xQ\u0026t=32s \"StatQuest: Random Forests Part 1 - Building, Using and Evaluating\")\n\n","lastmodified":"2023-06-10T07:55:31.329151367Z","tags":null},"/Deep_Learning_And_Machine_Learning/Deep_Learning_Block_and_Machine_Learning_Block/Transformer":{"title":"Transformer","content":"\n\u003e [!info] \n\u003e 在学习Transformer前，你需要学习 [⭐Attention](Deep_Learning_And_Machine_Learning/Deep_Learning_Block_and_Machine_Learning_Block/⭐Attention.md)\n\n\n\nTransformer 是Seq2Seq model，由Encoder和Decoder组成\n![300](Deep_Learning_And_Machine_Learning/Deep_Learning_Block_and_Machine_Learning_Block/attachments/Pasted%20image%2020230316160103.png)\n\n# Encoder\n这里贴的是原文Encoder的架构\n![Pasted image 20230316162635](Deep_Learning_And_Machine_Learning/Deep_Learning_Block_and_Machine_Learning_Block/attachments/Pasted%20image%2020230316162635.png)\n\n![Pasted image 20230316162642](Deep_Learning_And_Machine_Learning/Deep_Learning_Block_and_Machine_Learning_Block/attachments/Pasted%20image%2020230316162642.png)","lastmodified":"2023-06-10T07:55:31.329151367Z","tags":null},"/Deep_Learning_And_Machine_Learning/Deep_Learning_Block_and_Machine_Learning_Block/XGBoost":{"title":"XGBoost","content":"\n\nXGBoost is an open-source software library that implements optimized distributed gradient boosting machine learning algorithms under the **Gradient Boosting** framework.\n\n# What you need to know first\n\n* [🚧🚧AdaBoost](Deep_Learning_And_Machine_Learning/Deep_Learning_Block_and_Machine_Learning_Block/AdaBoost.md)\n\n# What is XGBoost\n\n**XGBoost**, which stands for Extreme Gradient Boosting, is a scalable, distributed **gradient-boosted** decision tree (GBDT) machine learning library. It provides parallel tree boosting and is the leading machine learning library for regression, classification, and ranking problems.\n\nIt’s vital to an understanding of XGBoost to first grasp the machine learning concepts and algorithms that XGBoost builds upon: **supervised machine learning**, **decision trees**, **ensemble learning**, and **gradient boosting**.\n\nHere, we need to know **ensemble learning** and **gradient boosting,** this two thing I don’t konw before.\n\n## What is Ensemble Learning(集成学习)\n\n**Ensemble learning** is a general meta approach to machine learning that **seeks better predictive performance by combining the predictions from multiple models**.\n\nThe three main classes of ensemble learning methods are **bagging**, **stacking**, and **boosting.**\n\n### Bagging\n\nBagging means **Bootstrap aggregation.** It’s an ****ensemble learning method that seeks a diverse group of ensemble members by **varying the training data**.\n\nThis typically involves using a single machine learning algorithm, almost always an unpruned decision tree, and **training each model on a different sample of the same training dataset.** The predictions made by the ensemble members are then **combined using simple statistics, such as voting or averaging.**\n\nKey to the method is the manner in which each sample of the dataset is prepared to train ensemble members. Each model gets its own unique sample of the dataset.\n\nBagging adopts the **bootstrap distribution** for generating **different base learners**. In other words, it applies **bootstrap sampling** to obtain the data subsets for training the base learners.\n\n![](Deep_Learning_And_Machine_Learning/Deep_Learning_Block_and_Machine_Learning_Block/attachments/Untitled.png)\n\n\u003caside\u003e\n💡 **Bootstrap Sampling\nSelect a sample(a row of data), then reture the sample to dataset and re-select another sample to aggregate a data sample dataset. It means a sample can be selected zero, one, or mulitple times for a given dataset.**\nBootstrap sampling ****is often used in statistics with **small dataset**. geive a better overall estimate of the desired quantity than simply estimating from the whole dataset directly.\n\n\u003c/aside\u003e\n\nKey word of bagging method:\n\n- **Bootstrap Sampling**\n- **Voting or averaging of predictions**\n- **Unpruned decision tree**\n\n\u003e Random forest is the typical example based on the bagging method.\n\u003e \n\n### Stacking\n\nStacking means **Stacked Generalization**. It is an ensemble method that seeks a diverse group of members by **varying the model types** fit on the training data and using a model to combine predictions.\n\n\u003e *Stacking is a general procedure where a learner is trained to combine the individual learners. Here, the individual learners are called the first-level learners, while the combiner is called the second-level learner, or meta-learner.*\n\u003e \n\nStacking has its own nomenclature where ensemble members are referred to as **level-0 models** and the model that is used to combine the predictions is referred to as a **level-1 model**.\n\nThe two-level hierarchy of models is the most common approach, although more layers of models can be used. For example, instead of a single level-1 model, we might have 3 or 5 level-1 models and a single level-2 model that combines the predictions of level-1 models in order to make a prediction.\n\n![](Deep_Learning_And_Machine_Learning/Deep_Learning_Block_and_Machine_Learning_Block/attachments/Untitled%201.png)\n\nKey words of stacknig method:\n\n- **Unchanged training dataset**\n- **Different machine learning algorithms for each ensemble member**\n- **Machine learning model to learn how to best combine predictions**\n\n### Boosting\n\n**Boosting** is an ensemble method that seeks to change the training data to focus attention on examples that previous fit models on the training dataset have gotten wrong.\n\n\u003e *In boosting, […] the training dataset for each subsequent classifier increasingly focuses on instances misclassified by previously generated classifiers.*\n\u003e \n\nThe key property of boosting ensembles is the idea of **correcting prediction errors**. The models are fit and added to the ensemble sequentially such that the second model attempts to correct the predictions of the first model, the third corrects the second model, and so on.\n\nThis typically involves the use of very simple decision trees that only make a single or a few decisions, referred to in boosting as weak learners. The predictions of the weak learners are combined using simple voting or averaging, although **the contributions are weighed proportional to their performance or capability**. The objective is to develop a so-called “***strong-learner***” from many purpose-built “***weak-learners***”.\n\nTypically, the training **dataset is left unchanged** and instead, the learning algorithm is modified to **pay more or less attention to specific samples based on whether they have been predicted correctly or incorrectly** by previously added ensemble members. \n\n![](Deep_Learning_And_Machine_Learning/Deep_Learning_Block_and_Machine_Learning_Block/attachments/Untitled%202.png)\n\nKey words to boosting method:\n\n- **Bias training data** toward those examples that are hard to predict\n- **Iteratively add ensemble members to correct predictions of prior models**\n- Combine predictions **using a weighted average** of models\n\n![](Deep_Learning_And_Machine_Learning/Deep_Learning_Block_and_Machine_Learning_Block/attachments/Untitled%203.png)\n\nType of boosting:\n\n- Adaptive boosting\n- Gradient boosting\n- Extreme gradient boosting\n\n# Introduction to three main type of boosting method\n\n## [Adaptive boosting](https://www.notion.so/AdaBoost-8e7009e35aee4334b31d46bfd7e3dbba)\n\nAdaptive Boosting (AdaBoost) was one of **the earliest boosting models** developed. It adapts and tries to **self-correct** in every iteration of the boosting process.\n\nAdaBoost initially gives the same weight to each dataset. Then, it automatically adjusts the weights of the data points after every decision tree. It **gives more weight to incorrectly classified items** to correct them for the next round. It repeats the process until the residual error, or the difference between actual and predicted values, falls below an acceptable threshold.\n\nYou can use AdaBoost with many predictors, and it is typically not as sensitive as other boosting algorithms. This approach does not work well when there is a correlation among features or high data dimensionality. Overall, **AdaBoost is a suitable type of boosting for classification problems**.\n\n**Must check Learning material below to know more detail of this algorithm. 🚧🚧🚧**\n\n## Gradient boosting\n\nGradient Boosting (GB) is similar to AdaBoost in that it, too, is a **sequential training technique**. The difference between AdaBoost and GB is that GB does not give incorrectly classified items more weight. Instead, GB software **optimizes the loss function by generating base learners sequentially** so that **the present base learner is always more effective than the previous one**. This method **attempts to generate accurate results initially instead of correcting errors throughout the process**, like AdaBoost. For this reason, GB software can lead to more accurate results. Gradient Boosting can help with both classification and regression-based problems.\n\n![](Deep_Learning_And_Machine_Learning/Deep_Learning_Block_and_Machine_Learning_Block/attachments/Untitled%204.png)\n\n## Extreme gradient boosting\n\nExtreme Gradient Boosting (XGBoost) improves gradient boosting for **computational speed and scale** in several ways. XGBoost uses multiple cores on the CPU so that learning can occur in parallel during training. It is a boosting algorithm that can handle extensive datasets, making it attractive for big data applications. The key features of XGBoost are parallelization, distributed computing, cache optimization, and out-of-core processing.\n\n# Reference\n\n## XGBoost\n\n* [What is XGBoost?](https://www.nvidia.com/en-us/glossary/data-science/xgboost/)\n\n* [XGBoost Part 1 (of 4): Regression](https://www.youtube.com/watch?v=OtD8wVaFm6E)\n\n## Ensemble Learning\n\n* [A Gentle Introduction to Ensemble Learning Algorithms - MachineLearningMastery.com](https://machinelearningmastery.com/tour-of-ensemble-learning-algorithms/)\n\n* [集成学习(ensemble learning)原理详解_Soyoger的博客-CSDN博客_ensemble l](https://blog.csdn.net/qq_36330643/article/details/77621232)\n\n* [What is Boosting? Guide to Boosting in Machine Learning - AWS](https://aws.amazon.com/what-is/boosting/)\n\n* [Regression Trees, Clearly Explained!!!](https://www.youtube.com/watch?v=g9c66TUylZ4\u0026list=PLblh5JKOoLUICTaGLRoHQDuF_7q2GfuJF\u0026index=45)\n\n* [AdaBoost, Clearly Explained](https://www.youtube.com/watch?v=LsK-xG1cLYA)\n\n* [Gradient Boost Part 1 (of 4): Regression Main Ideas](https://www.youtube.com/watch?v=3CC4N4z3GJc)\n","lastmodified":"2023-06-10T07:55:31.329151367Z","tags":null},"/Deep_Learning_And_Machine_Learning/Evaluation/model_evaluation_MOC":{"title":"Model Evaluation - MOC","content":"\n* [Model Evaluation in Time Series Forecasting](Deep_Learning_And_Machine_Learning/Evaluation/time_series_forecasting.md)","lastmodified":"2023-06-10T07:55:31.401152442Z","tags":null},"/Deep_Learning_And_Machine_Learning/Evaluation/time_series_forecasting":{"title":"Model Evaluation in Time Series Forecasting","content":"\n![](Deep_Learning_And_Machine_Learning/Evaluation/attachments/Pasted%20image%2020230526162839.png)\n\n# Some famous time series scoring technics\n\n1.  **MAE, RMSE and AIC**\n2.  **Mean Forecast Accuracy**\n3.  **Warning: The time series model EVALUATION TRAP!**\n4.  **RdR Score Benchmark**\n\n## MAE, RMSE, AIC\n\nMAE means **Mean Absolute Error (MAE)** and RMSE means **Root Mean Squared Error (RMSE)**.\n\n这是两个衡量 continuous variables的accuracy的著名指标，MAE在以前的文章中被时常使用，16年的观察已经发现RMSE或者其他version的R-squared逐渐被使用起来\n\n*我们需要了解何时使用哪种指标会更好*\n\n### MAE\n\n$$\n\\text{MAE} = \\frac{1}{n}\\sum_{j=1}^n |y_j - \\hat{y}_j|\n$$\nMAE的特点在于所有individual difference有着equal weight\n\n如果将绝对值去掉，MAE会变成**Mean Bias Error (MBE)**，使用MBE时，要注意正反bias相互抵消\n\n### RMSE\n\n$$\n\\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{j=1}^n (y_j - \\hat{y}_j)^2}\n$$\n\n均方根误差（RMSE）是一种二次评分规则，它还测量误差的平均幅度。它是预测值和实际观测值之间差异的平方的平均值的平方根。\n\n### AIC\n\n$$\n\\text{AIC} = 2k - 2\\ln{(\\hat{L})}\n$$\n$k$是模型参数的估计，$\\hat{L}$是模型似然函数(likelihood function)的最大化值\n\n**Akaike information criterion**，赤池信息准则（AIC）是一个有助于比较模型的指标，因为它同时考虑了模型对数据的拟合程度和模型的复杂性。\n  \nAIC衡量信息的损失并**对模型的复杂性进行惩罚**。它是*参数数量惩罚后的负对数似然函数*。AIC的主要思想是模型参数越少越好。**AIC允许您测试模型在不过拟合数据集的情况下拟合数据的程度**\n\n### Comparison\n\n#### Similarities between MAE and RMSE\n\n均方误差（MAE）和均方根误差（RMSE）都以感兴趣变量的单位来表示平均模型预测误差。这两个指标都可以在0到∞的范围内变化，并且对误差的方向不敏感。它们是负向评分指标，也就是说数值越低越好。\n\n#### Differences between MAE and RMSE\n\n*由于误差在求平均之前被平方，RMSE对大误差给予相对较高的权重*。这意味着在特别不希望出现大误差的情况下，RMSE应该更有用；而在MAE的平均值中，这些大误差将被稀释，\n\n![](Deep_Learning_And_Machine_Learning/Evaluation/attachments/Pasted%20image%2020230526161422.png)\n\nAIC the lower is better，但没有perfect score，只能用来相同dataset下不同model的性能\n\n## Mean Forecast Accuracy\n\n![](Deep_Learning_And_Machine_Learning/Evaluation/attachments/Pasted%20image%2020230526162035.png)\n\n计算每个点的Forecast Accuracy，然后求平均，得到 Mean Forecast Accuracy\n\nMean Forecast Accuracy的重大缺陷在大的偏离值造成巨大的负面影响，比如$1 - \\frac{|\\hat{y}_j - y_j|}{y_j} = 1 - \\frac{250-25}{25} = -800\\%$\n\n解决方案是将Forecast Accuracy的最小值限制为0%，同时可以使用Median代替Mean。\n\n一般来说，**当你的误差分布偏斜时，你应该使用 Median 而不是 Mean**。 在某些情况下，Mean Forecast Accuray也可能毫无意义。 如果你还记得你的统计数据； 变异系数 (**coefficient of variation**, CV) 表示标准偏差与平均值的比率（$\\text{CV} = (\\text{Standard Deviation}/\\text{Mean} * 100)$）。 大 CV 值意味着大变异性，这也意味着围绕均值的离差程度更大。 **例如，我们可以将 CV 高于 0.7 的任何事物视为高度可变且不可真正预测的。 另外，还可以说明你的预测模型预测能力很不稳定！** \n\n## RdR Score Benchmark (这是一个具有实验性的指标，blogger指出这个指标并没有在research paper出现过)\n\nRdR metric stands for:\n* *R*: **Naïve Random Walk**\n* *d*: **Dynamic Time Warping**\n* *R*: **Root Mean Squared Error**\n\n### DTW to deal with shape similarity\n\n![](Deep_Learning_And_Machine_Learning/Evaluation/attachments/Pasted%20image%2020230526163614.png)\n\nRMSE、MAE这些指标都没有考虑到一个重要的标准：**THE SHAPE SIMILARITY**\n\nRdR Score Benchmark使用 [**Dynamic Time Warping(DTW，动态时间调整)** ](Deep_Learning_And_Machine_Learning/Trick/DTW.md)作为shape similarity的指标\n\n![](Deep_Learning_And_Machine_Learning/Evaluation/attachments/Pasted%20image%2020230526164106.png)\n欧氏距离在时间序列之间可能是一个不好的选择，因为时间轴上存在扭曲的情况。\n\n* DTW：通过“同步”/“对齐”时间轴上的不同信号，找到两个时间序列之间的最佳（最小距离）扭曲路径\n\n### RdR score means\n\n![](Deep_Learning_And_Machine_Learning/Evaluation/attachments/Pasted%20image%2020230529130501.png)\n\n![](Deep_Learning_And_Machine_Learning/Evaluation/attachments/Pasted%20image%2020230529130509.png)\n\n*RdR score*通过RMSE和DTW distance来计算，用于比较你的model和Radnom Walk(*Random Walk的RdR score = 0*)相比的优越性\n\n### RdR calculation details\n\n可以通过绘制 RMSE vs. DTW来计算RdR score，绘制的图如下所示：\n\n![](Deep_Learning_And_Machine_Learning/Evaluation/attachments/Pasted%20image%2020230529130856.png)\n\n\n计算矩阵面积来计算RdR score，（文章里并没有完整介绍计算，在[github code](https://github.com/CoteDave/blog/tree/master/RdR%20score)里有，并不确定）\n\n# Reference\n\n* M.Sc, Dave Cote. “RdR Score Metric for Evaluating Time Series Forecasting Models.” _Medium_, 8 Feb. 2022, https://medium.com/@dave.cote.msc/rdr-score-metric-for-evaluating-time-series-forecasting-models-1c23f92f80e7.\n* JJ. “MAE and RMSE — Which Metric Is Better?” _Human in a Machine World_, 23 Mar. 2016, https://medium.com/human-in-a-machine-world/mae-and-rmse-which-metric-is-better-e60ac3bde13d.\n* _Accelerating Dynamic Time Warping Subsequence Search with GPU_. https://www.slideshare.net/DavideNardone/accelerating-dynamic-time-warping-subsequence-search-with-gpu. Accessed 29 May 2023.","lastmodified":"2023-06-10T07:55:31.401152442Z","tags":null},"/Deep_Learning_And_Machine_Learning/Famous_Model/DeepAR":{"title":"DeepAR - Time Series Forcasting","content":"\nDeepAR, an autoregressive recurrent network developed by Amazon, is the first model that could natively work on multiple time-series. It's a milestone in time-series community.\n\n# What is DeepAR\n\n\u003e [!quote] \n\u003e  DeepAR is the first successful model to combine Deep Learning with traditional Probabilistic Forecasting.\n\n* **Multiple time-series support**\n* **Extra covariates**: *DeepAR* allows extra features, covariates. It is very important for me when I learn *DeepAR*, because in my task, I have corresponding feature for each time series.\n* **Probabilistic output**:  Instead of making a single prediction, the model leverages [**quantile loss**](Deep_Learning_And_Machine_Learning/Trick/quantile_loss.md) to output prediction intervals.\n* **“Cold” forecasting:** By learning from thousands of time-series that potentially share a few similarities, _DeepAR_ can provide forecasts for time-series that have little or no history at all.\n\n# Block used in DeepAR\n\n* [LSTM](Deep_Learning_And_Machine_Learning/Deep_Learning_Block_and_Machine_Learning_Block/LSTM.md)\n\n# *DeepAR* Architecture\n\nDeepAR模型并不直接使用LSTMs去计算prediction，而是去估计Gaussian likelihood function的参数，即$\\theta=(\\mu,\\sigma)$，估计Gaussian likelihood function的mean和standard deviation。\n\n## Training Step-by-Step\n\n![](Deep_Learning_And_Machine_Learning/Famous_Model/attachments/Pasted%20image%2020230523134255.png)\n\n假设目前我们在time-series $i$ 的 t 时刻，\n\n1. LSTM cell会输入covariates $x_{i,t}$，即$x_i$在t时刻的值，还有上一时刻的target variable，$z_{i,t-1}$，LSTM还需要输入上一时刻的隐藏状态$h_{i,t-1}$\n2. LSTM紧接着就会输出当前的hidden state $h_{i,t}$，会输入到下一步中\n3. Gaussian likelihood function里的parameter，$\\mu$和$\\sigma$会从$h_{i,t}$中不直接计算出，计算细节在后面\n\n\u003e [!quote] \n\u003e 换言之，这个模型是为了得到最好的$\\mu$和$\\sigma$去构建gaussian distribution，让预测更接近$z_{i,t}$；同时，因为*DeepAR*每次都是train and predicts a single data point，所以这个模型也被称为autoregressive模型\n\n\n## Inference Step-by-Step\n\n\n![](Deep_Learning_And_Machine_Learning/Famous_Model/attachments/Pasted%20image%2020230523141219.png)\n\n\n在使用model进行预测的时候，某一改变的就是使用预测值$\\hat{z}$ 代替真实值$z$，同时$\\hat{z}_{i,t}$是在我们模型学习到的Gaussian distribution里sample得到的，而这个Gaussian distribution里的参数$\\mu$和$\\sigma$并不是model直接学习到的，*DeepAR*如何做到这一点的呢？\n\n# Gaussian Likelihood\n\n$$\n\\ell_G(z|\\mu,\\sigma) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp{(-\\frac{(z-\\mu)^2)}{2\\sigma^2}}\n$$\n\nEstimate gaussian distribution的任务一般会被转化成maximize gaussian log-likelihood function的任务，即**MLEformulas**(maximum log-likelihood estimators)\n**Gaussian log-likelihood function**:\n\n$$\n\\mathcal{L} = \\sum_{i=1}^{N}\\sum_{t=t_o}^{T} \\log{\\ell(z_{i,t}|\\theta(h_{i,t}))}\n$$\n\n\n# Parameter estimation in *DeepAR*\n\n\n在统计学中，预估Gaussian Distribution一般使用MLEformulas，但是在*DeepAR*中，并不这么去做，而是使用两个dense layer去做预估，如下图：\n\n![](Deep_Learning_And_Machine_Learning/Famous_Model/attachments/Pasted%20image%2020230523151201.png)\n\n使用dense layer的方式去预估Gaussian distribution的原因在于，可以使用backpropagation\n\n\n# Reference\n\n* [https://towardsdatascience.com/deepar-mastering-time-series-forecasting-with-deep-learning-bc717771ce85](https://towardsdatascience.com/deepar-mastering-time-series-forecasting-with-deep-learning-bc717771ce85)","lastmodified":"2023-06-10T07:55:31.401152442Z","tags":null},"/Deep_Learning_And_Machine_Learning/Famous_Model/Famous_Model_MOC":{"title":"Famous Model MOC","content":"\n# Time-series\n\n* [DeepAR](Deep_Learning_And_Machine_Learning/Famous_Model/DeepAR.md)\n\n","lastmodified":"2023-06-10T07:55:31.401152442Z","tags":null},"/Deep_Learning_And_Machine_Learning/Famous_Model/Temporal_Fusion_Transformer":{"title":"Temporal Fusion Transformer","content":"\n","lastmodified":"2023-06-10T07:55:31.401152442Z","tags":null},"/Deep_Learning_And_Machine_Learning/LLM/LLM_MOC":{"title":"Large Language Model(LLM) - MOC","content":"\n# Metrics\n\nHow to evaluate a LLM performance?\n\n","lastmodified":"2023-06-10T07:55:31.401152442Z","tags":null},"/Deep_Learning_And_Machine_Learning/Model_interpretability/Model_Interpretability_MOC":{"title":"Model Interpretability - MOC","content":"\n* [SHAP](Deep_Learning_And_Machine_Learning/Model_interpretability/SHAP.md)\n","lastmodified":"2023-06-10T07:55:31.401152442Z","tags":null},"/Deep_Learning_And_Machine_Learning/Model_interpretability/SHAP":{"title":"SHAP - a reliable way to analyze model interpretability","content":"\nSHAP is the most popular model-agnostic technique that is used to explain predictions. SHAP stands for **SH**apley **A**dditive ex**P**lanations\n\nShapely values are obtained by incorporating concepts from *Cooperative Game Theory*  and *local explanations*\n\n# Mathematical and Algorithm Foundation\n\n## Shapely Values\n\nShapely values were from game theory and invented by Lloyd Shapley. Shapely values were invented to be a way of providing a fair solution to the following question:\n\n\u003e [!question] \n\u003e  If we have a coalition **C** that collaborates to produce a value **V**: How much did each individual member contribute to the final value\n\nThe method here we assess each individual member’s contribution is to removing each member to get a new coalition and then compare their production, like this graphs:\n\n![](Deep_Learning_And_Machine_Learning/Model_interpretability/attachments/Pasted%20image%2020230329165429.png)\n\nAnd then, we get every member 1 included or not included coalitions like this:\n\n![](Deep_Learning_And_Machine_Learning/Model_interpretability/attachments/Pasted%20image%2020230329165523.png)\n\nUsing left value - right value, we can get difference like image left above; And then we calculate the mean of them:\n\n$$\n\\varphi_i=\\frac{1}{\\text{Members}}\\sum_{\\forall \\text{C s.t. i}\\notin \\text{C}} \\frac{\\text{Marginal Contribution of i to C}}{\\text{Coalitions of size |C|}}\n$$\n\n## Shapely Additive Explanations\n\nWe need to know what’s **additive** mean here. Lundberg and Lee define an additive feature attribution as follows:\n\n![](Deep_Learning_And_Machine_Learning/Model_interpretability/attachments/Pasted%20image%2020230329165623.png)\n\n![](Deep_Learning_And_Machine_Learning/Model_interpretability/attachments/Pasted%20image%2020230329165818.png)\n\n$x'$, the simplified local inputs usually means that we turn a feature vector into a discrete binary vector, where features are either included or excluded. Also, the $g(x')$ should take this form:\n\n$$\ng(x')=\\varphi_0+\\sum_{i=1}^N \\varphi_i {x'}_i\n$$\n\n* $\\varphi_0$ is the **null output** of this model, that is, the **average output** of this model\n-  $\\varphi_i$ is **feature affect**, is how much that feature changes the output of the model, introduced above. It’s called **attribution**\n\n![](Deep_Learning_And_Machine_Learning/Model_interpretability/attachments/Pasted%20image%2020230329165840.png)\n\nNow Lundberg and Lee go on to describe a set of three desirable properties of such an additive feature method, **local accuracy**, **missingness**, and **consistency**.\n\n### Local accuracy\n\n$$\ng(x')\\approx f(x) \\quad \\text{if} \\quad x'\\approx x\n$$\n\n### Missingness\n\n$$\n{x_i}' = 0 \\rightarrow \\varphi_i = 0\n$$\n\nif a feature excluded from the model. it’s attribution must be zero; that is, the only thing that can affect the output of the explanation model is the inclusion of features, not the exclusion.\n\n### Consistency\n\nIf feature contribution changes, the feature effect cannot change in the opposite direction\n\n# Why SHAP\n\nLee and Lundberg in their paper argue that only SHAP satisfies all three properties if **the feature attributions in only additive explanatory model are specifically chosen to be the shapley values of those features**\n\n# SHAP, step-by-step Process, same as shap.explainer\n\nFor example, we consider a ice cream shop in the airport, it has four features we can know to predict his business.\n\n$$\n\\begin{bmatrix}\n\\text{temperature} \u0026 \\text{day of weeks} \u0026 \\text{num of flights} \u0026 \\text{num of hours}\n\\end{bmatrix}\n\\\\\n\\rightarrow \\\\\n\\begin{bmatrix}\nT \u0026 D \u0026 F \u0026 H\n\\end{bmatrix}\n$$\n\nFor, example, we want to know the temperature 80 in sample [80 1 100 4] shapley value, here’s the step\n\n- Step 1. Get random permutation of features, and give a bracket to the feature we care and everything in its right. (manually)\n\n$$\n\\begin{bmatrix}\nF \u0026 D \u0026 \\underbrace{T \\quad H}\n\\end{bmatrix}\n$$\n\n- Step 2. Pick random sample from dataset\n \nFor example, [200 5 70 8], form: [F D T H]\n\n- Step 3. Form vectors $x_1 \\quad x_2$\n\n$$\nx_1=[100 \\quad 1 \\quad 80 \\quad \\color{#BF40BF} 8 \\color{#FFFFFF}] \n$$\n\n$x_1$ is partially from original sample and partially from the random chosen one, the feature in bracket will from random chosen one, exclude what we care\n\n$$\nx_2 = [100 \\quad 1 \\quad \\color{#BF40BF} 70 \\quad  8 \\color{#FFFFFF}]\n$$\n\n$x_2$  just change the feature we care into the same as random chosen one’s feature value\n\nThen, calculate the diff and record\n\n$$\nDIFF = c_1 - c_2\n$$\n\n- Step 4. Record the diff \u0026 return to step 1. and repeat many times\n\n$$\n\\text{SHAP}(T=80 | [80 \\quad 1 \\quad 100 \\quad 4]) = \\text{average(DIFF)}\n$$\n\n# Shapley kernel\n\n## Too many coalitions need to be sampled\n\nLike we introduce shapley values above, for each $\\varphi_i$ we need to sample a lot of coalitions to compute the difference. \n\nFor 4 features, we need 64 total coalitions to sample; For 32 features, we need 17.1 billion coalitions to sample.\n\nIt’s entirely untenable.\n\nSo, to get over this difficulty, we need devise a **shapley kernel**, and that’s how the Lee and Lundberg do\n\n![](Deep_Learning_And_Machine_Learning/Model_interpretability/attachments/Pasted%20image%2020230329181956.png)\n\n## Detail\n![](Deep_Learning_And_Machine_Learning/Model_interpretability/attachments/Pasted%20image%2020230329182011.png)\n\nThough most of ML models won’t just let you omit a feature, what we do is define a **background dataset** B, one that contains a set of representative data points that model was trained over. We then filled in out omitted feature of features with values from background dataset, while holding the features are included in the permutation fixed to their original values. We then take the average of the model output over all of these new synthetic data point as our model output for that feature permutation which we call $\\bar{y}$.\n\n$$\nE[y_{\\text{12i4}}\\ \\  \\forall \\ \\text{i}\\in B] = \\bar{y}_{\\text{124}}\n$$ \n![](Deep_Learning_And_Machine_Learning/Model_interpretability/attachments/Pasted%20image%2020230329205039.png)\n\nThem we have a number of samples computed in this way,like image in left.\n\nWe can formulate this as a weighted linear regression, with each feature assigned a coefficient.\n\nAnd we can prove that, in the special choice, the coefficient can be the shaplely values. **This weighting scheme is the basis of the Shapley Kernal.** In this situation, the weighted linear regression process as a whole is Kernal SHAP.\n\n### Different types of SHAP\n\n- **Kernal SHAP**\n- Low-order SHAP\n- Linear SHAP\n- Max SHAP\n- Deep SHAP\n- Tree SHAP\n\n![](Deep_Learning_And_Machine_Learning/Model_interpretability/attachments/Pasted%20image%2020230329205130.png)\n\n### You need to notice\nWe can see that, we calculate shapley values using linear regression lastly. So there must be the error here, but some python packages can not give us the error bound, so it’s confusion to konw if this error come from linear regression or the data, or the model.\n\n\n# Reference\n\n[Shapley Additive Explanations (SHAP)](https://www.youtube.com/watch?v=VB9uV-x0gtg)\n\n[SHAP: A reliable way to analyze your model interpretability](https://towardsdatascience.com/shap-a-reliable-way-to-analyze-your-model-interpretability-874294d30af6)\n\n[【Python可解释机器学习库SHAP】：Python的可解释机器学习库SHAP](https://zhuanlan.zhihu.com/p/483622352)\n\n[Shapley Values : Data Science Concepts](https://www.youtube.com/watch?v=NBg7YirBTN8)\n\n# Appendix\n\nOther methods to interprete model:\n\n[Papers with Code - SHAP Explained](https://paperswithcode.com/method/shap)","lastmodified":"2023-06-10T07:55:31.401152442Z","tags":null},"/Deep_Learning_And_Machine_Learning/Trick/DTW":{"title":"Dynamic Time Warping (DTW)","content":"\n![](Deep_Learning_And_Machine_Learning/Trick/attachments/Pasted%20image%2020230526164724.png)\n\n欧氏距离在时间序列之间可能是一个不好的选择，因为时间轴上存在扭曲的情况。DTW 是一个考虑到这种扭曲的，测量距离来比较两个时间序列的一个指标，本section讲解如何计算 DTW distance\n\n# Detail\n\n\n## Step 1.  准备输入序列\n\n假设两个time series, A \u0026 B\n\n## Step 2. 计算距离矩阵\n\n创建一个距离矩阵，其中的元素表示序列 A 和序列 B 中每个时间点之间的距离。常见的距离度量方法包括欧氏距离、曼哈顿距离、余弦相似度等。根据你的数据类型和需求选择适当的距离度量方法。\n\n## Step 3. 初始化累积距离矩阵\n\n创建一个与距离矩阵大小相同的累积距离矩阵，用于存储从起点到每个位置的累积距离。将起点 (0, 0) 的累积距离设为距离矩阵的起始点距离。\n\n## Step 4. 计算累积距离\n\n从起点开始，按照动态规划的方式计算累积距离矩阵中每个位置的累积距离。对于每个位置 (i, j)，**累积距离等于该位置的距离加上三个相邻位置中选择最小累积距离的值。**\n\n$$\nDTW(i, j) = d_{i,j} + \\min{\\{DTW(i-1,j), DTW(i, j-1), DTW(i-1, j-1)\\}}\n$$\n\n\n## Step 5. 回溯最优路径\n\n从累积距离矩阵的最右下角开始，根据最小累积距离的路径回溯到起点 (0, 0)。记录下经过的路径，即为最优路径。\n\n## Step 6. 计算最终距离\n\n根据最优路径上的累积距离，计算出最终的 DTW 距离。\n\n# Example\n\n![](Deep_Learning_And_Machine_Learning/Trick/attachments/Pasted%20image%2020230526170120.png)\n\n左边是距离矩阵，右边是DTW矩阵，也就是累积距离矩阵\n\n![](Deep_Learning_And_Machine_Learning/Trick/attachments/Pasted%20image%2020230526170921.png)\n\n![](Deep_Learning_And_Machine_Learning/Trick/attachments/Pasted%20image%2020230526171119.png)\n\n通过回溯，找到optimal warping path，DTW distance就是 the optimal warping path的square root，本例中就是$\\sqrt{15}$\n\n\n\n","lastmodified":"2023-06-10T07:55:31.413152621Z","tags":null},"/Deep_Learning_And_Machine_Learning/Trick/quantile_loss":{"title":"Quantile loss","content":"\n在大多数现实世界的预测问题中，我们的预测所带来的不确定性具有重要价值。相较于仅仅提供点估计，了解预测范围能够显著改善许多商业应用的决策过程。**Quantile loss**就是为例帮助我们了解预测范围的loss function。\n\nQuantile loss用于衡量预测分布和目标分布之间的差异，特别适用于处理不确定性较高的预测问题。\n\n# What is quantile\n\n[Quantile](Math/Statistics/Basic/Quantile.md)\n\n# What is a prediction interval\n\n  \n预测区间是对预测的不确定性进行量化的一种方法。它为结果变量的估计提供了**概率上限和下限的范围**。\n\n![](Deep_Learning_And_Machine_Learning/Trick/attachments/Pasted%20image%2020230522151015.png)\n\n输出本身是随机变量，因此具有分布特性。预测区间的目的在于了解结果的正确性可能性。\n\n# What is Quantile Loss\n\n在Quantile loss中，我们将预测结果和目标值都表示为分位数形式，例如，我们可以用预测的α分位数来表示预测结果，用真实值的α分位数来表示目标值。然后，Quantile loss衡量了这两个分布之间的差异，通常使用分位数损失函数来计算。\n\n分位数回归损失函数(Quantile Regression Loss)用于预测分位数(Quantile)。例如，对于分位数为0.9的预测，应该在90%的情况下做出过高的预测。\n\n对于一条数据，prediction是$y_i^p$，真实值是$y_i$，mean regression loss for a quantile q:\n\n$$\nL(y_i^p, y_i) = \\max[q(y_i^p - y_i), (q-1)(y_i^p - y_i)]\n$$\n\n一系列prediction数据来通过minimize这个loss function后，得到quantile - $q$\n\n\n## Intuitive Understanding\n\n在上述的回归损失方程中，由于 q 的取值范围在 0 到 1 之间，当进行过高预测（$y_i^p$ \u003e $y_i$）时，第一项将为正并占主导地位；而当进行过低预测（$y_i^p$ \u003c $y_i$）时，第二项将占主导地位。当 q 等于 0.5 时，过低预测和过高预测将受到相同的惩罚因子，从而得到中位数。q 的值越大，相比于过低预测，过高预测将受到更严厉的惩罚。例如，当 q 等于 0.75 时，过高预测将受到 0.75 的惩罚因子，而过低预测将受到 0.25 的惩罚因子。模型做出过高预测的可能性的*难度*将会是过低预测可能性的3倍，从而得到 0.75 分位数。\n\n## Why Quantile loss\n\n\u003e [!quote] \n\u003e **“同方差性”，“恒定方差假设”**\n\u003e \n\u003e 在最小二乘回归中，预测区间基于一个假设，即残差在自变量的各个取值上具有恒定的方差。这假设被称为“同方差性”或“恒定方差假设”。\n\u003e \n\u003e 这个假设是基于对回归模型中误差项的性质的一种合理假设。在最小二乘回归中，我们假设因变量的观测值是由真实值和一个误差项组成的，而这个误差项是独立同分布的，即在每个自变量取值上都具有相同的分布。\n\u003e \n\u003e 如果残差在自变量的各个取值上具有恒定的方差，意味着误差的大小不会随着自变量的变化而发生显著的变化。这样的话，我们可以使用统计方法来计算出预测区间，这个区间能够给出对未来观测值的置信度。\n\u003e \n\u003e 然而，如果恒定方差假设不成立，也就是残差在自变量的取值上具有不同的方差，那么最小二乘回归的结果可能会出现问题。在这种情况下，预测区间可能会低估或高估预测的不确定性，导致对未来观测值的置信度估计不准确。\n\nQuantile Loss Regression可以提供合理的预测区间，即使对于具有非恒定方差或非正态分布的残差也是如此\n\n\n# Reference\n\n* [Kandi, Shabeel. “Prediction Intervals in Forecasting: Quantile Loss Function.” _Analytics Vidhya_, 24 Apr. 2023, https://medium.com/analytics-vidhya/prediction-intervals-in-forecasting-quantile-loss-function-18f72501586f.](https://medium.com/analytics-vidhya/prediction-intervals-in-forecasting-quantile-loss-function-18f72501586f)","lastmodified":"2023-06-10T07:55:31.421152741Z","tags":null},"/Hardware/Hardware_MOC":{"title":"Hardware - MOC","content":"\n# Microcontroller unit (MCU)\n\n## Basic concepts\n\n* [Different programming interfaces](Hardware/MCU/Different%20programming%20interfaces.md)\n","lastmodified":"2023-06-10T07:55:31.421152741Z","tags":null},"/Hardware/MCU/Different-programming-interfaces":{"title":"Different programming interfaces","content":"# What is programming interfaces in MCU\n\nA **programming interface** is a device that allows a programmer to connect to a microcontroller (MCU) and program it. The programming interface is used to load the program into the MCU’s memory and debug it.\n\n# Different types of programming interfaces in MCU\nChipmakers have different names for programming interfaces that all basically do the same thing:\n-   ISP - programming interface for Atmel (now Microchip) AVRs. SPI-like (MISO, MOSI, SCK, reset). It can be used for flash programming and debugging.\n-   PDI - newer programming interface for Atmel AVRs (eg. Xmega). Uses two wires (data and clock). Can do the same as ISP.\n-   DebugWire - yet another interface from Atmel (this one uses only a single wire)\n-   ICSP - programming interface for Microchip PIC line of MCUs\n-   SWD - Serial Wire Debug - programming interface for MCUs with ARM Cortex-M cores (uses two wires - data and clock)\n-   JTAG - very generic term, SPI-like interface used for [boundary scan](https://en.wikipedia.org/wiki/Boundary_scan), can also be used for programming/debugging MCUs (almost every vendor has its own protocol, so Cortex-M JTAG is not the same as AVR JTAG or Blackfin JTAG)\n-   Spy-Bi-Wire - yet another two wire programming interface, this one is for TI's MSP430 MCUs\n\n## SWD 和 JTAG的区别\n\n目前在使用的st link可以使用SWD和JTAG这两种debugger去调试stm32，所以这两种方式的区别令人比较在意；\n* JTAG（Joint Test Action Group，联合测试行动小组）是一种国际标准测试协议，主要用于芯片内部测试。现在多数的高级器件都支持JTAG协议，如ARM、DSP、FPGA器件等。JTAG调试接口必须使用VCC、GND电源信号，以及TMS、TCK、TDI、TDO四根调试信号，可选TRST、RESET复位信号和RTCK（同步时钟）信号。\n\t* TMS(Test Mode Select)：模式选择，TMS用来设置JTAG接口处于某种特定的测试模式；\n\t* TCK(Test Clock)：时钟输入；\n\t* TDI(Test Data Input)：数据输入，数据通过TDI引脚输入JTAG接口；\n\t* TDO(Test Data Output)：数据输出，数据通过TDO引脚从JTAG接口输出；\n* 串行调试（Serial Wire Debug），是一种和JTAG不同的调试模式，使用的调试协议也不一样，所以最直接的体现在调试接口上，与JTAG的20个引脚相比，SWD只需要4个（或者5个）引脚，结构简单，但是使用范围没有JTAG广泛，主流调试器上也是后来才加的SWD调试模式。\n\t* SWDIO：串行数据输入输出，作为仿真信号的双向数据信号线，建议上拉；\n\t* SWCLK：串行时钟输入，作为仿真信号的时钟信号线，建议下拉；\n\t* SWO：串行数据输出引脚，CPU调试接口可通过SWO引脚输出一些调试信息。该引脚是可选的；\n\t* RESET：仿真器输出至目标CPU的系统复位信号，该引脚也为可选\n\n* SWD模式比JTAG在高速模式下面更加可靠。在大数据量的情况下面JTAG下载程序会失败，但是SWD发生的几率会小很多。*基本使用JTAG仿真模式的情况下是可以直接使用SWD模式的，只要你的仿真器支持。*\n* 在GPIO刚好缺一个的时候，可以使用SWD仿真，这种模式支持更少的引脚。\n\n\n* 同时JTAG调试版本不同的情况下：\n\t* JTAGV6 需要的硬件接口为: GND, RST, SWDIO, SWDCLK；\n\t* JTAGV7 需要的硬件接口为: GND, RST, SWDIO, SWDCLK，相对V6， 其速度有了明显的提高，速度是 JTAGV6 的 6 倍。 \n\t* JTAGV8 需要的硬件接口为: VCC, GND, RST, SWDIO, SWDCLK，速度可以到 10M。\n\n\n\n# Reference\n\n[JTAG, SWD, EDBG, ICSP, ISP terms - Electrical Engineering Stack Exchange](https://electronics.stackexchange.com/questions/412029/jtag-swd-edbg-icsp-isp-terms)\n\n[jtag和swd的区别_jtag和swd区别_耶稣赞我萌的博客-CSDN博客](https://blog.csdn.net/yym6789/article/details/88721409)\n\n[STM32的JTAG和SWD模式_学术马的博客-CSDN博客](https://blog.csdn.net/w1050321758/article/details/108663603)\n","lastmodified":"2023-06-10T07:55:31.421152741Z","tags":null},"/Math/Statistics/Basic/Quantile":{"title":"Quantile","content":"\n**分位数**（英语：Quantile），亦称**分位点**，是指用分割点（cut point）将一个随机变量的概率分布范围分为几个具有相同概率的连续区间。分割点的数量比划分出的区间少1，例如3个分割点能分出4个区间。\n\n常见的分位数包括中位数（二分位数）、四分位数（四分位数）和百分位数。\n\n1.  中位数：中位数是将一组数据按照大小排序后，处于中间位置的值。将数据分成两部分，有一半的观察值小于中位数，另一半的观察值大于中位数。\n    \n2.  四分位数：四分位数将数据分成四个等分，分别是下四分位数（25%分位数）、中位数（50%分位数）和上四分位数（75%分位数）。下四分位数是将数据排序后，处于25%位置的值；中位数是处于50%位置的值；上四分位数是处于75%位置的值。\n    \n3.  百分位数：百分位数将数据分成100个等分，可以表示某个特定百分比处的数据值。例如，75%的百分位数表示将数据排序后，处于75%位置的值","lastmodified":"2023-06-10T07:55:31.421152741Z","tags":null},"/Photography/Aesthetic/Landscape/Landscape_MOC":{"title":"Landscape Photography MOC","content":"\n* [🌊Sea MOC](Photography/Aesthetic/Landscape/Sea/Sea_MOC.md)","lastmodified":"2023-06-10T07:55:31.425152801Z","tags":null},"/Photography/Aesthetic/Landscape/Sea/%E8%B1%8A%E5%B3%B6_Instagram_shiifoncake":{"title":"豊島🏝","content":"![](Photography/Aesthetic/Landscape/Sea/attachments/shiifoncake_338949220_771246770941652_287141902256013940_n.jpg)\n\n![](Photography/Aesthetic/Landscape/Sea/attachments/shiifoncake_339164445_155642070453847_6842139942547564019_n%20(1).jpg)\n\n![](Photography/Aesthetic/Landscape/Sea/attachments/shiifoncake_339164445_155642070453847_6842139942547564019_n.jpg)\n\n![](Photography/Aesthetic/Landscape/Sea/attachments/shiifoncake_338803198_1141886276488589_5464974698780309052_n%20(1).jpg)\n\n![](Photography/Aesthetic/Landscape/Sea/attachments/shiifoncake_338803198_1141886276488589_5464974698780309052_n.jpg)\n\n![](Photography/Aesthetic/Landscape/Sea/attachments/shiifoncake_338758486_601356648715316_3737336679741136784_n.jpg)\n\n\n# Reference\n\n* (https://www.instagram.com/p/Cqh4Ci8vV5u/)[https://www.instagram.com/p/Cqh4Ci8vV5u/]","lastmodified":"2023-06-10T07:55:31.597155369Z","tags":null},"/Photography/Aesthetic/Landscape/Sea/Fujifilm_Blue_by_%E5%B0%8F%E7%BA%A2%E4%B9%A6_Philips%E8%B0%A2%E9%AA%8F":{"title":"Sea in Fujiflm Blue","content":"\n![](Photography/Aesthetic/Landscape/Sea/attachments/Pasted%20image%2020230420014349.png)\n\n\n![](Photography/Aesthetic/Landscape/Sea/attachments/Pasted%20image%2020230420014354.png)\n\n\n![](Photography/Aesthetic/Landscape/Sea/attachments/Pasted%20image%2020230420014401.png)\n\n\n![](Photography/Aesthetic/Landscape/Sea/attachments/Pasted%20image%2020230420014613.png)\n\n\n![](Photography/Aesthetic/Landscape/Sea/attachments/Pasted%20image%2020230420014622.png)\n\n\n![](Photography/Aesthetic/Landscape/Sea/attachments/Pasted%20image%2020230420014634.png)\n\n# Reference\n\n* [太绝了！我拍出了富士蓝！- 小红书，Philips谢骏](https://www.xiaohongshu.com/user/profile/6272c025000000002102353b/641299a200000000130129bb)\n\n","lastmodified":"2023-06-10T07:55:31.425152801Z","tags":null},"/Photography/Aesthetic/Landscape/Sea/Sea_MOC":{"title":"🌊Sea MOC","content":"\n* [Fujifilm Blue🌊, 小红书-Philips谢骏](Photography/Aesthetic/Landscape/Sea/Fujifilm_Blue_by_小红书_Philips谢骏.md)\n* [豊島🏝, Instagram-shiifoncake](Photography/Aesthetic/Landscape/Sea/豊島_Instagram_shiifoncake.md)","lastmodified":"2023-06-10T07:55:31.425152801Z","tags":null},"/Photography/Aesthetic/Polaroid/Polaroid_aesthetic_MOC":{"title":"Polaroid Aestheic MOC","content":"\n* [🖼How to show Polaroid photo in a great way](Photography/Aesthetic/Polaroid/Polaroid_showcase.md)","lastmodified":"2023-06-10T07:55:31.597155369Z","tags":null},"/Photography/Aesthetic/Polaroid/Polaroid_showcase":{"title":"How to show Polaroid photo in a great way","content":"\n\n\n![](Photography/Aesthetic/Polaroid/attachments/IMG_5330.jpg)\n\n\n\n![](Photography/Aesthetic/Polaroid/attachments/IMG_5329.jpg)\n\n\n\n![](Photography/Aesthetic/Polaroid/attachments/IMG_5327.jpg)\n\n\n\n![](Photography/Aesthetic/Polaroid/attachments/IMG_5334.jpg)\n\nCredits to  [比扫描仪更easy的宝丽来翻拍解决方案 -BonBon的Pan](https://www.xiaohongshu.com/user/profile/6272c025000000002102353b/6331af53000000001701acfd)","lastmodified":"2023-06-10T07:55:31.597155369Z","tags":null},"/Photography/Aesthetic/Portrait/Flower_and_Girl":{"title":"🌸Flower \u0026 Girl","content":"\nCredits to [Marta Bevacqua](https://www.martabevacquaphotography.com/), \nThanks🌸\n\n![](Photography/Aesthetic/Portrait/attachments/14.jpg)\n\n![](Photography/Aesthetic/Portrait/attachments/15.jpg)\n\n![](Photography/Aesthetic/Portrait/attachments/16.jpg)\n\n![](Photography/Aesthetic/Portrait/attachments/17.jpg)\n\n![](Photography/Aesthetic/Portrait/attachments/18.jpg)\n\n![](Photography/Aesthetic/Portrait/attachments/19.jpg)\n\n![](Photography/Aesthetic/Portrait/attachments/20.jpg)\n\n![](Photography/Aesthetic/Portrait/attachments/21.jpg)\n\n![](Photography/Aesthetic/Portrait/attachments/22.jpg)\n\n![](Photography/Aesthetic/Portrait/attachments/content%20(1).jpg)\n\n![](Photography/Aesthetic/Portrait/attachments/content%20(2).jpg)\n\n![](Photography/Aesthetic/Portrait/attachments/content%20(3).jpg)\n\n![](Photography/Aesthetic/Portrait/attachments/content%20(4).jpg)\n\n![](Photography/Aesthetic/Portrait/attachments/content%20(5).jpg)\n\n![](Photography/Aesthetic/Portrait/attachments/content%20(6).jpg)\n\n![](Photography/Aesthetic/Portrait/attachments/content%20(7).jpg)\n\n![](Photography/Aesthetic/Portrait/attachments/content%20(8).jpg)\n\n![](Photography/Aesthetic/Portrait/attachments/content%20(9).jpg)\n\n![](Photography/Aesthetic/Portrait/attachments/content%20(11).jpg)\n\n![](Photography/Aesthetic/Portrait/attachments/content%20(12).jpg)\n\n![](Photography/Aesthetic/Portrait/attachments/content.jpg)\n\n","lastmodified":"2023-06-10T07:55:31.601155429Z","tags":null},"/Photography/Aesthetic/Portrait/From-Korean-MV-Todays_Mod":{"title":"Cute Portrait from Korean MV \u003cToday's Mood\u003e","content":"\nCredits to [MV - CHEEZE(치즈) _ Today's Mood(오늘의 기분)](https://www.youtube.com/watch?v=zRq_DlEzygk),\nThanks\n\nAlso, I see this in [摄影灵感｜那有一点可爱 - by   \n小八怪](https://www.xiaohongshu.com/explore/63f0a27e0000000013002b05)\n\n![](Photography/Aesthetic/Portrait/attachments/photo_4_2023-03-27_23-53-20.jpg)\n\n![](Photography/Aesthetic/Portrait/attachments/photo_5_2023-03-27_23-53-20.jpg)\n\n![](Photography/Aesthetic/Portrait/attachments/photo_6_2023-03-27_23-53-20.jpg)\n\n![](Photography/Aesthetic/Portrait/attachments/photo_7_2023-03-27_23-53-20.jpg)\n\n![](Photography/Aesthetic/Portrait/attachments/photo_8_2023-03-27_23-53-20.jpg)\n\n![](Photography/Aesthetic/Portrait/attachments/photo_9_2023-03-27_23-53-20.jpg)\n\n![](Photography/Aesthetic/Portrait/attachments/photo_1_2023-03-27_23-53-20%201.jpg)\n\n![](Photography/Aesthetic/Portrait/attachments/photo_2_2023-03-27_23-53-20%201.jpg)\n\n![](Photography/Aesthetic/Portrait/attachments/photo_3_2023-03-27_23-53-20%201.jpg)\n\n![](Photography/Aesthetic/Portrait/attachments/photo_2023-03-27_23-55-45.jpg)","lastmodified":"2023-06-10T07:55:31.601155429Z","tags":null},"/Photography/Aesthetic/Portrait/Portrait_MOC":{"title":"👧Portrait","content":"\n* [🌸Flower \u0026 Girl](Photography/Aesthetic/Portrait/Flower_and_Girl.md)\n* [👧🇰🇷Cute Portrait from Korean MV \u003cToday's Mood\u003e](Photography/Aesthetic/Portrait/From%20Korean%20MV%20Todays_Mod.md)\n","lastmodified":"2023-06-10T07:55:31.601155429Z","tags":null},"/Photography/Aesthetic/Style/Grainy_Green":{"title":"Grainy Green","content":"\n![](Photography/Aesthetic/Style/attachments/cinematicshine_326914596_601425291912114_4038822895364546166_n.jpg)\n\n\n![](Photography/Aesthetic/Style/attachments/cinematicshine_341207739_637183131584785_7839745357939483631_n.jpg)\n\n\n# Reference\n\n* [https://www.instagram.com/p/CrGoBoeo8NF/](https://www.instagram.com/p/CrGoBoeo8NF/)","lastmodified":"2023-06-10T07:55:31.621155728Z","tags":null},"/Photography/Aesthetic/Style/Style_MOC":{"title":"☝Style","content":"\n* [🌅Warmth - Nguan](Photography/Aesthetic/Style/Warmth_by_Nguan.md)\n* [📗 Grainy Green](Photography/Aesthetic/Style/Grainy_Green.md)\n","lastmodified":"2023-06-10T07:55:31.621155728Z","tags":null},"/Photography/Aesthetic/Style/Warmth_by_Nguan":{"title":"🎈Warmth - Nguan","content":"\nCredits to [Nguan](https://www.instagram.com/_nguan_/)\n\n\n![](Photography/Aesthetic/Style/attachments/167396766_118928406833773_7462235788758622009_n.jpg)\n\n![](Photography/Aesthetic/Style/attachments/275801921_507726407459443_2779968335661218284_n.jpg)\n\n![](Photography/Aesthetic/Style/attachments/275101252_116346090976633_4116581661408205933_n.jpg)\n\n\n![](Photography/Aesthetic/Style/attachments/152391470_356387755409221_8144178651765781801_n.jpg)\n\n\n![](Photography/Aesthetic/Style/attachments/153386473_426909131936316_8535520818773302544_n.jpg)\n\n\n![](Photography/Aesthetic/Style/attachments/156216827_337435770999537_8250898900544979316_n.jpg)\n\n\n","lastmodified":"2023-06-10T07:55:31.621155728Z","tags":null},"/Photography/Basic/MTF_Curve":{"title":"Modulation transfer function(MTF) Curve","content":"\n有很多因素影响lens performance：\n\n* diffraction\n* optical aberrations\n* design criteria and philosophy\n* manufacturing tolerances and errors\n\n一般，可以用MTF Curve来作为一个标准来衡量lens performance\n\n\u003e [!abstract] \n\u003e 本篇笔记会从摄影角度浅浅了解MTF曲线，而不从物理光学角度分析 \n\n# What is MTF Curve\n\n\n调制传递函数 (MTF) 曲线是一种信息密集型指标(information-dense metric)，反映了镜头如何*将对比度再现为空间频率（分辨率）的函数*。MTF Curve在一组设定好的基础参数下，提供一个composite view，关于光学像差([**optical aberrations**](Physics/Optical/optical_abberation.md))如何影响镜头性能。\n\n通过MTF图，我们可以知道\n\n1. 分辨率, (*代表着镜头对细节的表现能力*)\n2. 对比度, (*代表着镜头表现光线亮和暗的能力*)\n3. 色散和横向色差\n4. 像场弯曲\n\n不可以知道：\n\n1. 镜头畸变\n2. 径向色差\n3. 晕影\n4. 眩光\n\n# How to measure MTF Curve\n\n大家应该知道，一个镜头的中心比边缘成像能力要好很多，因此只测试镜头的中心或边缘，是不能代表镜头的好坏的，所以厂家会从中心到边缘，选取多个点进行测试。如下图，尼康的全画幅机器，选取了距离中心5毫米，10mm，15mm，20mm的点测试。如果是APS-C画幅，因为感光元件小，会选取3mm，6mm，9mm，12mm等，不同厂家可能不一样。\n\n![](Photography/Basic/attachments/Pasted%20image%2020230424143258.png)\n\n测试方法一般使用白色背景、黑色直线\n\n![](Photography/Basic/attachments/Pasted%20image%2020230424143425.png)\n\n* **粗线**用来测试**对比度**，粗度为 10 lines/mm\n* **细线**用来测试**分辨率**，粗度为 30 lines/mm\n* 粗细各有两组，一组与半径平行，叫做Sagittal，另一组与半径垂直，叫做Meridonial，这样做主要是为了测试**色散**和**色差**的。\n\n下图的成像质量是越来越差：\n\n![](Photography/Basic/attachments/Pasted%20image%2020230424143543.png)\n\n# How to read MTF curve\n\n![](Photography/Basic/attachments/Pasted%20image%2020230424143711.png)\n\n横坐标代表了到镜头中心的距离，纵坐标代表了对比度和分辨率的值。\n\n最完美的镜头的曲线应该是下面这样的，一条红线一条蓝线，\n\n红线是通过**粗线**测试得到的，代表**对比度**；\n\n蓝线是通过**细线**测试得到的，代表**分辨率**。\n\n![](Photography/Basic/attachments/Pasted%20image%2020230424143940.png)\n\n普通的镜头的曲线应该是下面这样的(红线代表对比度，蓝线代表分辨率)，在中心点，镜头的对比度和分辨率最好，越往边缘越差。\n\n一般来讲，值大于0.9就代表镜头非常优秀，0.7-0.9是优秀，0.5-0.7就是普通，低于0.5就算差了。\n\n注意到线的中级部位有呈波浪状，这表明了镜头的另一个参数素质：像场弯曲(curvature of field)\\\n\n有波浪就代表有像场弯曲，越大就越严重，实际情况一般问题不大。\n\n![](Photography/Basic/attachments/Pasted%20image%2020230424144046.png)\n\n最常见的MTF曲线如图：\n\n![](Photography/Basic/attachments/Pasted%20image%2020230424144112.png)\n\n1. 红线，10lines/mm，也就是上面测试时说的粗线，用来测对比度的，从镜头中心到边缘，数值逐渐降低，表明镜头的对比度从镜头到边缘，逐渐降低。\n2. 分辨率，从中心到边缘逐渐降低\n3. 色散和色差\n\t* 测试时粗细都有两组线吗，一组与半径平行，另一组垂直，用来测试色散和色差，这样就分别得到两条线，与半径平行的一组得到实线，与半径垂直的一组得到虚线。**虚线实线越接近，代表镜头的色散和色差控制的很好，越背离，表示越严重**。\n4. 像场弯曲\n\n# Reference\n\n* [The Modulation Transfer Function (MTF), https://www.edmundoptics.com](https://www.edmundoptics.com/knowledge-center/application-notes/imaging/modulation-transfer-function-mtf-and-mtf-curves/)\n* [MTF 曲线图应该怎么看？, 知乎](https://www.zhihu.com/question/19713211)","lastmodified":"2023-06-10T07:55:31.629155847Z","tags":null},"/Photography/Basic/Saturation":{"title":"Saturation - 饱和度","content":"\nto be written...","lastmodified":"2023-06-10T07:55:31.629155847Z","tags":null},"/Photography/Cameras_Research/Lens_Structure/Lens_Structure_MOC":{"title":"Lens Structure MOC","content":"\n* ","lastmodified":"2023-06-10T07:55:31.633155907Z","tags":null},"/Photography/Cameras_Research/Pocket_film/Pocket_film_camera_MOC":{"title":"Pocket Film camera MOC","content":"\n# Rollei\n\n* [Rollei35](Photography/Cameras_Research/Pocket_film/Rollei_35.md)","lastmodified":"2023-06-10T07:55:31.633155907Z","tags":null},"/Photography/Cameras_Research/Pocket_film/Rollei_35":{"title":"Rollei 35 review","content":"\n\n","lastmodified":"2023-06-10T07:55:31.633155907Z","tags":null},"/Photography/Cameras_Research/Polaroid/Polaroid":{"title":"Polaroid","content":"\n# Polaroid Background\n\n![](Photography/Cameras_Research/Polaroid/attachments/Pasted%20image%2020230330195031.png)\n\nPolaroid是一家成立于1937年的美国相机及照片制造公司，该公司曾经是即时相机市场的领导者。Polaroid公司在20世纪50年代推出了第一台即时相机，并在随后的几十年里不断推出各种型号的即时相机和胶片，成为了全球广泛使用的品牌。\n\nPolaroid最著名的特点之一是它的“即时影像”技术，这种技术可以使用户在拍摄后几秒钟内看到他们所拍摄的照片。Polaroid的即时相机成为了许多人记录重要时刻和创造独特艺术作品的选择。\n\n除了即时相机，Polaroid还生产和销售其他相机、相机附件、数码相框和照片打印机等产品。此外，Polaroid还与其他品牌合作，推出了许多联名款式的相机和其他产品。\n\n在Polaroid成立近90年的历史中，它的相机和胶片已经成为了文化和艺术的象征，并继续影响着人们对摄影和影像创作的认知。\n\n# Polaroid Camera Review\n\n* [Polaroid one600](Photography/Cameras_Research/Polaroid/Polaroid_one600.md)\n* [Polaroid Integral 600 Series](Photography/Cameras_Research/Polaroid/Polaroid_600.md)\n","lastmodified":"2023-06-10T07:55:31.633155907Z","tags":null},"/Photography/Cameras_Research/Polaroid/Polaroid_600":{"title":"Polaroid 600","content":"\n# Reference\n\n* [How do I use my Vintage Polaroid 600 camera? – Retrospekt](https://retrospekt.com/blogs/ask-the-expert/how-do-i-use-my-vintage-polaroid-600-instant-camera)\n* [Polaroid Integral 600 Series - Camera-wiki.org - The free camera encyclopedia](http://camera-wiki.org/wiki/Polaroid_Integral_600_Series)\n","lastmodified":"2023-06-10T07:55:31.633155907Z","tags":null},"/Photography/Cameras_Research/Polaroid/Polaroid_one600":{"title":"Polaroid_one600","content":"\n\n![](Photography/Cameras_Research/Polaroid/attachments/Pasted%20image%2020230330195707.png)\n\n# Specifications\n\n- **(Wide) 100mm lens with minimum focus distance of 3 feet.**\n- **Maximum Aperture F12.9 (Don't know if it can change)**\n- **1/200 s to 1/3 s**\n- **Fixed focus.**\n- Exposure modes - **Program automatic**\n- \"Aerodynamic\" styling (particularly when folded) with downward curve at back.\n- Flash moved to right hand side of user and can be manually switched on and off.\n- Hand grip on right.\n- LCD frame counter.\n- Self-timer.\n\n## Functionally similar models\n\n-   Polaroid One (silver/grey)\n-   Polaroid One600 Job Pro (black/silver/yellow) (Close-focus to 18 inches!)\n-   Polaroid One600 Nero (all black)\n-   Polaroid One600 \"Flowers\" (white with purple and yellow flower design)\n-   Polaroid One600 Panna (white/black)\n-   Polaroid One600 \"Poison Frog\" (silver/grey with yellow/black pattern)\n-   Polaroid One600 Polala 2006 (red/silver with gold Chinese dragon)\n-   Polaroid One600 Pro (all silver) (Like Job Pro, close-focus to 18 inches!)\n-   Polaroid One600 Royksopp (grey/silver with 'Royksopp - Only This Moment' branding)\n-   Polaroid One600 Superheadz Special Edition Red Hat (silver/black, with 'red hat' cartoon character)\n-   Polaroid One600 Rossa (bright red/black)\n-   Polaroid One Rossa (as above)\n-   Polaroid One Ultra (silver/black) (Close focus to 2 feet)\n-   Polaroid Pop Kit (silver/black with stickers for user's customization)\n\n# Reference\n\n* [Polaroid One 600 Camera Review - by Dan Finnen](https://danfinnen.com/review/polaroid-one-600-camera-review/)\n* [Polaroid One600 (Classic) - Camera-wiki.org - The free camera encyclopedia](http://camera-wiki.org/wiki/Polaroid_One600_(Classic))\n","lastmodified":"2023-06-10T07:55:31.633155907Z","tags":null},"/Photography/MoodBoard/Sea_20230428/Sea_20230428":{"title":"🌊Sea - 2023.04.28","content":"\n\n* [idea - reference image](Photography/MoodBoard/Sea_20230428/idea.md)\n","lastmodified":"2023-06-10T07:55:31.633155907Z","tags":null},"/Photography/MoodBoard/Sea_20230428/idea":{"title":"idea - reference image","content":"\n# [Fujifilm_Blue_by_小红书_Philips谢骏](Photography/Aesthetic/Landscape/Sea/Fujifilm_Blue_by_小红书_Philips谢骏.md)\n\n![](Photography/Aesthetic/Landscape/Sea/attachments/Pasted%20image%2020230420014349.png)\n\n\n![](Photography/Aesthetic/Landscape/Sea/attachments/Pasted%20image%2020230420014354.png)\n\n\n![](Photography/Aesthetic/Landscape/Sea/attachments/Pasted%20image%2020230420014401.png)\n\n\n![](Photography/Aesthetic/Landscape/Sea/attachments/Pasted%20image%2020230420014613.png)\n\n\n![](Photography/Aesthetic/Landscape/Sea/attachments/Pasted%20image%2020230420014622.png)\n\n\n![](Photography/Aesthetic/Landscape/Sea/attachments/Pasted%20image%2020230420014634.png)\n\n# [豊島_Instagram_shiifoncake](Photography/Aesthetic/Landscape/Sea/豊島_Instagram_shiifoncake.md)\n\n![](Photography/MoodBoard/Sea_20230428/attachments/shiifoncake_338949220_771246770941652_287141902256013940_n.jpg)\n\n![](Photography/MoodBoard/Sea_20230428/attachments/shiifoncake_339164445_155642070453847_6842139942547564019_n%20(1).jpg)\n\n![](Photography/MoodBoard/Sea_20230428/attachments/shiifoncake_339164445_155642070453847_6842139942547564019_n.jpg)\n\n![](Photography/MoodBoard/Sea_20230428/attachments/shiifoncake_338803198_1141886276488589_5464974698780309052_n%20(1).jpg)\n\n![](Photography/MoodBoard/Sea_20230428/attachments/shiifoncake_338803198_1141886276488589_5464974698780309052_n.jpg)\n\n![](Photography/MoodBoard/Sea_20230428/attachments/shiifoncake_338758486_601356648715316_3737336679741136784_n.jpg)\n\n\n# [寄り道の理由。- Instagram, photono_gen](https://www.instagram.com/p/CrVPFjZvvlr/)\n\n![](Photography/MoodBoard/Sea_20230428/attachments/photono_gen_336060179_2380745882102401_2427706248624984378_n.jpg)","lastmodified":"2023-06-10T07:55:31.641156026Z","tags":null},"/Photography/Photography_MOC":{"title":"Photography - MOC","content":"\n# 🌊Photo Portfolio\nYou can see my photography works in:\n\n* [🎨Slide show](https://pinkr1ver.com/PhotoGallery/)\n* [🌄Photo Collection in Notion](https://www.notion.so/pinkr1ver/3cfdd332b9a94b20bca041f2aa2bdcd2?v=24e696e6ab754386a710bc8e83976357)\n* [🍻Instagram](https://www.instagram.com/jude.wang.yc/?next=%2F)\n* [🧶小红书](https://www.xiaohongshu.com/user/profile/6272c025000000002102353b)\n\n# Notes\nAlso, here's my notes about learning photography\n\n## About Basic Concepts:\n\n* [Saturation](Photography/Basic/Saturation.md)\n\n## Appreciation of other works - about ***aesthetic***\n\n* [👧Portrait](Photography/Aesthetic/Portrait/Portrait_MOC.md)\n* [🏔Landscape](Photography/Aesthetic/Landscape/Landscape_MOC.md)\n* [☝Style](Photography/Aesthetic/Style/Style_MOC.md)\n* [✨Polaroid](Photography/Aesthetic/Polaroid/Polaroid_aesthetic_MOC.md)\n\n## Camera Research\n\n* [✨Polaroid](Photography/Cameras_Research/Polaroid/Polaroid.md)\n* [📷Lens Structure](Photography/Cameras_Research/Lens_Structure/Lens_Structure_MOC.md)\n* [📸Pocket film camera](Photography/Cameras_Research/Pocket_film/Pocket_film_camera_MOC.md)\n\n## Skills I learned\n\n* [How to measure light using Polaroid?](Photography/Skills/Polaroid_light.md)\n* [How to use Moodboard](Photography/Skills/Moodboard.md)\n* [How to show your Polaroid Picture](Photography/Aesthetic/Polaroid/Polaroid_showcase.md)\n\n## Photography story\n\n* [夜爬蛤蟆峰拍Polaroid慢门 - 2023.04.14](Photography/Story/Rainy_evening_hiking_Polaroid.md)\n\n##  Mood Board\n\n* [🌊Sea - 2023.04.28](Photography/MoodBoard/Sea_20230428/Sea_20230428.md)\n\n## Meme\n\n* [Photography meme](Photography/Photography_meme/Photography_meme.md)\n\n\n# Reference\n\n## Platform\n\n* [Magnum Photos](https://www.magnumphotos.com/)\n* [CNU - Catch Next Ultimate](http://www.cnu.cc/)\n\n## Greatest Artist\n\n* [linksphotograph](https://www.linksphotograph.com/)\n* [HAMADA Hideaki / 濱田英明](https://www.hideakihamada.com)\n* [Jason Kummerfeldt](https://graincheck.darkroom.com/) and [his youtube](https://www.youtube.com/@grainydaysss)\n* [Nguan](https://nguan.tv/)\n* [Marta Bevacqua](https://www.martabevacquaphotography.com/)\n* [Sam Zhang](https://www.instagram.com/itscapturedbysam/)\n\n## Content Collector \u0026 Photographer\n\n* [🦺搬运UP主 - 豆腐素包](https://space.bilibili.com/196700312/video)\n* [小八怪 - 小红书](https://www.xiaohongshu.com/user/profile/5558b47f5894463d532a632c)\n\n","lastmodified":"2023-06-10T07:55:31.641156026Z","tags":null},"/Photography/Photography_meme/Photography_meme":{"title":"Photography Meme","content":"\n![](Photography/Photography_meme/attachments/QQ图片20230424193512.png)","lastmodified":"2023-06-10T07:55:31.641156026Z","tags":null},"/Photography/Skills/Moodboard":{"title":"How to use Moodboard","content":"\n# Overview\n\n1. 选题\n2. 风格\n3. 色彩\n4. 服装道具\n5. 模特\n6. 场地\n7. 构图\n8. 布光\n\n# 选题\n\n将参考图放进灵感文件夹\n\n# 风格\n\n在参考图中风格提取，一般可以收集200张参考图\n\n# 色彩\n\n使用[Adobe Color](https://color.adobe.com/)确定色彩方案\n\n\n# 服装道具\n\n略\n\n# 模特\n\n略\n\n# 场地\n\n略\n\n# 构图\n\n使用参考图和手绘\n\n# 布光\n\n略\n\n# Reference\n\n* [要做出完美的拍摄策划，必须知道的8个重点 - 小红书, Tripitaka Wu](https://www.xiaohongshu.com/user/profile/6272c025000000002102353b/62024914000000002103cedf)","lastmodified":"2023-06-10T07:55:31.645156086Z","tags":null},"/Photography/Skills/Polaroid_light":{"title":"How to measure light using Polaroid?","content":"\nThe most thing you need to know is that, **the right exposure is in your head**.\n\n# Basic\n\n\n\n# Practice\n\n\n# Reference\n\n* [How to EXPOSE your POLAROID PICTURE - Youtuber Analog Things](https://www.youtube.com/watch?v=iqU5YRG8WiE)\n\n","lastmodified":"2023-06-10T07:55:31.645156086Z","tags":null},"/Photography/Skills/howToShowPolaroid":{"title":"How to Show Polaroid?","content":"\n* [宝丽来翻拍9宫格](Photography/Aesthetic/Polaroid/Polaroid_showcase.md)","lastmodified":"2023-06-10T07:55:31.645156086Z","tags":null},"/Photography/Story/Rainy_evening_hiking_Polaroid":{"title":"夜爬蛤蟆峰拍Polaroid慢门 - 2023.04.14","content":"\n# Hiking\n\n周五，周潭来杭，计划去蛤蟆峰顶拍拍立得慢门，记录西湖夜景。\n\n晚饭后，雨渐起，兴致不减，亦去。\n\n山底已经在小雨中颇有丁达尔现象的感觉。\n\n![](Photography/Story/attachments/9970714720C0835E6547C263418D551B.jpg)\n\n雨让石头逐渐变得打滑，蛤蟆峰山顶的石头快的攀登会变得非常危险，这一点难以描述，或许你可以问你杭州本地的朋友。周潭在攀登最后一段路程之前摔倒，还好背包缓冲了几乎所有的冲撞，也让他意识到雨天来到这里的危险性，是具有极限运动的底色在的。\n\n最后，在小心翼翼中，登顶了。\n\n# Photographer\n\n在蛤蟆峰顶拍慢门需要一定的三脚架架设技巧和测光技巧，在雨中就显得更加困难。\n\n![](Photography/Story/attachments/QQ视频20230416012046.mp4)\n\n![](Photography/Story/attachments/FCB8B96468D3B459532E010E865D0B99.jpg)\n\n\n经过测光和宝丽来app曝光调整，这次拍摄夜景的计划以$f/22$, 30s shutter speed, i-type film 640 ISO进行拍摄，先看成片效果：\n\n![](Photography/Story/attachments/IMG_5553.jpg)\n\n照片由iPhone 12 mini Polaroid app scanner扫描完成的film -\u003e digital，效果比较一般，但我们能看出，曝光的效果不尽人意。这里的原因认为由以下原因导致：\n* 天气恶劣，空气湿度大，造成光线色散加重\n* 没有考虑i-type相纸**倒易率**，曝光时间不足（重要原因🚧🚧🚧）\n* 没有查询Polaroid now+镜头最好的光学素质的参数，自认为是$f/22$，导致曝光时间过长导致的点光源色散严重。（目前还没有查询到Polaroid now+镜头的光学参数曲线🚧🚧🚧）\n\n同时，那晚还不懂now+ +键的使用导致相纸浪费一张，下面是now+中+键的用法：\n\n![](Photography/Story/attachments/Pasted%20image%2020230416014050.png)\n\n同时，那晚曝光时，有一次光圈不小心打到$f/33$，导致欠曝地更为厉害，其效果大概如下：\n\n![](Photography/Story/attachments/IMG_5550.jpg)\n\n同时要注意的是，Polaroid的曝光时间最多是30s，如果要更长时间的曝光，可以不弹相纸进行二次曝光，但是长曝光30s以上可能效果很差。\n\n## 人像\n\n搞了两张人像，同样的曝光参数$f/22$, 30s shutter speed, i-type film 640 ISO，开了宝丽来闪关灯最大等级：\n\n![](Photography/Story/attachments/IMG_5492.jpg)\n\n\n![](Photography/Story/attachments/IMG_5493.jpg)\n\n第一张人像清晰些，以我个人观点来看，是因为伞造成的反射\n\n# 返程\n\n返程的故事有趣了些，因为三脚架落在了山脚，于是返回去取，但是去取的时候手机落在了打的网约车上。\n\n因为手机丢了，所以无法确认订单的详细信息，也就无法联系司机和客服。\n\n所以用周潭的手机去登录高德打车去确认订单，但是登录高德又需要手机验证码，非常傻逼的设计就是了，还好带了apple watch，连接了周潭的热点后可以同步手机消息收到验证码，这才登上了高德地图。\n\n高德地图的打车是联动多家打车公司的，所以情况错综复杂，我的订单来自天猫出行，高德端不允许我直接联系师傅，同时天猫出行的客服也无法拨通，最后还好拨通了高德客服的电话，联系上了师傅。\n\n师傅当时前往了滨江，所以我们只好在山脚下，也就是保俶路的忠儿面馆那里等待，刚好周潭没有吃饱，起源巧合下，在这也算吃了一顿还算杭州特色的拌川。\n\n![](Photography/Story/attachments/A9A6699D1859851AB1D66131BD1382DC.jpg)\n\n\n# Route\n\n![](Photography/Story/attachments/QQ图片20230417203443.jpg)","lastmodified":"2023-06-10T07:55:31.645156086Z","tags":null},"/Physics/Electromagnetism/Basic/Electric_units":{"title":"Electric Units","content":"# Electrical impedance\n\n$$\nZ = \\sqrt{R^2 + {(X_L-X_C)}^2}\n$$\n\n\n* $Z$ = impedance\n* $R$ = resistance\n* $X_L$  = inductive reactance\n* $X_C$  = capacitive reactance\n\n![](Physics/Electromagnetism/Basic/attachments/Pasted%20image%2020230330163734.png)\n\n**阻抗**是电路中电阻、电感、电容对交流电的阻碍作用的统称。阻抗是一个复数，实部称为**电阻**，虚部称为**电抗**；其中电容在电路中对交流电所起的阻碍作用称为**容抗**，电感在电路中对交流电所起的阻碍作用称为**感抗**，容抗和感抗合称为**电抗**。\n\n阻抗将电阻的概念加以延伸至交流电路领域，不仅描述*电压与电流的相对振幅*，也描述其*相对相位*。当通过电路的电流是直流电时，电阻与阻抗相等，电阻可以视为相位为零的阻抗。\n\n## 形式\n\n1. $R+jX$\n2. $Z_m\\angle\\theta$\n3. $Z_m e^{j\\theta}$\n\n阻抗定义为电压与电流的频域比率。阻抗的大小$Z_{m}$ 是电压振幅与电流振幅的绝对值比率，阻抗的相位 $\\theta$是电压与电流的相位差。\n\n## 欧姆定律\n\n$$\nv = iZ = iZ_m e^{j\\theta}\n$$\n\n阻抗大小$Z_m$的作用恰巧就像电阻，设定电流$i$，就可以计算出阻抗$Z$两端的电压降$v$。相位因子$e^{j\\theta}$则是电流滞后于电压的相位差$\\theta$ \n\n\u003e [!tip] \n\u003e 在时域中，电流信号会比电压信号慢$\\theta T/2\\pi$秒\n\n## 理想的阻抗\n$$\nZ_R = R\n$$\n\n$$\nZ_C = \\frac{1}{j\\omega C}\n$$\n\n$$\nZ_L = j \\omega L\n$$\n\n* 对于电容，交流电压滞后90°于交流电流；\n* 对于电感，交流电压超前90°于交流电流\n\n### 容抗\n\n$$\nX_C = -j/\\omega C\n$$\n随着$\\omega$趋向于0，电源趋向于直流电源，容抗的绝对值趋向于无穷；*因此，在低频率运作时，电容器貌似断路。假设电源的频率越高，则容抗越低，对于电流通过的阻碍也越低。在高频率运作时，电容器貌似短路。*\n\n### 阻抗\n\n$$\nX_L = j\\omega L\n$$\n从这方程可以观察到，当交流电源的角频率趋向于零时，电源会趋向于直流电源，感抗会趋向于零，对于电流的通过阻碍越低。*所以，在低频率运作时，电感器貌似短路。假设电源角频率越高，则感抗越高，假设给定电压源振幅，则电流会趋向于零。所以，在高频率运作时，电感器貌似断路。*\n\n\n# Reference\n\n[电气单位（V，A，Ω，W，...） (rapidtables.org)](https://www.rapidtables.org/zh-CN/electric/Electric_units.html)\n","lastmodified":"2023-06-10T07:55:31.713157102Z","tags":null},"/Physics/Electromagnetism/Electromagnetism_MOC":{"title":"Electromagnetism MOC","content":"\n# Basic\n\n* [Electric units](Physics/Electromagnetism/Basic/Electric_units.md)\n\n## Advanced\n\n* [Maxwell's equation](Physics/Electromagnetism/Maxwells_equation.md)\n\n# Circuit\n\n* [Resonant circuit](Physics/Electromagnetism/Resonant_circuit.md)","lastmodified":"2023-06-10T07:55:31.713157102Z","tags":null},"/Physics/Electromagnetism/Maxwells_equation":{"title":"Maxwell's Equation","content":"\n# Equation\n\n\n$$\n\\nabla \\cdot E = \\frac{\\rho}{\\epsilon_0}\n$$\n\n$$\n\\nabla \\cdot B = 0\n$$\n\n$$\n\\nabla \\times E = -\\frac{\\partial B}{\\partial t}\n$$\n\n$$\n\\nabla \\times B = \\mu_0 (J + \\epsilon_0 \\frac{\\partial E}{\\partial t})\n$$\n\n# Vector field\n\nEssentially a vector field is what you get if you associate each point in space with a vector, some magnitude and direction. Maybe those vectors represent the velocities of particles of fluid at each point in space or maybe they represent the force of gravity at many different points in space or maybe a magnetic field strength.\n\n\u003e [!note] \n\u003e  If you were to draw the vectors to scale, the longer ones end up just cluttering the whole thing, so it's common to basically lie a little and artificially shorten ones that are too long. Maybe using **color to give some vague sense of length**.\n\n![](Physics/Electromagnetism/attachments/Pasted%20image%2020230411151612.png)\n\n## Divergence\n\n![](Physics/Electromagnetism/attachments/my-life.gif)\n\nDivergence $\\cdot$ Vector filed是来衡量在(x, y)点你产生fluid的能力\n\n所以上述图中，产生fluid的source点，他们的Divergence $\\cdot$ Vector filed是positive的\n\n那些fluid流入的sink端，他们的Divergence $\\cdot$ Vector filed就是negative的\n\n![](Physics/Electromagnetism/attachments/Pasted%20image%2020230411155711.png)\n\n同时，如果点可以slow flow in变fast slow out，这个点位的divergence $\\cdot$ vector filed也是positive的\n\n![](Physics/Electromagnetism/attachments/my-life%201.gif)\n\nVector field input point得到的是一个多维的输出，指向一个方向并带有scale；divergence $\\cdot$ vector field，它的输出depends on the behavior of the field in small neighborhood around that point。输出为一个数值，衡量这个point acts as a source or a sink\n\n![](Physics/Electromagnetism/attachments/Pasted%20image%2020230411161346.png)\n\n\u003e [!note] \n\u003e  For actual fluid flow: $\\text{div} F = 0$ everywhere\n\n## Curl\n\n![](Physics/Electromagnetism/attachments/output%202.gif)\n\nCurl是衡量fluid在point被rotate的程度，clockwise方向是positive curl，counterclockwise是negative curl。\n\n![](Physics/Electromagnetism/attachments/curl.gif)\n\n上图中这个点的curl也是非零的，因为fluid上快下慢，result in clockwise influence\n\n## Calculate divergence and curl\n\n$$\n\\text{div} F = \\nabla \\cdot F = \n\\begin{bmatrix}\n\\frac{\\partial}{\\partial x} \\\\\n\\frac{\\partial}{\\partial y}\n\\end{bmatrix} \\cdot\n\\begin{bmatrix}\nF_x \\\\\nF_y\n\\end{bmatrix} = \\frac{\\partial F_x}{\\partial x} + \\frac{\\partial F_y}{\\partial y}\n$$\n\n$$\n\\text{curl} F = \\nabla \\times F = \n\\begin{bmatrix}\n\\frac{\\partial}{\\partial x} \\\\\n\\frac{\\partial}{\\partial y}\n\\end{bmatrix} \\times\n\\begin{bmatrix}\nF_x \\\\\nF_y\n\\end{bmatrix}\n= \\frac{\\partial F_y}{\\partial x} - \\frac{\\partial F_x}{\\partial y}\n$$\n\n![](Physics/Electromagnetism/attachments/calculation_result.gif)\n\n### Detail Explanation\n\n![](Physics/Electromagnetism/attachments/Pasted%20image%2020230412144351.png)\n\n![](Physics/Electromagnetism/attachments/Pasted%20image%2020230412144501.png)\n\n在$(x_0, y_0)$微分一个很小的tiny step，会有一个新的vector，它与原有的vector会有一个difference。\n\n![](Physics/Electromagnetism/attachments/div.gif)\n\n$\\text{div} F(x_0, y_0)$其实就是corresponds to $360^\\circ$方向的average的Step $\\cdot$ Difference\n\n可以想象一个source端，它朝四面发射vector，它的Step $\\cdot$ Difference自然就是positive的\n\n![](Physics/Electromagnetism/attachments/Pasted%20image%2020230412145732.png)\n\n同理，不难想象的是，$\\text{curl} F(x_0, y_0)$是corresponds to Step $\\times$ Difference\n\n# Understand Maxwell's Equation\n\n学会vector filed中的divergence和curl，是理解Maxwell’s Equation的关键\n\n## Gauss's Law\n\n$$\n\\text{div} E = \\frac{\\rho}{\\epsilon_0}\n$$\n\n\n![](Physics/Electromagnetism/attachments/Pasted%20image%2020230411163735.png)\n\n* $\\rho$是charge density\n* $\\epsilon_0$是Epsilon Naught，free space的介电常数，它决定free space空间中电场的强度\n\n\u003e [!note] \n\u003e 形象的\n\u003e \n\u003e Gauss's law stating that **divergence of an electric field at a given point is a proportional to the charge density at that point**. \n\u003e \n\u003e **Positively charged regions as acting like sources** of some imagined fluid and n**egatively charged regions as being the sinks** of that fluid.\n\u003e \n\u003e Parts of space where there is on charge the fluid **would be flowing incompressively** just like water.\n\n\n## Gauss's law for magnetism\n\n$$\n\\text{div} B = 0\n$$\n\n![](Physics/Electromagnetism/attachments/Pasted%20image%2020230411165048.png)\n\n磁场的divergence在任意地方为0，说明磁场的fluid是incompressible的，没有source也没有sinks，就像water一样。也有这样的interpretation，说明magnetic monopoles是不存在的\n\n## Maxwell–Faraday equation (Faraday's law of induction)\n\n$$\n\\nabla \\times E = - \\frac{1}{c} \\frac{\\partial B}{\\partial t}\n$$\n\n![](Physics/Electromagnetism/attachments/Pasted%20image%2020230419141438.png)\n\n![](Physics/Electromagnetism/attachments/Pasted%20image%2020230419141637.png)\n## Ampère's circuital law (with Maxwell's addition)\n\n$$\n\\nabla \\times B = \\frac{1}{c} (4\\pi J + \\frac{\\partial E}{\\partial t})\n$$\n\n![](Physics/Electromagnetism/attachments/Pasted%20image%2020230419141737.png)\n\n\n# Maxwells equation explain EM wave\n\nMaxwells的完备对称理论表明，电场力和磁力并不是分开的，而是同一事物——电磁力的不同表现形式。 这种力的经典统一是当前试图统一自然界中四种基本力——引力、电力、强核力和弱核力——的动机之一。\n\nMaxwells从Maxwells equation中预测了EM wave的存在。\n\nMaxwells意识到振荡电荷，就像交流电路中的电荷一样，会产生变化的电场。 他预测这些变化的场会像跳跃的鱼在湖上产生的波浪一样从源头传播。\n\n麦克斯韦预测的波将由振荡电场和磁场组成——定义为电磁波（EM 波）。 电磁波能够对距其源很远的电荷施加力，因此它们可能是可检测的。 Maxwells通过求解Maxwells方程组，可以求出EM的速度$c$，\n\n$$\nc = \\frac{1}{\\sqrt{\\mu_0 \\epsilon_0}} = 3 \\times 10^8 m/s\n$$\n\n电磁波的波段处于无法被肉眼观测的波段，直到Maxwells去世后，才被Hertz用实验证实了电磁波的存在。\n\n![](Physics/Electromagnetism/attachments/Pasted%20image%2020230419155744.png)\n\n# Reference\n\n* [Fun fluid-flow illustrations - by 3B1B](https://anvaka.github.io/fieldplay/?cx=0\u0026cy=0\u0026w=8.5398\u0026h=8.5398\u0026dt=0.01\u0026fo=0.998\u0026dp=0.009\u0026cm=1\u0026vf=%2F%2F%20p.x%20and%20p.y%20are%20current%20coordinates%0A%2F%2F%20v.x%20and%20v.y%20is%20a%20velocity%20at%20point%20p%0Avec2%20get_velocity%28vec2%20p%29%20%7B%0A%20%20vec2%20v%20%3D%20vec2%280.%2C%200.%29%3B%0A%0A%20%20%2F%2F%20change%20this%20to%20get%20a%20new%20vector%20field%0A%20%20v.x%20%3D%20p.y%3B%0A%20%20v.y%20%3D%20%28max%28cos%28sin%28p.y%29%29%2Csin%28p.y%29%2Fp.y%29%2Bp.y%29%3B%0A%0A%20%20return%20v%3B%0A%7D\u0026code=%2F%2F%20p.x%20and%20p.y%20are%20current%20coordinates%0A%2F%2F%20v.x%20and%20v.y%20is%20a%20velocity%20at%20point%20p%0Avec2%20get_velocity%28vec2%20p%29%20%7B%0A%20%20vec2%20v%20%3D%20vec2%280.%2C%200.%29%3B%0A%0A%20%20%2F%2F%20change%20this%20to%20get%20a%20new%20vector%20field%0A%20%20v.x%20%3D%20%28max%28p.x%2Cp.y%29%2Bmax%28p.y%2Cp.x%29%29%3B%0A%20%20v.y%20%3D%20p.y%3B%0A%0A%20%20return%20v%3B%0A%7D)\n* [Divergence and curl: The language of Maxwell's equations, fluid flow, and more - YouTube vedio by 3b1b](https://www.youtube.com/watch?v=rB83DpBJQsE)\n* [Let There Be Light: Maxwell's Equation EXPLAINED for BEGINNERS - YouTube vedio by Parth G](https://www.youtube.com/watch?v=0jW74lrpeM0)\n* [Faraday’s Law - online experiment](https://em.geosci.xyz/content/maxwell1_fundamentals/formative_laws/faraday.html)\n* [# Maxwell’s Equations- Electromagnetic Waves Predicted and Observed](https://phys.libretexts.org/Bookshelves/College_Physics/Book%3A_College_Physics_1e_(OpenStax)/24%3A_Electromagnetic_Waves/24.01%3A_Maxwells_Equations-_Electromagnetic_Waves_Predicted_and_Observed)","lastmodified":"2023-06-10T07:55:31.713157102Z","tags":null},"/Physics/Electromagnetism/Q_factor":{"title":"Q factor","content":"\n# Explanation\n\nIn physics and engineering, the quality factor or Q factor is a **dimensionless** parameter that describes how **underdamped** an oscillator or *resonator* is. It is defined as the ratio of the initial energy stored in the resonator to the *energy lost* in one radian of the cycle of oscillation. Q factor is alternatively defined as the ratio of a *resonator's center frequency to its bandwidth* when subject to an oscillating driving force. These two definitions give *numerically similar*, but not identical, results. \n\n\u003e [!tip] \n\u003e  高Q因子表示振子能量损失的速率较慢，振动可持续较长的时间; 单摆在空气中Q因子较高而在油中较低\n\n\n\n![](Physics/Electromagnetism/attachments/Pasted%20image%2020230404144801.png)\u003cfont size=1\u003eFig. A damped oscillation. A low Q factor – about 5 here – means the oscillation dies out rapidly.\u003c/font\u003e\n\n\nQ因子较高的振子在共振时，在共振频率附近的**振幅较大**，但会产生的共振的**频率范围比较小**，此频率范围可以称为频宽。\n\n例如一台无线电接收器内的调谐电路Q因子较高，要调整接收器对准一特定频率会比较困难，但其选择性较好，在过滤频谱上邻近电台的讯号上也有较佳的效果。\n\n系统的Q因子可能会随著应用场合及需求的不同而有大幅的差异。*强调阻尼特性的系统*（例如[防止门突然关闭的阻尼器](warehouse/dampers_keeping_a_door_from_slamming%20shut.md)）*其Q因子为1⁄2*，而时钟、雷射或是其他需要强烈共振或是要求频率稳定性的系统其Q因子也较高。音叉的Q因子大约为1000，原子钟、加速器中的超导射频或是光学共振腔的Q因子可以到$10^{11}$\n\n\u003e [!help] \n\u003e  There are many *alternative quantities* used by physicists and engineers to describe how damped an oscillator is. Important examples include: the [damping ratio](https://en.wikipedia.org/wiki/Damping_ratio \"Damping ratio\"), [relative bandwidth](https://en.wikipedia.org/wiki/Bandwidth_(signal_processing) \"Bandwidth (signal processing)\"), [linewidth](https://en.wikipedia.org/wiki/Oscillator_linewidth \"Oscillator linewidth\") and bandwidth measured in [octaves](https://en.wikipedia.org/wiki/Octave_(electronics) \"Octave (electronics)\").\n\n\n# Definition\n\n![](Physics/Electromagnetism/attachments/Pasted%20image%2020230404151254.png)\n\n\u003cfont size=1\u003eFig. 一阻尼谐振子的频宽, $\\Delta f$可以用频率和能量的图来表示。阻尼谐振子（或滤波器）的Q因子为$f_{0}/\\Delta f$。Q因子越大，其波峰高度会越高，而其宽度会越窄\u003c/font\u003e\n\nIn the context of resonators, there are two common definitions for Q, which aren't exactly equivalent. They become approximately equivalent *as Q becomes larger*, meaning the resonator becomes less damped.\n\n## Bandwidth definition\n\n$$Q\\stackrel{def}{=}\\frac{f_r}{\\Delta f}=\\frac{\\omega_r}{\\Delta \\omega}$$\n\n$f_r$为共振频率，$\\Delta f$为频宽，一般是 [full width at half maximum](https://en.wikipedia.org/wiki/Full_width_at_half_maximum \"Full width at half maximum\") (FWHM)\n\n## Stored energy definition\n\nQ因子可定义为在一系统的共振频率下，当信号振幅不随时间变化时，**系统储存能量和每个周期外界所提供能量的比例**（此时系统储存能量也不随时间变化）\n\n$$Q = 2\\pi \\times \\frac{\\text{Energy Stored}}{\\text{Energy dissipated per cycle}}=2\\pi f_r \\times \\frac{\\text{Energy Stored}}{\\text{Power Loss}}$$\n\n同时在像电感等储能元件的规格中，会用到和频率有关的Q因子，其定义如下\n\n$$Q(\\omega) = \\omega \\times \\frac{\\text{Maximum Energy Stored}}{\\text{Power Loss}}$$\n\n其中$\\omega$是计算储存能量和功率损失时的角频率\n\n\n# Reference\n\n* [Q factor in  wiki](https://en.wikipedia.org/wiki/Q_factor)\n* [品质因子](https://zh.wikipedia.org/zh-hans/%E5%93%81%E8%B3%AA%E5%9B%A0%E5%AD%90#:~:text=%E5%93%81%E8%B4%A8%E5%9B%A0%E5%AD%90%E6%88%96Q%E5%9B%A0%E5%AD%90,%E6%91%86Q%E5%9B%A0%E5%AD%90%E8%BE%83%E4%BD%8E%E3%80%82)","lastmodified":"2023-06-10T07:55:31.713157102Z","tags":null},"/Physics/Electromagnetism/Resonant_circuit":{"title":"Resonant circuit","content":"\n以RLC串联电路为例\n\n# 什么是谐振\n\n电路中电容器$L$、电感器$C$两组件之能量相等，当能量由电路中某一电抗组件释出时，且另一电抗组件必吸收相同之能量，即此两电抗组件间会产生一能量脉动。\n\n# 两种简单的谐振电路\n![](Synthetic%20Aperture%20Radar%20Imaging/attachments/Pasted%20image%2020230330160535.png)\n\n\n以串联谐振为例\n\n## *Resonant Frequency*\n\n电容，电阻的[电抗](Physics/Electromagnetism/Basic/Electric_units.md#Electrical%20impedance)相同时发生谐振\n\n$$\n|X_C| = |\\frac{1}{j2\\pi fC}| = |X_L| = |j2\\pi fL|\n$$\nRearranging,\n\n$$\nf^2 =  \\frac{1}{(2\\pi)^2 C L}\n$$\n\n$$\nf = \\frac{1}{2\\pi \\sqrt{LC}}\n$$\n\n## 串联谐振特性\n\n* 阻抗最小，且为纯电阻，$Z = R+jXL-jXC = R$ \n\n## **品质因子** ([*Q factor*](Physics/Electromagnetism/Q_factor.md))\n\n* 电感器或电容器在谐振时产生的电抗功率与电阻器消耗的平均功率之比，称为谐振时之品质因子。\n\n$$Q=\\frac{Q_L}{P}=\\frac{I^2X_L}{I^2R}=\\frac{Q_C}{P}=\\frac{I^2X_C}{I^2R}=\\frac{1}{R}\\sqrt{\\frac{L}{C}}=\\frac{\\sqrt{X_LX_C}}{R}$$\n\n#### 阻抗与频率的关系\n\n$Z = R + j(X_L-X_C)$\n* 当$f＝f_r$时，$Z＝R$为最小值，电路为电阻性；\n* 当$f＞f_r$时，$X_L＞X_C$为最小值，电路为电感性；\n* 当$f＜f_r$时，$X_L＜X_C$为最小值，电路为电容性。\n","lastmodified":"2023-06-10T07:55:31.713157102Z","tags":null},"/Physics/Optical/optical_abberation":{"title":"Optical Abberation","content":"\n# What is optical aberration\n\n光学像差是指镜头设计中的缺陷，它会导致光线散开而不是聚焦以形成清晰的图像。 范围从图像中的所有光线到只有某些点或边缘失焦。 成像时可能会出现几种类型的光学像差。 构建一个校正了所有可能像差的理想视觉系统会显着增加镜头的成本。 实际上，镜头中总会存在某种形式的像差，但将像差的影响降至最低至关重要。 因此，制造任何镜头通常都会做出一些妥协。\n\n# Circle of confusion\n\n要解释像差如何使图像模糊，首先要解释一下：什么是混淆圈？ 当来自目标的光点到达镜头，然后会聚在传感器上时，它会很清晰。 否则，如果它在传感器之前或之后会聚，则传感器上的光分布会更广。 这可以在图 1 中看到，其中可以看到点光源会聚在传感器上，但随着传感器位置的变化，沿传感器散布的光量也会发生变化。\n\n![](Physics/Optical/attachments/Fig_1_Circles_of_confusion.gif)\n\n光线越分散，图像的焦点就越少。 除非光圈很小，否则图像中彼此距离较大的目标通常会使背景或前景失焦。 这是因为会聚在前景中的光与来自背景中较远目标的光会聚在不同的点。\n\n# Types of Optical Aberration\n\n## Coma（慧差）\n\n\n彗形像差，又称彗星像差，此种像差的分布形状以类似于彗星的拖尾而得名。\n\n![](Physics/Optical/attachments/Pasted%20image%2020230424110844.png)\n\n这是一些透镜固有的或是光学设计造成的缺点，导致离开光轴的点光源，例如恒星，产生变形。特别是，彗形像差被定义为偏离入射光孔的放大变异。在折射或衍射的光学系统，特别是在宽光谱范围的影像中，彗形像差是波长的函数。\n\n## Astigmatism （像散）\n\n在两个垂直平面中传播的光线在聚焦于不同点时可能会产生像散。\n\n这可以在图 3 中看到，其中两个焦点由红色水平面和蓝色垂直面表示。 图像中的最佳清晰度点将在这两个点之间，其中任一平面的混淆圈都不太宽。\n\n![](Physics/Optical/attachments/Pasted%20image%2020230424111226.png)\n\n当光学器件未对准时，散光会导致图像的侧面和边缘失真。 它通常被描述为在查看图像中的线条时缺乏清晰度。\n\n这种形式的像差可以使用大多数优质光学器件中的适当透镜设计来校正。 固定散光的光学元件的最初设计是由卡尔蔡司完成的，并且已经发展了一百多年。 在这一点上，它通常只出现在质量非常低的镜头中，或者内部光学元件已损坏或通过镜头滴移动的情况下。\n\n## (Petzval) Field Curvature （场曲）\n\n许多镜头都有圆形的焦点。 这会导致图像出现柔和的角，主要是使图像的中心保持在焦点上。 然而，大多数镜头都有一些圆形的焦点，如果不进行一些裁剪，就无法聚焦整个图像。\n\n场曲是图像平面由于多个焦点而变得不平坦的结果。\n\n![](Physics/Optical/attachments/Pasted%20image%2020230424112159.png)\n\n相机镜头已在很大程度上纠正了这一点，但在许多镜头上可能会发现一些场曲。 一些传感器制造商实际上正在研究可以校正弯曲焦点区域的弯曲传感器。 这种设计将允许传感器校正像差，而不需要以这种精度生产昂贵的镜头设计。 通过实施这种类型的传感器，可以使用更便宜的镜头来产生高质量的结果。 这方面的真实例子可以在开普勒太空天文台看到，那里使用弯曲的传感器阵列来校正望远镜的大型球面光学元件。\n\n## Distortion (畸变)\n\n畸变是指当一物体通过Lens系统成像时，会产生一种对物体不同部分有不同的放大率的像差，此种像差会导致物像的相似性变坏。但不影响像的清晰度。 根据对物体周边及中心有放大率的差异此种像差可分为两类： \n\n### Barrel distortion （桶形畸变）\n\n具有桶形失真的图像的边缘和侧面远离中心弯曲。 这在视觉上看起来像是图像中有一个凸起，因为它捕获了弯曲视场 (FoV, field of view) 的外观。 例如，当在高层建筑的高处使用较低焦距的镜头（也称为广角镜头）时，可以捕捉到更宽的 FoV。 如图 5 所示，使用产生非常扭曲和宽 FoV 的鱼眼镜头时，这种情况最为夸张。在此图像中，网格线用于帮助说明失真效果如何在靠近侧面的地方向外产生更拉伸的图像， 边缘。\n\n![](Physics/Optical/attachments/Pasted%20image%2020230424113453.png)\n\n\n### Pincushion distortion （枕型畸变）\n\n当光线通过枕形畸变向光轴弯曲时，图像看起来会向内拉伸。 因此，图像的边缘和侧面看起来会向图像的中心弯曲。\n\n这种形式的像差最常见于焦距较长的远摄镜头。\n\n![](Physics/Optical/attachments/Pasted%20image%2020230424113838.png)\n\n### Mustache distortion\n\n**小胡子畸变**😂是枕形失真和桶形失真的组合。 这会导致图像的内部向外弯曲，而图像的外部向内弯曲。 小胡子失真是一种相当罕见的像差，其中不止一种失真模式会影响图像。 小胡子畸变通常是镜头设计非常糟糕的标志，因为这是导致像差融合的光学错误的高潮。\n\n\n## Chromatic （位置色差）\n\n### Longitudinal / axial aberration\n\n光的颜色代表特定波长的光。 由于折射，彩色图像将有多个波长进入镜头并聚焦在不同的点。 纵向或轴向色差是由不同波长聚焦在沿光轴的不同点引起的。 波长越短，其焦点将离镜头越近，而波长越远，则反之，离镜头越远，如图 8 所示。通过引入较小的孔径，进入的光仍可能聚焦在不同的位置 点，但“混淆圈”的宽度（直径）会小得多，导致不那么剧烈的模糊。\n\n![](Physics/Optical/attachments/Fig_8_Chromatic_abberation_animation.gif)\n\n### Transverse / lateral aberration\n\n导致不同波长沿图像平面分布的离轴光是横向或横向色差。 这会导致图像中主体边缘出现彩色边纹。 这比纵向色差更难校正。\n\n![](Physics/Optical/attachments/Fig_9_Chromatic_aberration_lateral.gif)\n\n它可以使用引入不同折射率的消色差双合透镜来固定。 通过将可见光谱的两端置于一个焦点上，可以消除色边。 对于横向和纵向色差，减小光圈的大小也有帮助。 此外，在高对比度环境（即具有非常亮的背景的图像）中不成像目标可能是有益的。 在显微镜中，镜头可能使用复消色差透镜 (APO) 而不是消色差透镜，消色差透镜使用三个透镜元件来校正入射光的所有波长。 当颜色最重要时，确保减轻色差将产生最佳效果。\n\n# Reference\n\n* [SIX OPTICAL ABERRATIONS THAT COULD BE IMPACTING YOUR VISION SYSTEM, https://www.lumenera.com](https://www.lumenera.com/blog/six-optical-aberrations-that-could-be-impacting-your-vision-system)\n* [光学像差重要知识点详解|光学经典理论, 知乎 - 监控李誉](https://zhuanlan.zhihu.com/p/40149006)","lastmodified":"2023-06-10T07:55:32.733172048Z","tags":null},"/Physics/Physics_MOC":{"title":"Physics MOC","content":"\n# Electromagnetism\n\n* [Electromagnetism MOC](Physics/Electromagnetism/Electromagnetism_MOC.md)","lastmodified":"2023-06-10T07:55:32.733172048Z","tags":null},"/Physics/Wave/Doppler_Effect":{"title":"Doppler Effect","content":"\n多普勒效应（**Doppler effect**）是波源和观察者有相对运动时，观察者接受到波的频率与波源发出的频率并不相同的现象。\n\n远方急驶过来的火车鸣笛声变得尖细（即频率变高，波长变短），而离我们而去的火车鸣笛声变得低沉（即频率变低，波长变长），就是多普勒效应的现象，同样现象也发生在汽车鸣响与火车的敲钟声。\n\n# General\n\n在classical physics中，source的speed和receiver的speed远小于wave在medium中的移动速度，observed frequency $f$和emitted frequency$f_0$关系：\n\n$$\nf = (\\frac{c \\pm v_r}{c \\pm v_s})f_0\n$$\n* $c$是wave在介质中的速度\n* $v_r$是receiver相对于介质的速度，如果receiver向source移动，则分子为加号，反之为减号\n* $v_s$是source相对于介质的速度，如果source远离receiver，则分母为加号，反之为减号\n\n\u003e [!note] \n\u003e  请注意，此关系预测如果源或接收器中的任何一个远离另一个，频率将会降低。\n\n$$\n\\frac{f}{v_{wr}} = \\frac{f_0}{v_{ws}} = \\frac{1}{\\lambda}\n$$\n* $v_{\\omega r}$是wave speed相对于receiver\n* $v_{\\omega s}$是wave speed相对于source\n* $\\lambda$是波长\n\n## Example\n\n![](Physics/Wave/attachments/Dopplereffectsourcemovingrightatmach0.7.gif)\n\n其中$v_s = 0.7c$，波前开始在源的右侧（前面）聚集，并在源的左侧（后面）进一步分开。\n\n在前面的receiver会听到higher frequency，也就是$f = \\frac{c}{c-0.7c}f_0 = 3.33f_0$；后面的receiver会听到lower frequency，也就是$f = \\frac{c}{c + 0.7c}f_0 = 0.59f_0$\n\n\n\n\n# Reference\n\n*  [多普勒效应 - Wiki](https://zh.wikipedia.org/wiki/%E5%A4%9A%E6%99%AE%E5%8B%92%E6%95%88%E5%BA%94)","lastmodified":"2023-06-10T07:55:32.733172048Z","tags":null},"/Report/2023.04.16-%E5%A4%A9%E7%BA%BF%E6%B5%8B%E8%AF%95":{"title":"2023.04.16 天线测试","content":"\n 对天线进行测距能力的测试\n\n# 背景\n\n![](Report/attachments/96251ac46494ab01294e570e352c426.png)\n\n# 测试结果\n\n## 无穷远距离测量\n\n前方30cm内无反射，超出本雷达测距能力极限，近似为无穷远距离内无反射，得到收集端电压\n\n![](Report/attachments/7983094eb03d1dcc285edf9c1768018.png)\n\n以前的天线收集的数据：\n\n![](Report/attachments/f5d557933b15f8ea7f6861f70663d13.png)\n\n问题在于两点：\n\n* 目前天线稳定性不足\n* 核心信号峰值下降为1.7v左右，而之前核心信号为2.2v\n\n## 实时测距实验\n\n*实时测距实验为在天线段实时测量信号并在前面按照时间放置金属挡板检测天线的测距能力。*\n\n实验大致的放置时间为：\n1. 0-25s，不放置金属挡板\n2. 25-50s，金属挡板贴紧天线\n3. 50-75s，不放置金属挡板\n4. 75-100s，在10cm处放置金属挡板\n5. 100-125s，不放置金属挡板\n6. 125-150s，在20cm处放置金属挡板\n7. 175-200s，不放置金属挡板\n8. 150-175s，在30cm处放置金属挡板\n\n新天线收集数据：\n\n![](Report/attachments/abaec3368e16f2c9be67b5edbba39be.png)\n\n旧天线收集信号：\n\n![](Report/attachments/ac4c5aa53392835d3db04a78e73476b.png)\n\n问题在于：\n\n* 新天线信号不稳定，与无穷远测试中的结果吻合。\n* 导致了不同距离的信号区分度丧失\n","lastmodified":"2023-06-10T07:55:32.737172106Z","tags":null},"/Signal-Processing/Basic-Concepts-in-Signal-Processing":{"title":"Basic Concepts in Signal Processing","content":"\n* [What is dB](Signal%20Processing/What%20is%20dB.md)","lastmodified":"2023-06-10T07:55:32.741172165Z","tags":null},"/Signal-Processing/Signal-Processing_MOC":{"title":"Signal Processing - MOC","content":"\n* [Basic Concepts in Signal Processing](Signal%20Processing/Basic%20Concepts%20in%20Signal%20Processing.md)\n","lastmodified":"2023-06-10T07:55:32.741172165Z","tags":null},"/Signal-Processing/What-is-dB":{"title":"What is dB","content":"dB is short for decibel, which is a unit that indicates ratio or gain. It is often used to measure *sound intensity*, *signal strength*, *attenuation* and other quantities. \n\nFor example, if a sound has a power of 10 W and another sound has a power of 1 W, then the difference in decibels is 10 dB = 10 log (10/1) = 10 log 10 = 10.\n\n**Signal Noise Ratio** is also measured by dB\n\n## Signal Noise Ratio\n$$\n{SNR}_{power}=\\frac{\\text{Average Signal Power}}{\\text{Average Noise Power}}\n$$\n\n$$\n{SNR}_{voltage}=\\frac{\\text{RMS Signal Voltage}}{\\text{RMS Noise Voltage}}\n$$\n\n$$\n{SNR}_{power}={{SNR}_{voltage}}^2\n$$\n\n$$\n{SNR}_{dB}=10\\log_{10}{{SNR}_{power}}=20\\log_{10}{{SNR}_{voltage}}\n$$\n","lastmodified":"2023-06-10T07:55:32.741172165Z","tags":null},"/Synthetic-Aperture-Radar-Imaging/Antenna":{"title":"Antenna","content":"\n# Theorem you need know\n\n* [🧷Resonant circuit](Physics/Electromagnetism/Resonant_circuit.md)\n\n# What is antenna\n\nA usually metallic device for radiating or receiving radio waves\n\n## A simple model representing antenna\n\n![](Synthetic%20Aperture%20Radar%20Imaging/attachments/Pasted%20image%2020230404163712.png)\n\n* $R_L$ 损耗电阻 - 介质与结构导致的损耗\n* $R_r$ 辐射电阻 - 与天线产生的辐射的能量关系密切\n* $X_A$ 电抗 - 描述天线近场电磁能转换的现象 (一般情况下$X_A$ = 0)\n\n\u003e [!warning] \n\u003e 天线还有一个很重要的损耗来源，**mismatch loss**, 天线跟前端的阻抗不匹配，导致能量打不进天线，这点可以通过设计和材质来解决 \n\n# Types of antennas\n\n## Wire antennas\n\n![](Synthetic%20Aperture%20Radar%20Imaging/attachments/Pasted%20image%2020230404165239.png)\n\n## Aperture antennas\n\n![](Synthetic%20Aperture%20Radar%20Imaging/attachments/Pasted%20image%2020230410105310.png)\n\n## Microstrip antennas\n\n![](Synthetic%20Aperture%20Radar%20Imaging/attachments/Pasted%20image%2020230410105548.png)\n\n## Array antennas\n\n![](Synthetic%20Aperture%20Radar%20Imaging/attachments/Pasted%20image%2020230410111719.png)\n\n\u003e [!hint] \n\u003e 天线的目的简单来说，就是为了将能量尽可能辐射出去，同时按照你希望的方向和区间辐射。\n\n## Reflector antennas \u0026 Lens antennas\n\n![](Synthetic%20Aperture%20Radar%20Imaging/attachments/Pasted%20image%2020230410112252.png)\n\n\n# Radiation mechanism\n\n## Ideal antenna\n\nRadiate all the power delivered to it from the transmitter in a desired direction or directions.\n\n## How is radiation accomplished?\n\n* How are EM fields generated by the source?\n* How are EM fields contained and guided within the transmission line \u0026 antenna?\n* How are EM fields finally detached from the antenna to form a free-space wave?\n\n### How are EM fields generated by the source?\n \n![](Synthetic%20Aperture%20Radar%20Imaging/attachments/Pasted%20image%2020230410113039.png)\n\n* $q_v$电荷密度，$C/m^3$\n* $v_Z$电荷移动速度，$m/s$\n* $J_Z$电流密度，$A/m^2$\n$$\nA/m^2 = C/m^3 * m/s = \\frac{C}{m^2 * s}\n$$\n\n导线由PEC所做时，或者高频情况，电流变成面电流\n* $J_S$变成面电流密度，$A/m^2$\n* $q_S$也变成面电荷密度，$C/m^2$\n\n但wire非常thin，当然面最终被认为为线\n\n$$\nI_Z = q_l v_Z\n$$\n我们用thin wire case来讨论\n\n对这个式子做时间微分\n$$\n\\frac{dI_z}{dt} = q_l\\frac{v_Z}{dt}=q_l a_z\n$$\n$$\nl\\frac{dI_Z}{dt}=lq_la_Z=Qa_z\n$$\n\u003e [!hint] \n\u003e To create radiation, there must be **a time-varying current** or **an acceleration (or deceleration) of charge** \n\u003e \n\u003e -\u003e The wire must be curved, bent, discontinuous, terminated, or truncated\n\n###  How are EM fields contained and guided within the transmission line \u0026 antenna?\n\n![](Synthetic%20Aperture%20Radar%20Imaging/attachments/Pasted%20image%2020230411105457.png)\n\nradiation要考虑两个方面，一方面激发电场那边提供的电子的加速，另一方面时end部分的pause造成的电子的减速，这两边会有最主要的辐射；\n\n如果加速和减速之间的距离很短，形成一个pulse，会发出一个很宽频的信号；\n\n如果加减速达到间歇运动状态，会发出一个单频的辐射\n\n\u003e [!hint] \n\u003e 用水波去理解辐射\n\u003e \n\u003e 在池塘里要产生水波，你可以丟一颗石头\n\u003e \n\u003e Source可以产生pulse或者弦波，引起电磁振荡，induce电荷做加减速，产生时变电流，在导线里产生导波，也就是在传输线中引导的电磁波，电磁波最后会走到天线端，被辐射出去；\n\u003e \n\u003e pulse就像你丢了一颗石头下去，弦波就像你按照周期去丢\n \n\u003e [!hint] \n\u003e 根据[Maxwell's equations](Physics/Electromagnetism/Maxwells_equation.md)\n\u003e \n\u003e 当电磁波在导线中存在的时候，它是需要时变的电流或者说是加减速的电荷来support。在传输线里，需要source才能有场；\n\u003e \n\u003e 但是在解[Maxwell's equations](Physics/Electromagnetism/Maxwells_equation.md)的时候，是有一组homogeneous的解，这组解指的是，你不需要source的存在的场，这个场指的是free-space wave；\n\u003e \n\u003e 所以，天线本质上就是一个interface，将导线内需要source的场，变成不需要source的场，也就是free-space wave\n\n### How are EM fields finally detached from the antenna to form a free-space wave?\n\n# Radar key Parameters\n\n\n\n# Reference\n\n* [知乎 - 天线与电波传播基础知识](https://zhuanlan.zhihu.com/p/497482699)\n* [天线 in wiki](https://zh.wikipedia.org/wiki/%E5%A4%A9%E7%BA%BF)\n* [⭐⭐⭐陈士元 - 天线原理与基本参数](https://www.youtube.com/watch?v=JsVGW3z81wc\u0026list=PLQdXflQNtKfLaGnvPLW_XVal-RaHxFN5j\u0026index=1)\n* [天线8个核心参数解析 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/375911768)","lastmodified":"2023-06-10T07:55:32.741172165Z","tags":null},"/Synthetic-Aperture-Radar-Imaging/Chirp":{"title":"Chirp - 啁啾","content":"\n啁啾（Chirp）是指频率随时间而改变（增加或减少）的信号。其名称来源于这种信号听起来类似鸟鸣的啾声。\n\n![](Synthetic%20Aperture%20Radar%20Imaging/attachments/Linear-chirp.svg)\n\nChirp常常被用在sonar, radar, laser systems里。其中，为了能够测量长距离又保留时间的分辨率，雷达需要短时间的派冲波但是又要持续的发射信号，啁啾信号可以同时保留连续信号和脉冲的特性，因此被应用在雷达和声纳探测上。\n\n# Definition\n\n## 瞬时频率 (instantaneous angular frequency)\n\n\n有一信号，$x(t)=A\\sin{(\\phi(t))}$，其瞬时角频率为\n$$\n\\omega(t)=\\frac{d\\phi(t)}{dt}\n$$\n经适当归一化后得到瞬时频率\n$$\nf(t)=\\frac{1}{2\\pi}\\frac{d\\phi(t)}{dt}\n$$\n\n## 啁啾度\n\n对前两式再求导，得到瞬时角频率的变化速率为**瞬时角啁啾度**(instantaneous angular chirpyness)\n\n$$\n\\gamma(t)=\\frac{d^2\\phi(t)}{dt^2}\n$$\n类似有**瞬时（普通）啁啾度**(instantaneous ordinary chirpyness)\n\n$$\nc(t)=\\frac{1}{2\\pi}\\gamma(t)=\\frac{1}{2\\pi}\\frac{d^2\\phi(t)}{dt^2}\n$$\n# Types\n\n## Linear\n\n![](Synthetic%20Aperture%20Radar%20Imaging/attachments/Pasted%20image%2020230418110700.png)\n\n啁啾的瞬时频率$f(t)$呈线性变化\n\n$$f(t)=f_0 + ct$$\n$$\nc = \\frac{f_1-f_0}{T}\n$$\n\nc是一个常值\n\nAlso，\n\n$$\n\\phi(t)=\\phi_0 + 2\\pi \\int_{0}^t f(\\tau)d\\tau =\\phi_0 = 2\\pi(\\frac{c}{2}t^2 + f_0 t)\n$$\n\n相位为t的二次函数，从而可以继续推导出信号在time domain：\n\n$$\nx(t)=A \\cos{(\\phi_0 + 2\\pi (\\frac{c}{2}t^2 + f_0 t))}\n$$\n\n这种Linear Chirp信号也被称为二次相位讯号(**quadratic-phase signal**)\n\n## Exponential\n\n![](Synthetic%20Aperture%20Radar%20Imaging/attachments/Pasted%20image%2020230418111708.png)\n\nExponential chirp，也叫geometric chirp，瞬时频率以指数变化，即$f(t_2)/f(t_1)$会是常数\n\nsignal frequency:\n\n$$\nf(t)=f_0 k^t\n$$\n\n$$\nk = (\\frac{f(T)}{f_0})^{\\frac{1}{T}} = \\text{constant}\n$$\n\n相位:\n\n$$\n\\phi(t)=\\phi_0 + 2\\pi\\int_0^t f(\\tau)d\\tau = \\phi_0 + 2\\pi f_0 (\\frac{k^t - 1}{\\ln(k)})\n$$\n\ntime-domain:\n\n$$\nx(t) = \\sin{[\\phi_0 + 2\\pi f_0(\\frac{k^t - 1}{\\ln(k)})]}\n$$\n\n## Hyperbolic\n\n双曲线线性调频用于雷达应用，因为它们在被多普勒效应([Doppler Effect](Physics/Wave/Doppler_Effect.md))扭曲后显示出最大的匹配滤波器([Matched filter](https://en.wikipedia.org/wiki/Matched_filter))响应。\n\nsignal frequency:\n\n$$\nf(t) = \\frac{f_0 f_1 T}{(f_0 - f_1)t + f_1T}\n$$\n\nPhase:\n\n$$\n\\phi(t) = \\phi_0 + 2\\pi \\int_0^t f(\\tau)d\\tau = \\phi_0 + 2\\pi \\frac{-f_0f_1 T}{f_1 - f_0}\\ln(1 - \\frac{f_1-f_0}{f_1 T}t)\n$$\n\n\ntime-domain:\n\n$$\nx(t) = \\sin{[\\phi_0 + 2\\pi \\frac{-f_0f_1 T}{f_1 - f_0}\\ln(1 - \\frac{f_1-f_0}{f_1 T}t)]}\n$$\n\n","lastmodified":"2023-06-10T07:55:32.741172165Z","tags":null},"/Synthetic-Aperture-Radar-Imaging/Radiometric_Calibration":{"title":"Radiometric Calibration - 辐射校准","content":"\n# Overview\nSAR 校准旨在提供其像素值可与场景中的雷达反向散射直接相关的影像。虽然未校准的 SAR 影像足以用于定性用途，但校准后的 SAR 影像对于定量使用 SAR 数据而言仍至关重要。\n\n生成级别 1 影像的典型 SAR 数据处理不包括辐射校正，且仍然存在明显的辐射偏差。因此有必要对 SAR 影像应用辐射校正，*使影像的像素值真正能够反映反射表面的雷达反向散射情况*。在比较由不同的传感器采集的 SAR 影像时，或比较由同一传感器在不同时间、不同模式下采集的（或由不同处理器处理的）SAR 影像时，都需要进行辐射校正。\n\n## Types\n* **Sigma nought** - 用于校准地面上单位面积内返回到天线的反向散射，并与地面范围相关。影像经过校准，因此可以直接与相同或不同传感器收集的不同雷达影像进行比较。科学家倾向于使用 sigma naught 来解释表面散射、表面反射以及表面属性。\n\t* *Scattering coefficient*, or the conventional measure of the strength of radar signals reflected by a distributed scatterer, usually expressed in dB. It is a *normalised dimensionless number*, comparing the strength observed to that expected from an area of one square meter. Sigma nought is defined with respect to the nominally horizontal plane, and in general has a significant variation with **incidence angle**, **wavelength**, and **polarisation**, as well as with **properties of the scattering surface itself**.\n* **Beta nought** - 可生成包含雷达亮度系数的数据集（雷达亮度系数是天线发射功率与接收功率之比）。它与倾斜范围有关，且无维度。\n* **Gamma** - 通常在校准天线时使用。因为每个范围像元与卫星的距离均相等，所以近距范围和远距范围的亮度均相等，这有助于确定输出数据集中的天线方向图。\n* **None** - 不做校正\n\n\n\n# Reference\n\n* [Sentinel-1 Radiometric Calibration—ArcMap | Documentation (arcgis.com)](https://desktop.arcgis.com/en/arcmap/latest/manage-data/raster-and-images/sentinel-1-radiometric-calibration.htm)\n\n* [Urban objects detection from C-band synthetic aperture radar (SAR) satellite images through simulating filter properties | Scientific Reports (nature.com)](https://www.nature.com/articles/s41598-021-85121-9)\n\n* [✨✨✨User Guides - Sentinel-1 SAR - Definitions - Sentinel Online - Sentinel Online (esa.int)](https://sentinel.esa.int/web/sentinel/user-guides/sentinel-1-sar/definitions)\n\n","lastmodified":"2023-06-10T07:55:32.741172165Z","tags":null},"/Synthetic-Aperture-Radar-Imaging/SAR_Explained":{"title":"Synthetic Aperture Radar (SAR) Explained","content":"\n# Radar Basic Concepts\n\n## Down Looking vs. Side Looking\n\n![Pasted image 20230320150424](Synthetic%20Aperture%20Radar%20Imaging/attachments/Pasted%20image%2020230320150424.png)\n\nDown Looking不能区分距离一样的a，b点，一般只用于monitoring of air and naval traffic\n\n## Simplified explanation of Radar working \u0026 What is SAR\nThe radar consists fundamentally of *a transmitter*, *a receiver*, *an antenna* and *an electronic system* to process and record the data.\n\nThe transmitter generates successive short bursts or pulses of microwave at regular intervals which are focused by the antenna into a beam. Radar beam illuminates the surface **obliquely** at a right angle to the motion of the platform. The antenna receives a portion of the transmitted energy reflected or it's known as backscattered from various objects within the illuminated beam by  measuring this time delay between the transmission of a pulse and the reception of the backscattered echo from different  targets. Their distance from the radar and therefore their location can be determined as the sensor platform *moves forward* recording and processing of the backscattered signals builds up a 2-dimensional image of the surface.\n\n\n\u003e [!important] \n\u003e Important\u003cbr\u003e\n\u003e The along track **resolution** is determined by the beam width which is *inversely proportional to the antenna length*, also known as the **aperture**, which means that longer antenna or a longer aperture will produce a narrow beam and a finer resolution. \u003cbr\u003e\n\u003e Long antenna $\\leftrightarrow$ Small beam $\\leftrightarrow$ Long aperture $\\leftrightarrow$ Better image resolution\n\n\n\n### Why SAR\n介于实际情况下的物理空间中，雷达天线的大小是限的，可以通过雷达的移动去模拟长天线情况下的雷达，也就是活得更大的aperture，这项被叫做SAR。目的是在于使用*comparatively small physical antennas*去获得*high resolution images*\n\n--- \n\n![660](Synthetic%20Aperture%20Radar%20Imaging/attachments/Pasted%20image%2020230320163240.png)\n\n* Radar can measure *amplitude* and *phase*\n* Radar can only measure part of echoes.\n* The strength of the reflected echo is the backscattering coefficient ([sigma nought](Synthetic%20Aperture%20Radar%20Imaging/Radiometric_Calibration.md)）and is expressed in [decibels(dB)](Signal%20Processing/What%20is%20dB.md)\n\n## Radar Resolution\n\n### Detail geometry\n\n![](Synthetic%20Aperture%20Radar%20Imaging/attachments/Pasted%20image%2020230330153450.png)\n\u003cfont size=1\u003e**Fig** *Geometry of a side-looking real aperture radar. (SLAR)*\u003c/font\u003e\n\nside-looking的雷达被分为two types —— real aperture radar(*SLAR or SLR*, SL for side-looking)和synthetic aperture radar(SAR)\n\n如上图所示，雷达发出的pulse被[antenna聚焦](Synthetic%20Aperture%20Radar%20Imaging/Antenna.md)在一个narrow的area里，然后scatter后在不同和的时间再被receiver接收\n\n### Resolution\n\n当我们谈SAR的分辨率时，我们要知道有四种operating modes对于SAR而言。\n\n![](Synthetic%20Aperture%20Radar%20Imaging/attachments/Pasted%20image%2020230418103211.png)\n\n* Stripmap SAR\n* Spotlight SAR\n* Circular SAR\n* Scan SAR\n\n其中Stripmap SAR, Spotlight SAR,  Circular SAR这三种最为常用\n\n![](Synthetic%20Aperture%20Radar%20Imaging/attachments/Pasted%20image%2020230414105501.png)\n\nStripmap SAR是将antenna固定在platform，以straight line方式移动并连续接发pulse，它的优势是可以cover large area。\n\n![](Synthetic%20Aperture%20Radar%20Imaging/attachments/Pasted%20image%2020230414105703.png)\n\nSpotlight SAR天线不断移动以照射同一区域，它的特点是high-resolution image，因为它从不同的角度收集同一区域的data\n\n![](Synthetic%20Aperture%20Radar%20Imaging/attachments/Pasted%20image%2020230414110025.png)\n\nCircular SAR通过circular trajectory窥探同一片area，它跟spotlight SAR很像，区别在于Spotlight mode里antenna是不动的，只有平台在移动，而在circular mode里，antenna也在移动，来收集$360^\\circ$信息，circular SAR的分辨率计算时，认为反射是$360^\\circ$各向同性反射，所以是理论分辨率。\n\n我在UWB radar探测烧伤的技术中将采用Spotlight SAR\n\n\n#### Range Resolution \u0026 Azimuth Resolution\n\n![](Synthetic%20Aperture%20Radar%20Imaging/attachments/Pasted%20image%2020230414111329.png)\n\n这是一张可以快速check概念的图\n\nTable. *Range and azimuth resolution*\n|               | Range Resolution                             | Azimuth Resolution                                     |\n| ------------- | -------------------------------------------- | ------------------------------------------------------ |\n| Stripmap SAR  | $\\Delta_r = \\frac{c\\pi}{2\\omega_0}$          | $\\Delta_a = \\frac{D_y}{2}$                             |\n| Spotlight SAR | $\\Delta_r = \\frac{c\\pi}{2\\omega_0}$          | $\\Delta_a=\\frac{r_n\\lambda_c}{4L \\cos \\theta_n(0)}$    |\n| Circular SAR  | $\\Delta_r = \\frac{\\pi}{\\rho_max - \\rho_min}$ | $\\Delta_a=\\frac{\\pi}{2k_c \\cos{\\theta_z}\\sin{\\phi_0}}$ |\n\n* $\\omega_0$ radar signal half-bandwidth in radians\n* $D_y$ the diameter of the radar in azimuth domain\n* $r_n$ the target radical distance from the center of aperture\n* $\\lambda_c = \\frac{2c\\pi}{\\omega_c}$ the wavelength at carrier fast-time frequency\n* $\\omega_c$ the central frequency\n* $L$ half-size of the aperture\n* $\\theta_n(0)$ the aspect angle of the $n$th target when radar is at (0, 0)\n* $\\rho_{max}$ and $\\rho_{min}$ the maximum and minimum polar radius in spatial frequency domain for the support of a target at the center of the spotlight area\n* $k_c$ the wavenumber at carrier frequency\n* $\\theta_z$ the average depression angle of the target area\n* $\\phi_0$ the polar angle in spatial frequency domain \n\n## Radar Image Format\n\n![](Synthetic%20Aperture%20Radar%20Imaging/attachments/Pasted%20image%2020230509140819.png)\n\n## Radar Key Parameters\n* Wave Length\n* Polarization\n* Incidence Angle\n\n### Wave Length\n\n![](Synthetic%20Aperture%20Radar%20Imaging/attachments/Pasted%20image%2020230330153007.png)\n\n雷达数据的空间分辨率与传感器波长与传感器天线长度之比直接相关。 对于给定的波长，天线越长，空间分辨率越高。 对于以大约 5 cm 波长运行的太空卫星（C 波段雷达），为了获得 10 m 的空间分辨率，您需要一个大约 4,250 m 长的雷达天线。 （超过 47 个足球场！）\n\n\n\n# Reference\n\n* [Theory of Synthetic Aperture Radar (uzh.ch)](https://www.geo.uzh.ch/~fpaul/sar_theory.html)\n* ***Sentinel-1** is a famous SAR, you can find almost every definitions* of SAR in this page:\n[User Guides - Sentinel-1 SAR - Definitions - Sentinel Online - Sentinel Online (esa.int)](https://sentinel.esa.int/web/sentinel/user-guides/sentinel-1-sar/definitions)\n* [SAR(Synthetic Aperture Radar)基础(一) - 知乎 (评论区说这个有错)](https://zhuanlan.zhihu.com/p/98053986)\n* [A Review of Synthetic-Aperture Radar Image Formation Algorithms and Implementations: A Computational Perspective]([Remote Sensing | Free Full-Text | A Review of Synthetic-Aperture Radar Image Formation Algorithms and Implementations: A Computational Perspective (mdpi.com)](https://www.mdpi.com/2072-4292/14/5/1258))\n","lastmodified":"2023-06-10T07:55:32.741172165Z","tags":null},"/Synthetic-Aperture-Radar-Imaging/SAR_Imaging_Algorithm":{"title":"SAR Imaging Algorithm review in 2022","content":"\n\n# Overview\n\n* Backprojection\n* Matched-filter\n* Polar format\n* Range-Doppler\n* Chirp scaling algorithms\n\n\n# What is SAR processing?\n\n\n## Born approximation\n\nSAR 处理算法将场景建模为一组离散的点目标，其分散的 EM 场不会相互影响。\n\n* 无多次反弹\n* 目标处的电场仅来自入射波，而不来自周围的散射体\n* 目标模型是线性的，因为点目标 P1 和点目标 P2 的散射响应被建模为点目标 P1 本身的响应 + 点目标 P2 本身的响应\n* 可以应用**叠加原理(principle of superposition)**\n\n\u003c!--SAR 处理是对图像中每个像素应用匹配滤波器，其中匹配滤波器系数是来自单个孤立点目标的响应\n\n* SAR processing is a correlation filter between a single isolated point target response and the raw data\n* SAR processing is an inner product between our model of a single isolated point target and the raw data\n--\u003e\n\n## 信号建模\n\n\nSAR成像是对一个区域的散射特性进行成像，这个区域的地形一般比较复杂，区域内不同位置处的物体散射特性各不相同，最后SAR接收的是探测区域内所有物体后向散射信号的叠加，整个探测区域散射的回波信号模型非常复杂。直接构造整个探测区域的散射信号模型十分困难，也没有必要。为了简化信号模型，信号模型的建立运用了两个离散化：\n\n* 探测区域的离散化；\n* 平台飞行的离散化;\n\n### 探测区域离散化\n\n**将探测区域认为是若干散射点的集合**，由此对区域回波信号模型的建立转化为对这些散射点回波信号模型的建立。这样只需构建任意散射点的回波信号模型即可表示整个探测区域的回波信号模型。该离散化的准则是：离散间隔内的物体散射特性基本不变。\n\n### 平台飞行离散化\n\n**将平台的飞行过程认为是一个“走停”模式**，即在一个脉冲时间（脉冲重复周期）内，平台是“停”（静止）的状态，平台发射一个脉冲信号，并在该位置处接收该脉冲照射目标的回波信号；在下一个脉冲时间内，平台“走”（瞬移）到另一个位置（按照原来匀速运动应该走到的位置处），并在下一个位置重复上一个脉冲时间内平台的操作。该离散化的准则是：电磁波传播速度远大于平台速度，即SAR一次发射、接收过程中，雷达的位置基本不变。\n\n--- \n\n![](Synthetic%20Aperture%20Radar%20Imaging/attachments/Pasted%20image%2020230419111635.png)\n\n![](Synthetic%20Aperture%20Radar%20Imaging/attachments/Pasted%20image%2020230418165114.png)\n\n如图，针对红点目标，SAR从A点开始照射到P点最接近目标，直到B点离开红点离开。\n\n假设平台$t$时刻飞行到红点位置，雷达发射脉冲信号$s(\\tau)$，此时接收的回波信号信息为：\n\n\n$$\nr(\\tau,t) = \\sigma(R_0, A_0) s(\\tau - \\frac{2R(t)}{c})\\omega_a(\\frac{t - t_p}{T_{syn}})\n$$\n\n\n* $\\sigma(R_0, A_0)$表示$(R_0, A_0)$处目标的散射面积\n* $T_{syn}$表示合成孔径的时长\n* $\\omega_a(\\cdot)$理想情况可以认为是矩性窗，实际上是由实孔径天线的方向图构成；考虑到信号往返，$\\omega_a(\\cdot)$函数为天线方向图的平方。\n\n同时，有：\n\n$$\nR(t) = \\sqrt{R_0^2 + v^2(t-t_p)^2}\n$$\n\n从图示不难发现，与红点目标相比，距离向等距的黑点目标多普勒历程一致，只是对应的方位向时延不一样，反映在表达式上，即距离目标最短的时刻$t_p$不同。对接收的回波信号进一步化简可得：\n\n$$\nr(\\tau, t) = \\{s(\\tau)w_a(\\frac{t}{T_{syn}})\\} \\bigotimes h(\\tau, t)\n$$\n\n$$\nh(\\tau, t) = \\sigma(R_0, A_0)\\delta(\\tau-\\frac{2R(t)}{c}, t-t_p)\n$$\n\n将SAR（信号发射到接收的过程）看成一个系统，$h(\\tau, t)$为对应的系统函数，系统函数包含目标位置处散射面积$\\sigma(R_0, A_0)$和重建函数$\\delta(\\tau-\\frac{2R(t)}{c}, t-t_p)$。\n\nSAR成像问题等效为：根据发射信号从回波信号中反卷积出系统函数$h(\\tau, t)$\n\n同时，系统函数$h(\\tau, t)$中的重建函数$\\delta(\\tau-\\frac{2R(t)}{c}, t-t_p)$的快时间维存在慢时间维的耦合项，为此SAR成像算法一个关键的步骤是去除这个耦合项，称为距离徙动校正，将重建函数矫正为$\\delta(\\tau-\\frac{2R}{c}, t-t_p)$，这时候可以分别对快时间维$\\tau$和慢时间维$t$的信号做脉冲压缩处理，得到SAR图像\n\n上述是SAR回波信号模型的建立过程以及对所得回波信号模型的简单分析，在建立信号模型的过程中，运用了雷达领域经常用到了两个概念，*慢时间是对脉冲间时间的标记*，即慢时间表示发射的是第几个脉冲信号，所以慢时间本身是离散的，离散间隔为脉冲重复周期；*快时间是对脉冲内时间的标记*，即快时间显示的是任意一个脉冲内的时刻，相比慢时间，快时间是连续的，需要通过信号的采样来离散。\n\n\n### 信号模型的四域表示\n\n\n\n# Range-Doppler Algorithm (RDA)\n\nRange-Doppler Algorithm是SAR成像的第一个算法，在1970年代被developed出来，用来生成stripmap的SAR。Range-Doppler Algorithm利用block-processing处理，在距离和方位角中使用频域运算。\n\n步骤如下：\n\n![](Synthetic%20Aperture%20Radar%20Imaging/attachments/Pasted%20image%2020230417110036.png)\n\n## Range Compression\n\n![](Synthetic%20Aperture%20Radar%20Imaging/attachments/Pasted%20image%2020230418102226.png)\n\n距离参考函数是一系列复数，表示天线发射的原始啁啾信号(original [chirp](Synthetic%20Aperture%20Radar%20Imaging/Chirp.md))。\n\n天线发射的原始线性调频信号（**linear-frequency chirp**）是一种线性调频连续波信号，它的频率随着时间线性变化，形成一种锯齿状的波形。这种信号可以用数学公式表示为：\n\n$$ s(t) = \\cos\\left(2\\pi\\left(f_c t + \\frac{B}{T} t^2\\right)\\right) $$\n\n其中，$f_c$是信号的中心频率，$B$是信号的带宽，$T$是信号的持续时间。这种信号可以用一个本地振荡器（LO）来生成，然后通过一个功率放大器来放大，并从天线发射出去。\n\n## Azimuth Compression\n\n![](Synthetic%20Aperture%20Radar%20Imaging/attachments/Pasted%20image%2020230418162216.png)\n\n\n\n# Reference\n\n* [A Review of Synthetic-Aperture Radar Image Formation Algorithms and Implementations: A Computational Perspective]([Remote Sensing | Free Full-Text | A Review of Synthetic-Aperture Radar Image Formation Algorithms and Implementations: A Computational Perspective (mdpi.com)](https://www.mdpi.com/2072-4292/14/5/1258))\n* [Range Doppler Algorithm - University of Kansas](https://people.eecs.ku.edu/~callen58/826/826_SAR_Processing_Algorithms_Overview-F15.pptx)\n* [距离多普勒算法（RDA）-SAR成像算法系列（三）-【杨（_\u003e \u003c_)】的博客-CSDN博客 🚧这个人的博客讲的真不错🚧](https://blog.csdn.net/yjh_2019/article/details/123772486?spm=1001.2014.3001.5502)\n\n","lastmodified":"2023-06-10T07:55:32.741172165Z","tags":null},"/Synthetic-Aperture-Radar-Imaging/SAR_MOC":{"title":"Synthetic Aperture Radar (SAR) Imaging - MOC","content":"\n\n# Antenna\n\n* [Antenna](Synthetic%20Aperture%20Radar%20Imaging/Antenna.md)\n\n# SAR\n\n* [[Synthetic Aperture Radar Imaging/SAR_Explained|SAR Explained]]\n* [SAR Imaging Algorithm review in 2022](Synthetic%20Aperture%20Radar%20Imaging/SAR_Imaging_Algorithm.md)","lastmodified":"2023-06-10T07:55:32.741172165Z","tags":null},"/assets/pdf/NUS_Transcript.pdf":{"title":"NUS_Transcript.pdf","content":"","lastmodified":"2023-06-10T07:55:32.777172689Z","tags":null},"/coding_knowledge/python/matplotlib_backend":{"title":"Matplotlib Backend Review","content":"\n","lastmodified":"2023-06-10T07:55:32.777172689Z","tags":null},"/resume":{"title":"Resume","content":"\n\u003cdiv style=\"margin:auto;width: 50%; transform: translate(50%, 0);\"\u003e\n\u003ctr\u003e\n            \u003ctd style=\"text-align:\n                center;\"\u003e\u003cimg src=\"https://github.com/PinkR1ver/ImageHosting/blob/main/Pfp/Maoqiu_Child.png?raw=true\"\n                    role=\"presentation\" width=\"114\" \n                    style=\"display: inline-block; max-width: 180px; border-radius: 25px;text-align: center;\"\u003e\n                \u003ch2 color=\"#000000\"  style=\"margin: 0px; font-size: 20px; color: #3A4E48; font-weight: 1000;\"\u003e\u003cspan\u003eJude\u003c/span\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003cspan\u003eWang\u003c/span\u003e\u003c/h2\u003e\n        \u003c/tr\u003e\n\u003c/div\u003e\n\n# 📐 Education\n\n**Zhejiang University (ZJU)**,\u0026nbsp;\u0026nbsp;Zhejiang,\u0026nbsp;\u0026nbsp;China \u003cspan style=\"float: right; \"\u003e2022.09 - Now\u003c/span\u003e \u003cbr\u003e\n*M.Sc.* Major in Biomedical Engineering (BME)\n\n**Exchange to National University of Singapore (NUS)**  \u003cspan style=\"float: right; \"\u003e2021.08-2022.05\u003c/span\u003e \u003cbr\u003e\n*Final Year Project* \u0026nbsp;instructed by [Dan wu](https://person.zju.edu.cn/en/danwu) and [Zhiwei Huang](https://cde.nus.edu.sg/bme/staff/dr-huang-zhiwei/)\n\n**Zhejiang University**, \u0026nbsp;\u0026nbsp;Zhejiang, China \u003cspan style=\"float: right; \"\u003e2018.08-2022.06\u003c/span\u003e\u003cbr\u003e\n*B.S.* Major in Biomedical Engineering (BME), *The first Lv Weixue laboratory class in ZJU*\u003cbr\u003e\n*B.S.* Minor in *Intensive Training Program of Innovation and Entrepreneurship (ITP)*\n\n**Summer exchange to City University of HongKong (CityU)** \u003cspan style=\"float: right; \"\u003eAug. 2019\u003c/span\u003e\n\n# 🔥 Projects \u0026 Research Experience\n\n**Master's thesis**, SAR image reconstruction to detect burn skin based on UWB echo signal \u003cspan style=\"float: right; \"\u003e2022 - now\u003c/span\u003e \u003cbr\u003e\nFor now, my master's research direction is about echo signal processing. Ultra-wide band(UWB) signal has a good ability to across skin surface to get information under skin. We want use UWB signal's feature to detect skin burn level in non-invasive way. This project involves *back projection(BP)* algorithm to reconstruct 3D image from echo signal, image artifact removal based on amplitude coherence factor(ACF) and correlation weighted(CW), burn level evaluation method and so on. \nhttps://github.com/PinkR1ver/UWB-Imagination-Using-SAR\n\n**FYP**, Radiogenomics Analysis of Glioblastoma with Deep learning Techniques \u003cspan style=\"float: right; \"\u003e2021-2022\u003c/span\u003e \u003cbr\u003e\nI finish this FYP instructed by [Zhiwei Huang](https://cde.nus.edu.sg/bme/staff/dr-huang-zhiwei/) in NUS. This project contains three part. MRI image segmentation by *U-Net*, radiomics features extraction by *pyradiomics*, and feature vector classification by machine learning such as *random forest*, *MLP*, *SVM* and so on. [https://github.com/PinkR1ver/Radiogenemics--on-Ivy-Gap](https://github.com/PinkR1ver/Radiogenemics--on-Ivy-Gap)\n\n**SRTP**, 3D tooth segmentation based on deep learning \u003cspan style=\"float: right; \"\u003e2020-2021\u003c/span\u003e \u003cbr\u003e \nThis project targets at instance segmentation given images on teeth . We have implemented a semantic segmentation to detect teeth and gingiva using PointNet, and then utilize bounding boxes to do instance segmentation on every single teeth using 3D-BoNet.\n\n**Smooth Boy** \u003cspan style=\"float: right; \"\u003eAug. 2020\u003c/span\u003e \u003cbr\u003e\nSmooth Boy is a WeChat app that can evaluate a person’s skin quality and recommend skin care products and it was especially developed for young male teenage who purchase for beauty. It was a real self-learning project as well. In this project I design the UI and code the core part of the app to achieve the function of detecting the person’s face. [https://github.com/PinkR1ver/Smooth-Boy](https://github.com/PinkR1ver/Smooth-Boy)\n\n\n**Sketchpad** \u003cspan style=\"float: right; \"\u003eApr – Jun. 2019\u003c/span\u003e \u003cbr\u003e\nIt was my first class project in college. It was a simple program based on an old graphics library which created in 1995, can draw image of polynomial function. In this project, I built the whole structure of the code and organize my team to code different part to make it done. It was really exciting to stay up all night to code and when it was finished, I almost cried that time. [https://github.com/PinkR1ver/SketchPad](https://github.com/PinkR1ver/SketchPad)\n\n\n# 🤹🏽Skills \u0026 Knowledge\n\n## Proficient\n\u003cbr\u003e\n\u003cdiv style=\"display: flex; white-space:nowrap; overflow:auto; padding: 15px\"\u003e\n\t\u003cimg align=\"left\" alt=\"python\" height=\"35px\" style=\"margin:0px 4px\" src=\"https://github.com/PinkR1ver/Jude.W-s-Knowledge-Brain/blob/master/warehouse/img/skills/python.png?raw=true\" /\u003e\n\t\u003cimg align=\"left\" alt=\"matlab\" height=\"35px\" style=\"margin:0px 4px\" src=\"https://github.com/PinkR1ver/Jude.W-s-Knowledge-Brain/blob/master/warehouse/img/skills/matlab.png?raw=true\" /\u003e\n\t\u003cimg align=\"left\" alt=\"numpy\" height=\"35px\" style=\"margin:0px 4px\" src=\"https://github.com/PinkR1ver/Jude.W-s-Knowledge-Brain/blob/master/warehouse/img/skills/numpy.png?raw=true\" /\u003e\n\t\u003cimg align=\"left\" alt=\"pandas\" height=\"35px\" style=\"margin:0px 4px\" src=\"https://github.com/PinkR1ver/Jude.W-s-Knowledge-Brain/blob/master/warehouse/img/skills/pandas.png?raw=true\" /\u003e\n\t\u003cimg align=\"left\" alt=\"pytorch\" height=\"35px\" style=\"margin:0px 4px\" src=\"https://github.com/PinkR1ver/Jude.W-s-Knowledge-Brain/blob/master/warehouse/img/skills/pytorch.png?raw=true\" /\u003e\n\t\u003cimg align=\"left\" alt=\"anaconda\" height=\"35px\" style=\"margin:0px 4px\" src=\"https://github.com/PinkR1ver/Jude.W-s-Knowledge-Brain/blob/master/warehouse/img/skills/anaconda.png?raw=true\" /\u003e\n\u003c/div\u003e\n\n## Detail\n\n* Program Language: Python \u003e= MATLAB \u003e\u003e C == HTML/CSS/JavaScript\n* Deep Learning Associated:\n\t* Proficient in PyTorch deep learning frameworks\n\t* Familiar with the common techniques and algorithms of deep neural network,.\n\t* Familiar with the common CV tasks and NLP tasks.\n\t* Familiar with some famous backbone of DL model -  U-Net, Vit...\n\t* Learning LLM knowledge recently\n* Core lessons: \n\t* NUS - EE4305 - Fuzzy/Neural System for Intelligent Robotics - Grade: A\n\t* NUS - EE4309 - Robot Perception - Grade: A-\n\t* ZJU - Signal and System - Grade: A-\n\t* ZJU - Modern Medical Imaging Technology - Grade: A\n\t* ZJU - Data Structure - Grade: B+\n\t* ...\n* Toolkit: Git, VS code\n\n## Others\n\n*  Jekyll, RStudio and some other tools to build personal blog: [https://pinkr1ver.com](https://pinkr1ver.com) (🚧 obsolete...)\n* HTML+CSS+JS to create my photo slide show web - [https://pinkr1ver.com/PhotoGallery/](https://pinkr1ver.com/PhotoGallery/)\n* SHAP analysis for model interpretability https://github.com/PinkR1ver/SHAP_Tutorial\n* $\\LaTeX$ for my FYP thesis, contributed to 1.9k star repository [zjuthesis](https://github.com/TheNetAdmin/zjuthesis)\n\n# 🏆 Honors\n\n* Excellent Graduate of Zhejiang University\n* Third Class Scholarship of Zhejiang University\n\n# 🎈 Clubs\n\n* DanYang \u0026 QingXi Community Student Union New Media Department deputy director \u003cspan style=\"float: right; \"\u003e2018-2020\u003c/span\u003e\n\n# 🌺 Other Fun Facts\n\n* Outdoor fans - cycling, hiking... - [My Strava Profile](https://www.strava.com/athletes/109116948)\n* Photography fans - [My Photo Gallery](https://pinkr1ver.notion.site/3cfdd332b9a94b20bca041f2aa2bdcd2?v=24e696e6ab754386a710bc8e83976357)\n* Loving films, dramas, books... - [My Watching List](https://pinkr1ver.notion.site/5e136466f3664ff1aaaa75b85446e5b4?v=a41efbce52a84f7aa89d8f649f4620f6)\n* PC Game fans, especially CS - [My Steam profile](https://steamcommunity.com/id/PinkCred1t)\n* Chess fans - [Rank in chess.com](https://www.chess.com/member/yichongwang)\n\n# 📟 Contacts\n\n* 🏢: Dept. Biomedical Engineering Lab 511 | Zhejiang University\n* ☎: +86 177-6826-6860\n* 📬: pinkr1veroops@gmail.com\n\n","lastmodified":"2023-06-10T07:55:32.777172689Z","tags":null},"/warehouse/dampers_keeping_a_door_from_slamming-shut":{"title":"Dampers keeping a door from slamming shut","content":"\n![](warehouse/attachments/Pasted%20image%2020230404150745.png)","lastmodified":"2023-06-10T07:55:32.785172806Z","tags":null}}