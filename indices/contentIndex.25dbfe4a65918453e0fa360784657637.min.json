{"/":{"title":"Home","content":"\n🕵️‍♂️ This is Jude Wang's vault about his notebook, his knowledge, his second brain. \n\n🚧 There are notebooks about his research career:\n\n* [[Deep Learning And Machine Learning/Deep Learning Block/Deep Learning Block|Deep Learning Block]]\n\n* [Signal Processing](Signal%20Processing/Signal%20Processing_MOC.md)\n\n* [[Synthetic Aperture Radar Imaging/SAR_MOC| Synthetic Aperture Radar(SAR) Imaging]]\n\n🛶 Also, he learn some knowledge about his hobbies:\n\n* [📷 Photography](Photography/Photography_MOC.md)\n\n* [文学✒](文学/文学_MOC.md)\n\n","lastmodified":"2023-03-22T08:29:08.862083505Z","tags":null},"/%E6%96%87%E5%AD%A6/%E5%8F%A5%E5%AD%90":{"title":"句子","content":"\n  \u003cstyle\u003e\n    p {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n\n    a {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n  \u003c/style\u003e\n\n\n\u003cscript\u003e\n    //  document.addEventListener(\"DOMContentLoaded\", function() {\n    //     var divElements = document.body.getElementsByClassName(\"singlePage\");\n    //     for (var i = 0; i \u003c divElements.length; i++) {\n    //         var articleElements = divElements[i].getElementsByTagName(\"article\");\n    //         for (var j = 0; j \u003c articleElements.length; j++) {\n    //             var pElements = articleElements[j].querySelectorAll(\"p:not([class])\");\n    //             console.log(pElements)\n    //             console.log(pElements.length)\n    //             for (var k = 0; k \u003c pElements.length; k++) {\n    //                 var pText = pElements[k].textContent;\n    //                 pText = pText.replaceAll(\"\\u201C\", \"\\u300C\");\n    //                 pText = pText.replaceAll(\"\\u201D\", \"\\u300D\");\n    //                 pElements[k].textContent = pText;\n    //                 console.log(pElements[k].textContent)\n    //             }\n    //         }\n    //     }\n    // })\n    // 三个问题：\n    // 1. 需要reload来加载这段script\n    // 2. 把英文的\"\"也替换成了「」\n    // 3. 因为2的问题，让\u003ca\u003e中的链接失效\n\u003c/script\u003e\n\u003e [!quote] \n\u003e \"No easy basket\"\n\n“如果你想了解American篮球的根基，你要去看看美高”\n\n---\n\n\u003e [!quote] \n\u003e [A poem](https://www.bilibili.com/video/BV1V24y1x7Nh/?buvid=YF4AFCFA7E0887094E329B9A6FADF98BF343\u0026is_story_h5=false\u0026mid=B1quk6Mlu6tnRY8zjwxWeg%3D%3D\u0026p=1\u0026plat_id=116\u0026share_from=ugc\u0026share_medium=iphone\u0026share_plat=ios\u0026share_session_id=4AD8E5F4-D617-499B-9C19-D5897A7EB825\u0026share_source=QQ\u0026share_tag=s_i\u0026timestamp=1679378304\u0026unique_k=tXa4xdJ\u0026up_id=315154029\u0026vd_source=c47136abc78922800b17d6ce79d6e19f) \u003cbr\u003e\n\u003e “至少有两次喜欢\u003cbr\u003e\n一次发生在在一起之前，一次发生在之后，\u003cbr\u003e\n第一次是喜欢上你。第二次是喜欢上我们，\u003cbr\u003e\n我只敢把第二次翻译成爱，\u003cbr\u003e\n第一次是因为你很好，第二次是因为我还没有坏到敢放满揉碎你的好。\u003cbr\u003e\n我要小心的捧着第一次的喜欢，就像掏出一份手写的初稿，\u003cbr\u003e\n你会接过我的目光，在岁月里重新誊写岁月，\u003cbr\u003e\n要删改的地方还很多，包括但不限于，把差错翻译成幽默\u003cbr\u003e\n改了还是存在啊，爱情本就是听起来很美的，阴差阳错”\n\n---\n\n\u003e [!quote] \n\u003e \"I am too full of life to be half-loved\"\n\u003e \n\n![400](文学/attachments/Pasted%20image%2020230321142115.png)\n\n---\n\n\u003e [!quote] \n\u003e [A poem](https://www.bilibili.com/video/BV1Vd4y187Tq/?buvid=YF4AFCFA7E0887094E329B9A6FADF98BF343\u0026is_story_h5=false\u0026mid=B1quk6Mlu6tnRY8zjwxWeg%3D%3D\u0026p=1\u0026plat_id=116\u0026share_from=ugc\u0026share_medium=iphone\u0026share_plat=ios\u0026share_session_id=F81E6185-E382-4E78-95FD-3155869F570B\u0026share_source=QQ\u0026share_tag=s_i\u0026timestamp=1679380048\u0026unique_k=Q9GSCLM\u0026up_id=2009238634\u0026vd_source=c47136abc78922800b17d6ce79d6e19f)\u003cbr\u003e\n\u003e  “他听的小众音乐，\u003cbr\u003e\n\u003e  第二天上了抖音热榜。\u003cbr\u003e\n\u003e  他爱吃的苍蝇小馆，\u003cbr\u003e\n\u003e  第二天全国连锁了一万家。\u003cbr\u003e\n\u003e  他爱的县城姑娘，\u003cbr\u003e\n\u003e  第二天出国留学再也没回来。\u003cbr\u003e\n\u003e  他觉得那些特别，\u003cbr\u003e\n\u003e  都已烟消云散，\u003cbr\u003e\n\u003e  可那些特别一直都在，\u003cbr\u003e\n\u003e  错就错在他认为特别\u003cbr\u003e\n\u003e  只属于他。”\u003cbr\u003e\n\u003e  \u003ca href=\"https://space.bilibili.com/2009238634\"\u003e\u003cp style=\"text-align:right\"\u003e——祺白石\u003c/p\u003e\u003c/a\u003e\n\n![400](文学/attachments/Pasted%20image%2020230321143300.png)","lastmodified":"2023-03-22T08:29:08.870083679Z","tags":null},"/%E6%96%87%E5%AD%A6/%E6%96%87%E5%AD%A6_MOC":{"title":"文学","content":"\n  \u003cstyle\u003e\n    p {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n\n    a {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n  \u003c/style\u003e\n\nIn this MOC, it shows you the path to what I record for some interesting sentences, including Chinese and English, even Japanese.\n\n[🌌句子](文学/句子.md)\n\n[📜原创诗](文学/Poem_by_me.md)\n","lastmodified":"2023-03-22T08:29:08.870083679Z","tags":null},"/%E6%96%87%E5%AD%A6/Poem_by_me":{"title":"My Poem","content":"\n  \u003cstyle\u003e\n    p {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n\n    a {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n  \u003c/style\u003e\n","lastmodified":"2023-03-22T08:29:08.862083505Z","tags":null},"/.trash/attachments/Pasted-image-20230320150424.png":{"title":"Pasted image 20230320150424.png","content":"","lastmodified":"2023-03-22T08:29:08.810082368Z","tags":null},"/Deep-Learning-And-Machine-Learning/Deep-Learning-Block/Attention":{"title":"⭐Attenion","content":"# Self-Attention\n\n讲述self-attention我们以*sequence labeling*任务作为任务来讲解，sequence labeling的任务是输入N个vector并且输出N个label。\n\n典型的例子有输入一个句子，分析每个词汇的词性是什么，比如句子“I saw a saw”，这个句子里saw和saw的词性分别是verb和nonu，如果我们用fully-connected（FC）层来做的话，那么面对同样的输入saw，我们无法得出不同的结果。\n\n![Pasted image 20230315195403](Deep%20Learning%20And%20Machine%20Learning/Deep%20Learning%20Block/attachments/1.png)\n\n我们的做法可以是对输入加窗，考虑周边邻近的词汇信息，这与信号处理常用的方法类似，但是窗的长度是有限且固定的，而seq的长度是变化的，因此我们在面对这种任务的时候，我们可以借助**self-attention**层。\n\n## Detail\n\n![Pasted image 20230315195603](Deep%20Learning%20And%20Machine%20Learning/Deep%20Learning%20Block/attachments/Pasted%20image%2020230315195603.png)\n\n对于Self-attention层，生成的$b^i$向量是考虑到所有输入$\\sum_i\\alpha^i$向量\n\n### Vector Relevance\n\n![250](Deep%20Learning%20And%20Machine%20Learning/Deep%20Learning%20Block/attachments/Pasted%20image%2020230315200009.png)\n\n\n* *Step 1.* 使用Dot-product 去计算 vector relevance\n\n![400](Deep%20Learning%20And%20Machine%20Learning/Deep%20Learning%20Block/attachments/Pasted%20image%2020230315201906.png)\n\n* *Step 2.* Normalizing计算出来的vector relevance\n![400](Deep%20Learning%20And%20Machine%20Learning/Deep%20Learning%20Block/attachments/Pasted%20image%2020230315202047.png)\n\n* *Step 3.*  根据vector relevance，也就是attention scores计算最后的输出。这是一个Reweighting Process，一个extract information based on attention scores\n\n![400](Deep%20Learning%20And%20Machine%20Learning/Deep%20Learning%20Block/attachments/Pasted%20image%2020230315202314.png)\n\n\u003e [!hint] \n\u003e  从上面的过程中，可以看出，$b^i$互相之间的计算没有关系，具有很好的并行性\n\n### Matrix Detail\n\n$$\nq^i = W^q \\alpha^i\n$$\n\n\n$$\nQ = [q^1 \\quad q^2 \\quad \\cdots \\quad q^N],\\ \\  I = [\\alpha^1 \\quad \\alpha^2 \\quad \\cdots \\quad \\alpha^N]\n$$\n\n\n\nSo,\n\n$$\nQ = W^q I\n$$\n\nAs same,\n$$\nK = W^k I,\\quad V = W^v I\n$$\nCalculate attention score $\\alpha$,\n$$\n\\begin{bmatrix}\n\\alpha_{1,1} \\\\\n\\alpha_{1,2} \\\\\n\\cdots \\\\\n\\alpha_{1,N}\n\\end{bmatrix} =\n\\begin{bmatrix}\nk^1 \\\\\nk^2 \\\\\n\\cdots \\\\\nk_N\n\\end{bmatrix} q^1\n$$\n\nSo,\n$$\nA=\\begin{bmatrix}\n\\alpha_{1,1} \u0026 \\alpha_{2,1} \u0026 \\cdots \u0026 \\alpha_{N,1} \\\\\n\\alpha_{1,2} \u0026 \\alpha_{2,2} \u0026 \\cdots \u0026 \\alpha_{N,2} \\\\\n\\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots\\\\\n\\alpha_{1,N} \u0026 \\alpha_{2,N} \u0026 \\cdots \u0026 \\alpha_{N,N}\n\\end{bmatrix} =\n\\begin{bmatrix}\nk^1 \\\\\nk^2 \\\\\n\\cdots \\\\\nk_N\n\\end{bmatrix} [q^1 \\quad q^2 \\quad \\cdots \\quad q^N] = K^TQ\n$$\n\n$$\nA' = \\text{Softmax}(A)\n$$\n\nFinally, calculate output $b$\n\n$$\nO = [b^1 \\quad b^2 \\quad \\cdots \\quad b^N] = [v^1 \\quad v^2 \\quad \\cdots \\quad v^N] = VA'\n$$\n\n![600](Deep%20Learning%20And%20Machine%20Learning/Deep%20Learning%20Block/attachments/Pasted%20image%2020230315205148.png)\n\n### Positional Encoding\n![250](Deep%20Learning%20And%20Machine%20Learning/Deep%20Learning%20Block/attachments/Pasted%20image%2020230315205727.png)\n* Each position has a unique positional vector $e^i$\n\t* hand-crafted\n\t* learned from data\n\n## Fun Facts\n\n### Self-attention vs. CNN\n\n![Pasted image 20230315205918](Deep%20Learning%20And%20Machine%20Learning/Deep%20Learning%20Block/attachments/Pasted%20image%2020230315205918.png)\n\n因为transformer有着更大的function set，所以需求更多的数据; ![Pasted image 20230315210032](Deep%20Learning%20And%20Machine%20Learning/Deep%20Learning%20Block/attachments/Pasted%20image%2020230315210032.png)\n\n### Self-attention vs. RNN\n\n目前，RNN的角色正在被self-attention替代，RNN在long seq的情况下，前面的信息会被逐渐遗忘；同时**RNN没有并行性**\n同样，Self attention有着比RNN更大的function set，在某些情况下，self-attention可以变成RNN\n\n# Multi-head Self-attention\nMulti-head self attention就是由不同的self attention layer在一起，有不同的$W^q$,$W^k$来负责不同种类的relevance\n\n![600](Deep%20Learning%20And%20Machine%20Learning/Deep%20Learning%20Block/attachments/Pasted%20image%2020230315210631.png)\n![300](Deep%20Learning%20And%20Machine%20Learning/Deep%20Learning%20Block/attachments/Pasted%20image%2020230315210704.png) ","lastmodified":"2023-03-22T08:29:08.862083505Z","tags":null},"/Deep-Learning-And-Machine-Learning/Deep-Learning-Block/Deep-Learning-Block":{"title":"Deep Learning Block - MOC","content":"\n[[Deep Learning And Machine Learning/Deep Learning Block/⭐Attention|Attention Blocker]]\n\n[[Deep Learning And Machine Learning/Deep Learning Block/Transformer|Transformer]]\n\n","lastmodified":"2023-03-22T08:29:08.810082368Z","tags":null},"/Deep-Learning-And-Machine-Learning/Deep-Learning-Block/Transformer":{"title":"Transformer","content":"\n\u003e [!info] \n\u003e 在学习Transformer前，你需要学习 [⭐Attention](Deep%20Learning%20And%20Machine%20Learning/Deep%20Learning%20Block/⭐Attention.md)\n\n\n\nTransformer 是Seq2Seq model，由Encoder和Decoder组成\n![300](Deep%20Learning%20And%20Machine%20Learning/Deep%20Learning%20Block/attachments/Pasted%20image%2020230316160103.png)\n\n# Encoder\n这里贴的是原文Encoder的架构\n![Pasted image 20230316162635](Deep%20Learning%20And%20Machine%20Learning/Deep%20Learning%20Block/attachments/Pasted%20image%2020230316162635.png)\n\n![Pasted image 20230316162642](Deep%20Learning%20And%20Machine%20Learning/Deep%20Learning%20Block/attachments/Pasted%20image%2020230316162642.png)","lastmodified":"2023-03-22T08:29:08.810082368Z","tags":null},"/Photography/Photography_MOC":{"title":"Photography - MOC","content":"\n# 🌊Photo Portfolio\nYou can see my photography works in:\n\n* [🌄Photo Collection](https://www.notion.so/pinkr1ver/3cfdd332b9a94b20bca041f2aa2bdcd2?v=24e696e6ab754386a710bc8e83976357)\n* [🍻Instagram](https://www.instagram.com/jude.wang.yc/?next=%2F)\n\n# Notes\nAlso, here's my notes about learning photography\n\n## About Basic Concepts:\n\n* [Saturation](Photography/Saturation.md)\n\n## Appreciation of other works - about ***aesthetic***\n\n* [👧Portrait](Photography/Portrait.md)\n\n# Reference about great photography website\n\n* [Magnum Photos](https://www.magnumphotos.com/)\n* [CNU - Catch Next Ultimate](http://www.cnu.cc/)\n","lastmodified":"2023-03-22T08:29:08.862083505Z","tags":null},"/Photography/Portrait":{"title":"👧Portrait","content":"\n* [🌸Flower \u0026 Girl](Photography/Portrait/Flower_and_Girl.md)","lastmodified":"2023-03-22T08:29:08.862083505Z","tags":null},"/Photography/Portrait/Flower_and_Girl":{"title":"🌸Flower \u0026 Girl","content":"\n","lastmodified":"2023-03-22T08:29:08.862083505Z","tags":null},"/Photography/Saturation":{"title":"Saturation - 饱和度","content":"\nto be written...","lastmodified":"2023-03-22T08:29:08.862083505Z","tags":null},"/Signal-Processing/Basic-Concepts-in-Signal-Processing":{"title":"Basic Concepts in Signal Processing","content":"\n* [What is dB](Signal%20Processing/What%20is%20dB.md)","lastmodified":"2023-03-22T08:29:08.862083505Z","tags":null},"/Signal-Processing/Signal-Processing_MOC":{"title":"Signal Processing - MOC","content":"\n* [Basic Concepts in Signal Processing](Signal%20Processing/Basic%20Concepts%20in%20Signal%20Processing.md)\n","lastmodified":"2023-03-22T08:29:08.862083505Z","tags":null},"/Signal-Processing/What-is-dB":{"title":"What is dB","content":"dB is short for decibel, which is a unit that indicates ratio or gain. It is often used to measure *sound intensity*, *signal strength*, *attenuation* and other quantities. \n\nFor example, if a sound has a power of 10 W and another sound has a power of 1 W, then the difference in decibels is 10 dB = 10 log (10/1) = 10 log 10 = 10.\n\n**Signal Noise Ratio** is also measured by dB\n\n## Signal Noise Ratio\n$$\n{SNR}_{power}=\\frac{\\text{Average Signal Power}}{\\text{Average Noise Power}}\n$$\n\n$$\n{SNR}_{voltage}=\\frac{\\text{RMS Signal Voltage}}{\\text{RMS Noise Voltage}}\n$$\n\n$$\n{SNR}_{power}={{SNR}_{voltage}}^2\n$$\n\n$$\n{SNR}_{dB}=10\\log_{10}{{SNR}_{power}}=20\\log_{10}{{SNR}_{voltage}}\n$$\n","lastmodified":"2023-03-22T08:29:08.862083505Z","tags":null},"/Synthetic-Aperture-Radar-Imaging/Radiometric-Calibration":{"title":"Radiometric Calibration - 辐射校准","content":"\n# Overview\nSAR 校准旨在提供其像素值可与场景中的雷达反向散射直接相关的影像。虽然未校准的 SAR 影像足以用于定性用途，但校准后的 SAR 影像对于定量使用 SAR 数据而言仍至关重要。\n\n生成级别 1 影像的典型 SAR 数据处理不包括辐射校正，且仍然存在明显的辐射偏差。因此有必要对 SAR 影像应用辐射校正，*使影像的像素值真正能够反映反射表面的雷达反向散射情况*。在比较由不同的传感器采集的 SAR 影像时，或比较由同一传感器在不同时间、不同模式下采集的（或由不同处理器处理的）SAR 影像时，都需要进行辐射校正。\n\n## Types\n* **Sigma nought** - 用于校准地面上单位面积内返回到天线的反向散射，并与地面范围相关。影像经过校准，因此可以直接与相同或不同传感器收集的不同雷达影像进行比较。科学家倾向于使用 sigma naught 来解释表面散射、表面反射以及表面属性。\n\t* *Scattering coefficient*, or the conventional measure of the strength of radar signals reflected by a distributed scatterer, usually expressed in dB. It is a *normalised dimensionless number*, comparing the strength observed to that expected from an area of one square meter. Sigma nought is defined with respect to the nominally horizontal plane, and in general has a significant variation with **incidence angle**, **wavelength**, and **polarisation**, as well as with **properties of the scattering surface itself**.\n* **Beta nought** - 可生成包含雷达亮度系数的数据集（雷达亮度系数是天线发射功率与接收功率之比）。它与倾斜范围有关，且无维度。\n* **Gamma** - 通常在校准天线时使用。因为每个范围像元与卫星的距离均相等，所以近距范围和远距范围的亮度均相等，这有助于确定输出数据集中的天线方向图。\n* **None** - 不做校正\n\n\n\n# Reference\n\n* [Sentinel-1 Radiometric Calibration—ArcMap | Documentation (arcgis.com)](https://desktop.arcgis.com/en/arcmap/latest/manage-data/raster-and-images/sentinel-1-radiometric-calibration.htm)\n\n* [Urban objects detection from C-band synthetic aperture radar (SAR) satellite images through simulating filter properties | Scientific Reports (nature.com)](https://www.nature.com/articles/s41598-021-85121-9)\n\n* [✨✨✨User Guides - Sentinel-1 SAR - Definitions - Sentinel Online - Sentinel Online (esa.int)](https://sentinel.esa.int/web/sentinel/user-guides/sentinel-1-sar/definitions)\n\n","lastmodified":"2023-03-22T08:29:08.862083505Z","tags":null},"/Synthetic-Aperture-Radar-Imaging/SAR-Explained":{"title":"Synthetic Aperture Radar (SAR) Explained","content":"\n# Radar Basic Concepts\n\n## Down Looking vs. Side Looking\n\n![Pasted image 20230320150424](Synthetic%20Aperture%20Radar%20Imaging/attachments/Pasted%20image%2020230320150424.png)\n\nDown Looking不能区分距离一样的a，b点\n\n## Simplified explanation of Radar working \u0026 What is SAR\nThe radar consists fundamentally of *a transmitter*, *a receiver*, *an antenna* and *an electronic system* to process and record the data.\n\nThe transmitter generates successive short bursts or pulses of microwave at regular intervals which are focused by the antenna into a beam. Radar beam illuminates the surface **obliquely** at a right angle to the motion of the platform. The antenna receives a portion of the transmitted energy reflected or it's known as backscattered from various objects within the illuminated beam by  measuring this time delay between the transmission of a pulse and the reception of the backscattered echo from different  targets. Their distance from the radar and therefore their location can be determined as the sensor platform moves forward recording and processing of the backscattered signals builds up a 2-dimensional image of the surface.\n\n\n\u003e [!important] \n\u003e Important\u003cbr\u003e\n\u003e The along track **resolution** is determined by the beam width which is *inversely proportional to the antenna length*, also known as the **aperture**, which means that longer antenna or a longer aperture will produce a narrow beam and a finer resolution. \u003cbr\u003e\n\u003e Long antenna $\\leftrightarrow$ Small beam $\\leftrightarrow$ Long aperture $\\leftrightarrow$ Better image resolution\n\n介于实际情况下的物理空间中，雷达天线的大小是限的，可以通过雷达的移动去模拟长天线情况下的雷达，也就是活得更大的aperture，这项被叫做SAR。目的是在于使用*comparatively small physical antennas*去获得*high resolution images*\n\n## Review of Radar Image Formation\n\n![660](Synthetic%20Aperture%20Radar%20Imaging/attachments/Pasted%20image%2020230320163240.png)\n\n* Radar can measure *amplitude* and *phase*\n* Radar can only measure part of echoes.\n* The strength of the reflected echo is the backscattering coefficient ([sigma nought](Synthetic%20Aperture%20Radar%20Imaging/Radiometric%20Calibration.md)）and is expressed in [decibels(dB)](Signal%20Processing/What%20is%20dB.md)\n\n## Radar Key Parameters\n* Wave Length\n* Polarization\n* Incidence Angle\n\n\n# Reference\n\n* ***Sentinel-1** is a famous SAR, you can find almost every *definitions* of SAR in this page:\n[User Guides - Sentinel-1 SAR - Definitions - Sentinel Online - Sentinel Online (esa.int)](https://sentinel.esa.int/web/sentinel/user-guides/sentinel-1-sar/definitions)","lastmodified":"2023-03-22T08:29:08.862083505Z","tags":null},"/Synthetic-Aperture-Radar-Imaging/SAR_MOC":{"title":"Synthetic Aperture Radar (SAR) Imaging - MOC","content":"\n* [[Synthetic Aperture Radar Imaging/SAR Explained|SAR Explained]]\n","lastmodified":"2023-03-22T08:29:08.862083505Z","tags":null}}